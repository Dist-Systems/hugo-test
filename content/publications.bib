% Encoding: UTF-8

@inproceedings{gritti2020_symbion,
  title     = {{SYMBION: Interleaving Symbolic with Concrete Execution}},
  author    = {Gritti, Fabio and Fontana, Lorenzo and Gustafson, Eric and Pagani, Fabio and Continella, Andrea and Kruegel, Christopher and Vigna, Giovanni},
  booktitle = {Proceedings of the IEEE Conference on Communications and Network Security (CNS)},
  month     = {June},
  year      = {2020},
  kind      = {conference},
  timestamp = {2020-06-15},
  paper     = {yes},
}

@inproceedings{redini2020_karonte,
  title     = {KARONTE: Detecting Insecure Multi-binary Interactions in Embedded Firmware},
  author    = {Nilo Redini and Aravind Machiry and Ruoyu Wang and Chad Spensky and Andrea Continella and Yan Shoshitaishvili and Christopher Kruegel and Giovanni Vigna},
  booktitle = {{Proceedings of the IEEE Symposium on Security & Privacy (S&P)}},
  year      = {2020},
  month     = {May},
  kind      = {conference},
  timestamp = {2020-05-15},
  paper     = {yes}, 
}

@InProceedings{Aghakhani2020_Malware_Packin_Heat,
  title     = {{When Malware is Packin' Heat; Limits of Machine Learning Classifiers Based on Static Analysis Features}},
  author={Hojjat Aghakhani and Fabio Gritti and Francesco Mecca and Martina Lindorfer and Stefano Ortolani and Davide Balzarotti and Giovanni Vigna and Christopher Kruegel},
  booktitle={Proceedings of Symposium on Network and Distributed System Security (NDSS)},
  year      = {2020},
  month     = feb,
  kind      = {conference},
  timestamp = {2020-02-15},
  paper     = {yes}, 
}

@InProceedings{jindal2019_neurlux,
  title     = {{Neurlux: Dynamic Malware Analysis Without Feature Engineering}},
  author={Chani Jindal and Christopher Salls and Hojjat Aghakhani and Keith Long and Christopher Kruegel and Giovanni Vigna},
  booktitle={Proceedings of the Annual Computer Security Applications Conference (ACSAC)},
  year      = {2019},
  month     = dec,
  kind      = {conference},
  timestamp = {2019-12-15},
  paper     = {yes}, 
}

@inproceedings{hauser2019_sleak,
  title={{Sleak: Automating Address Space Layout Derandomization}},
  author={Christophe Hauser and Jayakrishna Menon and Yan Shoshitaishvili and Ruoyu Wang and Giovanni Vigna and Christopher Kruegel},
  booktitle={Proceedings of the Annual Computer Security Applications Conference (ACSAC)},
  month     = dec,
  year      ={2019},
  kind      = {conference},
  timestamp = {2019-12-12},
  paper     = {yes}, 
}

@inproceedings{gustafson2019_pretender,
  title     ={{Toward the Analysis of Embedded Firmware Through Automated Re-hosting}},
  author    ={Gustafson, Eric and Muench, Marius and Spensky, Chad and and Redini, Nilo and Machiry, Aravind and Francillon, Aurelien and Balzarotti, Davide and Choe, Yung Ryn and Kruegel, Christopher and Vigna, Giovanni},
  booktitle ={Proceedings of the International Symposium on Research in Attacks, Intrusions, and Defenses (RAID)},
  year      ={2019},
  month     =sep,
  address   ={Beijing, China},
  kind      = {conference},
  timestamp = {2019-09-12},
  paper     = {yes}, 
}

@inproceedings{redini19_bintrimmer,
  title     = {{BinTrimmer: Towards Static Binary Debloating Through Abstract Interpretation}},
  author    = {Nilo Redini and Ruoyu Wang and Aravind Machiry and Yan Shoshitaishvili and Giovanni Vigna and Christopher Kruegel},
  year      = 2019,
  month     = {June},
  address   = {Gothenburg, Sweden},
  series    = {Lecture Notes in Computer Science},
  publisher = {Springer Verlag},
  booktitle = {Proceedings of the International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA)},
  kind      = {conference},
  timestamp = {2019-06-12},
  paper     = {yes}, 
}

@inproceedings{nilizadeh19_dataset,
  title     = {{Think Outside the Dataset: Finding Fraudulent Reviews using Cross-Dataset Analysis}},
  author    = {Shirin Nilizadeh and Hojjat Aghakhani and Eric Gustafson and Christopher Kruegel and Giovanni Vigna},
  booktitle = {Proceedings of the Web Conference (WWW)},
  year      = 2019,
  month     = {May},
  address   = {San Francisco, USA},
  kind      = {conference},
  timestamp = {2019-05-12},
  paper     = {yes}, 
}

@inproceedings{chevalier19_bootkeeper,
  author = {Ronny Chevalier and Stefano Cristalli and Christophe Hauser and Yan Shoshitaishvili and Ruoyu Wang and Christopher Kruegel and Giovanni Vigna and Danilo Bruschi and Andrea Lanzi},
  title = {{BootKeeper: Validating Software Integrity Properties on Boot Firmware Images}},
  booktitle = {Proceedings of the ACM Conference on Data and Application Security and Privacy (CODASPY)},
  year = 2019,
  month = mar,
  address = {Dallas, USA},
  kind      = {conference},
  timestamp = {2019-03-12},
  paper     = {yes}, 
}

@inproceedings{machiry19_dataset,
  author = {Aravind Machiry and Nilo Redini and Eric Gustafson and Hojjat Aghakhani and Christopher Kruegel and Giovanni Vigna},
  title = {{Towards Automatically Generating a Sound and Complete Dataset for Evaluating Static Analysis Tools}},
  booktitle = {Proceedings of the Workshop on Binary Analysis Research (BAR)},
  address   = {San Diego, USA},
  month     = feb,
  year      = {2019},
  kind      = {conference},
  timestamp = {2019-02-12},
  paper     = {yes}, 
}

@InProceedings{Zhou2004Detecting_Attacks,
  title       = {Detecting {Attacks} {That} {Exploit} {Application}-{Logic} {Errors} {Through} {Application}-{Level} {Auditing}},
  author      = {Zhou, J. and Vigna, G.},
  booktitle   = {{Proceedings of the 20th Annual Computer Security Applications Conference}},
  year        = {2004},
  address     = {Tucson, AZ},
  month       = dec,
  pages       = {168--178},
  series      = {ACSAC},
  kind        = {conference},
  timestamp   = {2004-12-06},
  paper       = {yes}, 
}

@InProceedings{Zarras2014The_Dark,
  Paper       = {yes},
  title       = {The {Dark} {Alleys} of {Madison} {Avenue}: {Understanding} {Malicious} {Advertisements}},
  author      = {Zarras, Apostolis and Kapravelos, Alexandros and Stringhini, Gianluca and Holz, Thorsten and Kruegel, Christopher and Vigna, Giovanni},
  booktitle   = {Proceedings of the 2014 {Conference} on {Internet} {Measurement} {Conference}},
  year        = {2014},
  address     = {New York, NY, USA},
  pages       = {373--380},
  publisher   = {ACM},
  abstract    = {Online advertising drives the economy of the World Wide Web. Modern websites of any size and popularity include advertisements to monetize visits from their users. To this end, they assign an area of their web page to an advertising company (so called ad exchange) that will use it to display promotional content. By doing this, the website owner implicitly trusts that the advertising company will offer legitimate content and it will not put the site's visitors at risk of falling victims of malware campaigns and other scams. In this paper, we perform the first large-scale study of the safety of the advertisements that are encountered by the users on the Web. In particular, we analyze to what extent users are exposed to malicious content through advertisements, and investigate what are the sources of this malicious content. Additionally, we show that some ad exchanges are more prone to serving malicious advertisements than others, probably due to their deficient filtering mechanisms. The observations that we make in this paper shed light on a little studied, yet important, aspect of advertisement networks, and can help both advertisement networks and website owners in securing their web pages and in keeping their visitors safe.},
  iSBN        = {978-1-4503-3213-2},
  doi         = {10.1145/2663716.2663719},
  series      = {IMC},
  kind        = {conference},
  timestamp   = {2014-11-05},
  paper       = {yes}, 
}

@InProceedings{Zand2014Extracting_Probable,
  Paper       = {yes},
  title     = {Extracting {Probable} {Command} and {Control} {Signatures} for {Detecting} {Botnets}},
  author    = {Zand, Ali and Vigna, Giovanni and Yan, Xifeng and Kruegel, Christopher},
  booktitle = {Proceedings of the 29th {Annual} {ACM} {Symposium} on {Applied} {Computing}},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {1657--1662},
  publisher = {ACM},
  abstract  = {Botnets, which are networks of compromised machines under the control of a single malicious entity, are a serious threat to online security. The fact that botnets, by definition, receive their commands from a single entity can be leveraged to fight them. To this end, one requires techniques that can detect command and control (C\&C) traffic, as well as the servers that host C\&C services. Given the knowledge of a C\&C server's IP address, one can use this information to detect all hosts that attempt to contact such a server, and subsequently disinfect, disable, or block the infected machines. This information can also be used by law enforcement to take down the C\&C server. In this paper, we present a new botnet C\&C signature extraction approach that can be used to find C\&C communication in traffic generated by executing malware samples in a dynamic analysis system. This approach works in two steps. First, we extract all frequent strings seen in the network traffic. Second, we use a function that assigns a score to each string. This score represents the likelihood that the string is indicative of C\&C traffic. This function allows us to rank strings and focus our attention on those that likely represent good C\&C signatures. We apply our technique to almost 2.6 million network connections produced by running more than 1.4 million malware samples. Using our technique, we were able to automatically extract a set of signatures that are able to identify C\&C traffic. Furthermore, we compared our signatures with those used by existing tools, such as Snort and BotHunter.},
  iSBN      = {978-1-4503-2469-4},
  doi       = {10.1145/2554850.2554896},
  series    = {SAC},
  kind      = {conference},
  timestamp = {2014-03-24},
  paper     = {yes},
}

@InProceedings{Zand2014Rippler_Delay,
  Paper       = {yes},
  title     = {Rippler: {Delay} Injection For Service Dependency Detection},
  author    = {Zand, Ali and Vigna, Giovanni and Kemmerer, Richard A. and Kruegel, Christopher},
  booktitle = {2014 {IEEE} {Conference} on {Computer} {Communications}},
  year      = {2014},
  pages     = {2157--2165},
  doi       = {10.1109/INFOCOM.2014.6848158},
  series    = {INFOCOM},
  kind      = {conference},
  timestamp = {2014-04-29},
  paper     = {yes},
}

@InProceedings{Yin2007Panorama_Capturing,
  Paper       = {yes},
  title     = {Panorama: {Capturing} System-Wide Information Flow For Malware Detection and Analysis},
  author    = {Yin, Heng and Song, Dawn Xiaodong and Egele, Manuel and Kruegel, Christopher and Kirda, Engin},
  booktitle = {{Proceedings of the 14th Annual Computer Security Applications Conference}},
  year      = {2007},
  address   = {Alexandria, VA},
  month     = oct,
  doi       = {10.1145/1315245.1315261},
  series    = {CCS},
  kind      = {conference},
  timestamp = {2007-10-29},
  paper     = {yes},
}

@InProceedings{Wurzinger2009Automatically_Generating,
  Paper       = {yes},
  title       = {Automatically {Generating} {Models} for {Botnet} {Detection}},
  author      = {Wurzinger, Peter and Bilge, Leyla and Holz, Thorsten and Goebel, Jan and Kruegel, Christopher and Kirda, Engin},
  booktitle   = {Proceedings of the 14th {European} {Conference} on {Research} in {Computer} {Security}},
  year        = {2009},
  address     = {Berlin, Heidelberg},
  pages       = {232--249},
  publisher   = {Springer-Verlag},
  abstract    = {A botnet is a network of compromised hosts that is under the control of a single, malicious entity, often called the botmaster. We present a system that aims to detect bots, independent of any prior information about the command and control channels or propagation vectors, and without requiring multiple infections for correlation. Our system relies on detection models that target the characteristic fact that every bot receives commands from the botmaster to which it responds in a specific way. These detection models are generated automatically from network traffic traces recorded from actual bot instances. We have implemented the proposed approach and demonstrate that it can extract effective detection models for a variety of different bot families. These models are precise in describing the activity of bots and raise very few false positives.},
  iSBN        = {3-642-04443-3 978-3-642-04443-4},
  url         = {http://dl.acm.org/citation.cfm?id=1813084.1813104},
  series      = {ESORICS},
  kind        = {conference},
  timestamp   = {2009-09-21},
  paper       = {yes}, 
}

@InProceedings{Wondracek2010A_Practical,
  Paper       = {yes},
  title     = {A {Practical} {Attack} to {De}-anonymize {Social} {Network} {Users}},
  author    = {Wondracek, Gilbert and Holz, Thorsten and Kirda, Engin and Kruegel, Christopher},
  booktitle = {Proceedings of the 31th {IEEE} {Symposium} on {Security} and {Privacy}},
  year      = {2010},
  doi       = {10.1109/SP.2010.21},
  pages     = {223--238},
  series    = {S&P},
  kind      = {conference},
  timestamp = {2010-05-22},
  paper     = {yes},
}

@InProceedings{Wang2010Steal_This,
  Paper       = {yes},
  title       = {Steal {This} {Movie} - {Automatically} {Bypassing} {DRM} {Protection} in {Streaming} {Media} {Services}},
  author      = {Wang, Ruoyu and Shoshitaishvili, Yan and Kruegel, Christopher and Vigna, Giovanni},
  booktitle   = {Proceedings of the 22nd {USENIX} {Conference} on {Security}},
  year        = {2013},
  address     = {Berkeley, CA, USA},
  pages       = {687--702},
  publisher   = {USENIX Association},
  abstract    = {Streaming movies online is quickly becoming the way in which users access video entertainment. This has been powered by the ubiquitous presence of the Internet and the availability of a number of hardware platforms that make access to movies convenient. Often, video-on-demand services use a digital rights management system to prevent the user from duplicating videos because much of the economic model of video stream services relies on the fact that the videos cannot easily be saved to permanent storage and (illegally) shared with other customers. In this paper, we introduce a general memory-based approach that circumvents the protections deployed by popular video-on-demand providers. We apply our approach to four different examples of streaming services: Amazon Instant Video, Hulu, Spotify, and Netflix and we demonstrate that, by using our technique, it is possible to break DRM protection in a semi-automated way.},
  iSBN        = {978-1-931971-03-4},
  url         = {http://dl.acm.org/citation.cfm?id=2534766.2534825},
  series      = {USENIX Security},
  kind        = {conference},
  timestamp   = {2010-08-14},
  paper       = {yes}, 
}

@InProceedings{Volpatto2010Effective_Multimodel,
  Paper       = {yes},
  title       = {Effective {Multimodel} {Anomaly} {Detection} {Using} {Cooperative} {Negotiation}},
  author      = {Volpatto, Alberto and Maggi, Federico and Zanero, Stefano},
  booktitle   = {Proceedings of the {Decision} and {Game} {Theory} for {Security}},
  year        = {2010},
  month       = nov,
  pages       = {180--191},
  publisher   = {Springer Berlin/Heidelberg},
  series      = {Lecture {Notes} in {Computer} {Science}},
  volume      = {6442},
  iSBN        = {978-3-642-17196-3},
  series      = {GameSec},
  kind        = {conference},
  timestamp   = {2010-11-22},
  paper       = {yes}, 
}

@InProceedings{Vogt2007Cross_Site,
  Paper       = {yes},
  title       = {Cross {Site} {Scripting} {Prevention} with {Dynamic} {Data} {Tainting} and {Static} {Analysis}.},
  author      = {Vogt, Philipp and Nentwich, Florian and Jovanovic, Nenad and Kirda, Engin and Kruegel, Christopher and Vigna, Giovanni},
  booktitle   = {{Proceedings of the 14th Network and Distributed Systems Security Symposium}},
  year        = {2007},
  address     = {San Diego, CA},
  series      = {NDSS},
  kind        = {conference},
  timestamp   = {2007-02-28},
  paper       = {yes}, 
}


@InProceedings{Vigna2002Composable_Tools,
  title       = {Composable {Tools} {For} {Network} {Discovery} and {Security} {Analysis}},
  author      = {Vigna, Giovanni and Valeur, Fredrik and Zhou, Jingyu and Kemmerer, Richard A.},
  booktitle   = {{Proceedings of the 18th Annual Computer Security Applications Conference}},
  year        = {2002},
  address     = {Las Vegas, NV},
  month       = dec,
  pages       = {14--24},
  publisher   = {IEEE Press},
  series      = {ACSAC},
  kind        = {conference},
  timestamp   = {2002-12-09},
  paper       = {yes}, 
}

@InProceedings{Vigna2003Designing_and,
  title       = {Designing and {Implementing} a {Family} of {Intrusion} {Detection} {Systems}},
  author      = {Vigna, Giovanni and Valeur, Fredrik and Kemmerer, Richard A.},
  booktitle   = {Proceedings of the 9th {European} {Software} {Engineering} {Conference} and {ACM} {SIGSOFT} {Symposium} on the {Foundations} of {Software} {Engineering}},
  year        = {2003},
  address     = {Helsinki, Finland},
  month       = sep,
  pages       = {88--97},
  series      = {{ESEC}/{FSE}},
  kind        = {conference},
  timestamp   = {2003-09-05},
  paper       = {yes}, 
}

@Article{Vigna2009Reducing_errors,
  title       = {Reducing errors in the anomaly-based detection of web-based attacks through the combined analysis of web requests and {SQL} queries},
  author      = {Vigna, Giovanni and Valeur, Fredrik and Balzarotti, Davide and Robertson, William and Kruegel, Christopher and Kirda, Engin},
  journal     = {Journal of Computer Security},
  year        = {2009},
  number      = {3},
  pages       = {305--329},
  volume      = {17},
  url         = {http://www.cs.ucsb.edu/~chris/research/doc/jcs09_revproxy.pdf},
  kind        = {journal},
  timestamp   = {2009-03-01},
  paper       = {yes}, 
}

@InProceedings{Vigna2003A_Stateful,
  title       = {A {Stateful} {Intrusion} {Detection} {System} for {World}-{Wide} {Web} {Servers}},
  author      = {Vigna, Giovanni and Robertson, Wil and Kher, Vishal and Kemmerer, Richard A.},
  booktitle   = {{Proceedings of the 10th Annual Computer Security Applications Conference}},
  year        = {2003},
  address     = {Las Vegas, NV},
  month       = dec,
  pages       = {34--43},
  series      = {CCS},
  kind        = {conference},
  timestamp   = {2003-12-08},
  paper       = {yes}, 
}

@InProceedings{Vigna2004Testing_Network-based,
  title       = {Testing {Network}-based {Intrusion} {Detection} {Signatures} {Using} {Mutant} {Exploits}},
  author      = {Vigna, Giovanni and Robertson, Wil and Balzarotti, Davide},
  booktitle   = {Proceedings of the 11th {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
  year        = {2004},
  address     = {Washington, DC},
  month       = oct,
  pages       = {21--30},
  series      = {CCS},
  kind        = {conference},
  timestamp   = {2004-10-25},
  paper       = {yes}, 
}

@InProceedings{Vigna2002Mnemosyne_Designing,
  title       = {Mnemosyne: {Designing} and {Implementing} {Network} {Short}-{Term} {Memory}},
  author      = {Vigna, G. and Mitchell, A.},
  booktitle   = {Proceedings of the 8th {IEEE} {International} {Conference} on {Engineering} of {Complex} {Computer} {Systems}},
  year        = {2002},
  address     = {Greenbelt, MD},
  month       = dec,
  pages       = {91--100},
  publisher   = {IEEE Press},
  series      = {ICECCS},
  kind        = {conference},
  timestamp   = {2002-12-01},
  paper       = {yes}, 
}

@InProceedings{Vigna2001Designing_a,
  title       = {Designing a {Web} of {Highly}-{Configurable} {Intrusion} {Detection} {Sensors}},
  author      = {Vigna, Giovanni and Kemmerer, Richard A. and Blix, Per},
  booktitle   = {Proceedings of the 4th {International} {Symposium} on {Recent} {Advances} in {Intrusion} {Detection}},
  year        = {2001},
  address     = {Davis, CA},
  month       = oct,
  pages       = {69--84},
  publisher   = {Springer-Verlag},
  volume      = {2212},
  series      = {RAID},
  kind        = {conference},
  timestamp   = {2001-10-10},
  paper       = {yes}, 
}

@Article{Vigna2007Security_Evaluation,
  title       = {Security {Evaluation} of the {Sequoia} {Voting} {System}},
  author      = {Vigna, Giovanni and Kemmerer, Richard A. and Balzarotti, Davide and Banks, Greg and Cova, Marco and Felmetsger, Vika and Robertson, Wil and Valeur, Fredrik},
  journal     = {Top-To-Bottom Review of the California Voting Machines},
  year        = {2007},
  month       = jul,
  kind        = {journal},
  timestamp   = {2007-07-01},
  paper       = {yes}, 
}

@InProceedings{Vigna1998NetSTAT_A,
  title       = {{NetSTAT}: {A} {Network}-based {Intrusion} {Detection} {Approach}},
  author      = {Vigna, Giovanni and Kemmerer, Richard A.},
  booktitle   = {{Proceedings of the 14th Annual Computer Security Applications Conference}},
  year        = {1998},
  address     = {Scottsdale, AZ},
  month       = dec,
  pages       = {25--34},
  publisher   = {IEEE Press},
  series      = {ACSAC},
  kind        = {conference},
  timestamp   = {1998-12-10},
  paper       = {yes}, 
}

@Article{Vigna1999NetSTAT_A,
  title       = {{NetSTAT}: {A} {Network}-based {Intrusion} {Detection} {System}},
  author      = {Vigna, Giovanni and Kemmerer, Richard A.},
  journal     = {Journal of Computer Security},
  year        = {1999},
  number      = {1},
  pages       = {37--71},
  volume      = {7},
  kind        = {journal},
  timestamp   = {1999-01-01},
  paper       = {yes}, 
}

@InProceedings{Vigna2004An_Intrusion,
  title       = {An {Intrusion} {Detection} {Tool} for {AODV}-based {Ad} {Hoc} {Wireless} {Networks}},
  author      = {Vigna, Giovanni and Gwalani, Sumit and Srinivasan, Kavitha and Belding-Royer, Elizabeth and Kemmerer, Richard},
  booktitle   = {{Proceedings of the 20th Annual Computer Security Applications Conference}},
  year        = {2004},
  address     = {Tucson, AZ},
  month       = dec,
  pages       = {16--27},
  series      = {ACSAC},
  kind        = {conference},
  timestamp   = {2004-12-20},
  paper       = {yes}, 
}

@InProceedings{Vigna2000The_STAT,
  title       = {The {STAT} {Tool} {Suite}},
  author      = {Vigna, Giovanni and Eckmann, Steve T. and Kemmerer, Richard A.},
  booktitle   = {Proceedings of {DISCEX} 2000},
  year        = {2000},
  address     = {Hilton Head, SC},
  month       = jan,
  pages       = {46--55},
  publisher   = {IEEE Press},
  series      = {DISCEX},
  kind        = {conference},
  timestamp   = {2000-01-01},
  paper       = {yes}, 
}

@InProceedings{Vigna2000Attack_Languages,
  title       = {Attack {Languages}},
  author      = {Vigna, Giovanni and Eckmann, Steve T. and Kemmerer, Richard A.},
  booktitle   = {Proceedings of the 3rd {IEEE} {Information} {Survivability} {Workshop}},
  year        = {2000},
  address     = {Boston, MA},
  month       = oct,
  pages       = {163--166},
  series      = {ISW},
  kind        = {conference},
  timestamp   = {2000-10-24},
  paper       = {yes}, 
}

@InProceedings{Vigna2002An_Intrusion,
  title       = {An {Intrusion} {Detection} {System} for {Aglets}},
  author      = {Vigna, Giovanni and Cassell, Bryan and Fayram, Dave},
  booktitle   = {Proceedings of the 6th {International} {Conference} on {Mobile} {Agents}},
  year        = {2002},
  address     = {Barcelona, Spain},
  month       = oct,
  pages       = {64--77},
  publisher   = {Springer-Verlag},
  volume      = {2535},
  series      = {MA},
  kind        = {conference},
  timestamp   = {2002-10-24},
  paper       = {yes}, 
}

@InProceedings{Vigna1998A_Model-Centered,
  title       = {A {Model}-{Centered} {Electronic} {Commerce} {Middleware}},
  author      = {Vigna, Giovanni and Bonomi, Leonardo},
  booktitle   = {Proceedings of the {International} {IFIP} {Working} {Conference} on {Trends} in {Electronic} {Commerce}},
  year        = {1998},
  address     = {Hamburg, Germany},
  month       = jun,
  series      = {TrEC},
  kind        = {conference},
  timestamp   = {1998-06-01},
  paper       = {yes}, 
}

@InProceedings{Vigna2003A_Topological,
  title       = {A {Topological} {Characterization} of {TCP}/{IP} {Security}},
  author      = {Vigna, Giovanni},
  booktitle   = {Proceedings of the 12th {International} {Symposium} of {Formal} {Methods} {Europe}},
  year        = {2003},
  address     = {Pisa, Italy},
  month       = sep,
  pages       = {914--940},
  publisher   = {Springer-Verlag},
  series      = {FME},
  kind        = {conference},
  timestamp   = {2003-09-08},
  paper       = {yes}, 
}

@Article{Vigna2003Teaching_Hands-On,
  title       = {Teaching {Hands}-{On} {Network} {Security}: {Testbeds} and {Live} {Exercises}},
  author      = {Vigna, Giovanni},
  journal     = {Journal of Information Warfare},
  year        = {2003},
  number      = {2},
  pages       = {8--25},
  volume      = {3},
  kind        = {journal},
  timestamp   = {2003-12-01},
  paper       = {yes}, 
}

@InProceedings{Vigna2004Mobile_Agents,
  title       = {Mobile {Agents}: {Ten} {Reasons} {For} {Failure}},
  author      = {Vigna, Giovanni},
  booktitle   = {Proceedings of the 5th {IEEE} {International} {Conference} on {Mobile} {Data} {Management}},
  year        = {2004},
  address     = {Berkeley, CA},
  month       = jan,
  pages       = {298--299},
  series      = {MDM},
  kind        = {conference},
  timestamp   = {2004-01-19},
  paper       = {yes}, 
}

@InProceedings{Vigna2010Network_Intrusion,
  title       = {Network {Intrusion} {Detection}: {Dead} or {Alive}?},
  author      = {Vigna, Giovanni},
  booktitle   = {{Proceedings of the 26th Annual Computer Security Applications Conference}},
  year        = {2010},
  address     = {Austin, TX},
  month       = dec,
  series      = {ACSAC},
  kind        = {conference},
  timestamp   = {2010-12-06},
  paper       = {yes}, 
}

@InProceedings{Vigna2003Teaching_Network,
  title       = {Teaching {Network} {Security} {Through} {Live} {Exercises}},
  author      = {Vigna, Giovanni},
  booktitle   = {Proceedings of the 3rd {Annual} {World} {Conference} on {Information} {Security} {Education}},
  year        = {2003},
  address     = {Monterey, CA},
  month       = jun,
  pages       = {3--18},
  publisher   = {Kluwer Academic Publishers},
  series      = {WISE},
  kind        = {conference},
  timestamp   = {2003-06-01},
  paper       = {yes}, 
}

@InProceedings{vanderVeen2016Drammer_Deterministic,
  title       = {Drammer: {Deterministic} {Rowhammer} {Attacks} on {Mobile} {Platforms}},
  author      = {van der Veen, Victor and Fratantonio, Yanick and Lindorfer, Martina and Gruss, Daniel and Maurice, Clementine and Vigna, Giovanni and Bos, Herbert and Razavi, Kaveh and Giuffrida, Cristiano},
  booktitle   = {Proceedings of the 2016 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
  year        = {2016},
  address     = {Vienna, Austria},
  month       = oct,
  abstract    = {Recent work shows that the Rowhammer hardware bug can be used to craft powerful attacks and completely subvert a system. However, existing efforts either describe probabilistic (and thus unreliable) attacks or rely on special (and often unavailable) memory management features to place victim objects in vulnerable physical memory locations. Moreover, prior work only targets x86 and researchers have openly wondered whether Rowhammer attacks on other architectures, such as ARM, are even possible.
We show that deterministic Rowhammer attacks are feasible on commodity mobile platforms and that they cannot be mitigated by current defenses. Rather than assuming special memory management features, our attack, Drammer, solely relies on the predictable memory reuse patterns of standard physical memory allocators. We implement Drammer on Android/ARM, demonstrating the practicability of our attack, but also discuss a generalization of our approach to other Linux-based platforms. Furthermore, we show that traditional x86-based Rowhammer exploitation techniques no longer work on mobile platforms and address the resulting challenges towards practical mobile Rowhammer attacks.
To support our claims, we present the first Rowhammer-based Android root exploit relying on no software vulnerability, and requiring no user permissions. In addition, we present an analysis of several popular smartphones and find that many of them are susceptible to our Drammer attack. We conclude by discussing potential mitigation strategies and urging our community to address the concrete threat of faulty DRAM chips in widespread commodity platforms.},
  series      = {DIMVA},
  kind        = {conference},
  timestamp   = {2016-10-24},
  paper       = {yes}, 
}

@Article{Valeur2004A_Comprehensive,
  Paper       = {yes},
  title     = {A {Comprehensive} {Approach} to {Intrusion} {Detection} {Alert} {Correlation}},
  author    = {Valeur, Fredrik and Vigna, Giovanni and Kruegel, Christopher and Kemmerer, Richard A.},
  journal   = {IEEE Transactions on Dependable and Secure Computing},
  year      = {2004},
  month     = jul,
  number    = {3},
  pages     = {146--169},
  volume    = {1},
  iSSN      = {1545-5971},
  doi       = {10.1109/TDSC.2004.21},
  kind      = {journal},
  timestamp = {2004-03-01},
  paper     = {yes},
}

@InProceedings{Valeur2005A_Learning-Based,
  title       = {A {Learning}-Based {Approach} to the {Detection} of {SQL} {Attacks}},
  author      = {Valeur, Fredrik and Mutz, Darren and Vigna, Giovanni},
  booktitle   = {Proceedings of the 2nd Detection of {Intrusions} and {Malware}, and {Vulnerability} {Assessment}},
  year        = {2005},
  address     = {Berlin, Heidelberg},
  pages       = {123--140},
  publisher   = {Springer-Verlag},
  iSBN        = {3-540-26613-5 978-3-540-26613-6},
  doi = {10.1007/11506881_8},
  series      = {DIMVA},
  kind        = {conference},
  timestamp   = {2005-07-07},
  paper       = {yes}, 
}

@Article{Valdi2015Scalable_Testing,
  Paper       = {yes},
  title       = {Scalable {Testing} of {Mobile} {Antivirus} {Applications}},
  author      = {Valdi, Andrea and Lever, Eros and Benefico, Simone and Quarta, Davide and Zanero, Stefano and Maggi, Federico},
  journal     = {Computer},
  year        = {2015},
  month       = nov,
  number      = {11},
  pages       = {60--68},
  volume      = {48},
  abstract    = {AndroTotal, a scalable antivirus evaluation system for mobile devices, creates reproducible, self-contained testing environments for each antivirus application and malware pair and stores them in a repository, benefiting both the research community and Android device users.},
  iSSN        = {0018-9162},
  kind        = {journal},
  timestamp   = {2015-11-01},
  paper       = {yes}, 
}

@InProceedings{Thomas2015Ad_Injection,
  Paper       = {yes},
  title       = {Ad {Injection} at {Scale}: {Assessing} {Deceptive} {Advertisement} {Modifications}},
  author      = {Thomas, Kurt and Bursztein, Elie and Grier, Chris and Ho, Grant and Jagpal, Nav and Kapravelos, Alexandros and McCoy, Damon and Nappa, Antonio and Paxson, Vern and Pearce, Paul and Provos, Niels and Rajab, Moheeb Abu},
  booktitle   = {Proceedings of the 36th {IEEE} {Symposium} on {Security} and {Privacy}},
  year        = {2015},
  series      = {iNetSec},
  kind        = {conference},
  timestamp   = {2015-05-18},
  paper       = {yes}, 
}

@InProceedings{Szydlowski2011Challenges_for,
  title       = {Challenges for {Dynamic} {Analysis} of {iOS} {Applications}},
  author      = {Szydlowski, Martin and Egele, Manuel and Kruegel, Christopher and Vigna, Giovanni},
  booktitle   = {{iNetSec} {Open} {Research} {Problems} in {Network} {Security}},
  year        = {2011},
  address     = {Luzerne, Switzerland},
  month       = jun,
  series      = {iNetSec},
  kind        = {conference},
  timestamp   = {2011-06-09},
  paper       = {yes}, 
}

@InProceedings{Stringhini2013Follow_the,
  title     = {Follow the {Green}: {Growth} and {Dynamics} in {Twitter} {Follower} {Markets}},
  author    = {Stringhini, Gianluca and Wang, Gang and Egele, Manuel and Kruegel, Christopher and Vigna, Giovanni and Zheng, Haitao and Zhao, Ben Y.},
  booktitle = {Proceedings of the 2013 {Conference} on {Internet} {Measurement} {Conference}},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {163--176},
  publisher = {ACM},
  abstract  = {The users of microblogging services, such as Twitter, use the count of followers of an account as a measure of its reputation or influence. For those unwilling or unable to attract followers naturally, a growing industry of "Twitter follower markets" provides followers for sale. Some markets use fake accounts to boost the follower count of their customers, while others rely on a pyramid scheme to turn non-paying customers into followers for each other, and into followers for paying customers. In this paper, we present a detailed study of Twitter follower markets, report in detail on both the static and dynamic properties of customers of these markets, and develop and evaluate multiple techniques for detecting these activities. We show that our detection system is robust and reliable, and can detect a significant number of customers in the wild.},
  iSBN      = {978-1-4503-1953-9},
  doi       = {10.1145/2504730.2504731},
  series    = {IMC},
  kind      = {conference},
  timestamp = {2013-10-23},
  paper     = {yes},
}

@InProceedings{Stringhini2015EvilCohort_Detecting,
  title       = {{EvilCohort}: {Detecting} {Communities} of {Malicious} {Accounts} on {Online} {Services}},
  author      = {Stringhini, Gianluca and Mourlanne, Pierre and Jacob, Gregoire and Egele, Manuel and Kruegel, Christopher and Vigna, Giovanni},
  booktitle   = {Proceedings of the 24th {USENIX} {Conference} on {Security}},
  year        = {2015},
  address     = {Washington, D.C.},
  month       = aug,
  series      = {USENIX Security},
  kind        = {conference},
  timestamp   = {2015-08-12},
  paper       = {yes}, 
}

@InProceedings{Stringhini2010Detecting_Spammers,
  Paper       = {yes},
  title     = {Detecting {Spammers} on {Social} {Networks}},
  author    = {Stringhini, Gianluca and Kruegel, Christopher and Vigna, Giovanni},
  booktitle = {{Proceedings of the 26th Annual Computer Security Applications Conference}},
  year      = {2010},
  address   = {New York, NY, USA},
  pages     = {1--9},
  publisher = {ACM},
  abstract  = {Social networking has become a popular way for users to meet and interact online. Users spend a significant amount of time on popular social network platforms (such as Facebook, MySpace, or Twitter), storing and sharing a wealth of personal information. This information, as well as the possibility of contacting thousands of users, also attracts the interest of cybercriminals. For example, cybercriminals might exploit the implicit trust relationships between users in order to lure victims to malicious websites. As another example, cybercriminals might find personal information valuable for identity theft or to drive targeted spam campaigns. In this paper, we analyze to which extent spam has entered social networks. More precisely, we analyze how spammers who target social networking sites operate. To collect the data about spamming activity, we created a large and diverse set of "honey-profiles" on three large social networking sites, and logged the kind of contacts and messages that they received. We then analyzed the collected data and identified anomalous behavior of users who contacted our profiles. Based on the analysis of this behavior, we developed techniques to detect spammers in social networks, and we aggregated their messages in large spam campaigns. Our results show that it is possible to automatically identify the accounts used by spammers, and our analysis was used for take-down efforts in a real-world social network. More precisely, during this study, we collaborated with Twitter and correctly detected and deleted 15,857 spam profiles.},
  iSBN      = {978-1-4503-0133-6},
  doi       = {10.1145/1920261.1920263},
  series    = {ACSAC},
  kind      = {conference},
  timestamp = {2010-12-06},
  paper     = {yes},
}

@InProceedings{Stringhini2013Shady_Paths,
  title       = {Shady Paths: Leveraging Surfing Crowds to Detect malicious Web Pages},
  author      = {Stringhini, Gianluca and Kruegel, Christopher and Vigna, Giovanni},
  booktitle   = {Proceedings of the 2013 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
  year        = {2013},
  pages       = {133--144},
  publisher   = {ACM Press},
  iSBN        = {978-1-4503-2477-9},
  language    = {en},
  series      = {CCS},
  kind        = {conference},
  timestamp   = {2013-11-04},
  paper       = {yes}, 
}

@InProceedings{Stringhini2011BOTMAGNIFIER_Locating,
  title       = {{BOTMAGNIFIER}: {Locating} {Spambots} on the {Internet}},
  author      = {Stringhini, Gianluca and Holz, Thorsten and Stone-Gross, Brett and Kruegel, Christopher and Vigna, Giovanni},
  booktitle   = {Proceedings of the 20st {USENIX} {Conference} on {Security}},
  year        = {2011},
  address     = {Berkeley, CA, USA},
  pages       = {28--28},
  publisher   = {USENIX Association},
  abstract    = {Unsolicited bulk email (spam) is used by cybercriminals to lure users into scams and to spread malware infections. Most of these unwanted messages are sent by spam botnets, which are networks of compromised machines under the control of a single (malicious) entity. Often, these botnets are rented out to particular groups to carry out spam campaigns, in which similar mail messages are sent to a large group of Internet users in a short amount of time. Tracking the bot-infected hosts that participate in spam campaigns, and attributing these hosts to spam botnets that are active on the Internet, are challenging but important tasks. In particular, this information can improve blacklist-based spam defenses and guide botnet mitigation efforts. In this paper, we present a novel technique to support the identification and tracking of bots that send spam. Our technique takes as input an initial set of IP addresses that are known to be associated with spam bots, and learns their spamming behavior. This initial set is then "magnified" by analyzing large-scale mail delivery logs to identify other hosts on the Internet whose behavior is similar to the behavior previously modeled. We implemented our technique in a tool, called BOTMAGNIFIER, and applied it to several data streams related to the delivery of email traffic. Our results show that it is possible to identify and track a substantial number of spam bots by using our magnification technique. We also perform attribution of the identified spam hosts and track the evolution and activity of well-known spamming botnets over time. Moreover, we show that our results can help to improve state-of-the-art spam blacklists.},
  url         = {http://dl.acm.org/citation.cfm?id=2028067.2028095},
  series      = {USENIX Security},
  kind        = {conference},
  timestamp   = {2011-08-08},
  paper       = {yes}, 
}

@InProceedings{Stringhini2014The_Harvester,
  title     = {The {Harvester}, the {Botmaster}, and the {Spammer}: {On} the {Relations} {Between} the {Different} {Actors} in the {Spam} {Landscape}},
  author    = {Stringhini, Gianluca and Hohlfeld, Oliver and Kruegel, Christopher and Vigna, Giovanni},
  booktitle = {Proceedings of the 9th {ACM} {Symposium} on {Information}, {Computer} and {Communications} {Security}},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {353--364},
  publisher = {ACM},
  abstract  = {A spammer needs three elements to run a spam operation: a list of victim email addresses, content to be sent, and a botnet to send it. Each of these three elements are critical for the success of the spam operation: a good email list should be composed of valid email addresses, a good email content should be both convincing to the reader and evades anti-spam filters, and a good botnet should efficiently sent spam. Given how critical these three elements are, figures specialized on one of these elements have emerged in the spam ecosystem. Email harvesters crawl the web and compile email lists, botmasters infect victim computers and maintain efficient botnets for spam dissemination, and spammers rent botnets and buy email lists to run spam campaigns. Previous research suggested that email harvesters and botmasters sell their services to spammers in a prosperous underground economy. No rigorous research has been performed, however, on understanding the relations between these three actors. This paper aims to shed some light on the relations between harvesters, botmasters, and spammers. By disseminating email addresses on the Internet, fingerprinting the botnets that contact these addresses, and looking at the content of these emails, we can infer the relations between the actors involved in the spam ecosystem. Our observations can be used by researchers to develop more effective anti-spam systems.},
  iSBN      = {978-1-4503-2800-5},
  doi       = {10.1145/2590296.2590302},
  series    = {ASIA CCS},
  kind      = {conference},
  timestamp = {2014-06-03},
  paper     = {yes},
}

@InProceedings{Stringhini2012B@bel_Leveraging,
  Paper       = {yes},
  title       = {B@bel: {Leveraging} {Email} {Delivery} for {Spam} {Mitigation}.},
  author      = {Stringhini, Gianluca and Egele, Manuel and Zarras, Apostolis and Holz, Thorsten and Kruegel, Christopher and Vigna, Giovanni},
  booktitle   = {{Proceedings of the 21st USENIX Security Symposium}},
  year        = {2012},
  address     = {Bellevue, WA},
  pages       = {16--32},
  url         = {https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final59.pdf},
  series      = {USENIX Security},
  kind        = {conference},
  timestamp   = {2012-08-08},
  paper       = {yes}, 
}

@Article{Stringhini2012Poultry_Markets,
  title     = {Poultry {Markets}: {On} the {Underground} {Economy} of {Twitter} {Followers}},
  author    = {Stringhini, Gianluca and Egele, Manuel and Kruegel, Christopher and Vigna, Giovanni},
  journal   = {Proceedings of the 2012 ACM workshop on Workshop on online social networks},
  year      = {2012},
  month     = sep,
  number    = {4},
  pages     = {527--532},
  volume    = {42},
  iSSN      = {0146-4833},
  doi       = {10.1145/2377677.2377781},
  kind      = {journal},
  timestamp = {2012-08-17},
  paper     = {yes},
}

@InProceedings{Stone-Gross2008Malware_in,
  title       = {Malware in {IEEE} 802.11 {Wireless} {Networks}}, 
  author      = {Stone-Gross, Brett and Wilson, Christo and Almeroth, Kevin and Belding, Elizabeth and Zheng, Heather and Papagiannaki, Konstantina},
  booktitle   = {Proceedings of the 9th {Passive} and {Active} {Measurement} {Conference}}, 
  year        = {2008},
  address     = {Cleveland, OH},
  month       = apr,
  series      = {PAM},
  kind        = {conference},
  timestamp   = {2008-04-29},
  paper       = {yes}, 
}

@InProceedings{Stone-Gross2011Understanding_Fraudulent,
  title     = {Understanding {Fraudulent} {Activities} in {Online} {Ad} {Exchanges}},
  author    = {Stone-Gross, Brett and Stevens, Ryan and Zarras, Apostolis and Kemmerer, Richard and Kruegel, Chris and Vigna, Giovanni},
  booktitle = {Proceedings of the 2011 {ACM} {SIGCOMM} {Conference} on {Internet} {Measurement} {Conference}},
  year      = {2011},
  address   = {New York, NY, USA},
  pages     = {279--294},
  publisher = {ACM},
  abstract  = {Online advertisements (ads) provide a powerful mechanism for advertisers to effectively target Web users. Ads can be customized based on a user's browsing behavior, geographic location, and personal interests. There is currently a multi-billion dollar market for online advertising, which generates the primary revenue for some of the most popular websites on the Internet. In order to meet the immense market demand, and to manage the complex relationships between advertisers and publishers (i.e., the websites hosting the ads), marketplaces known as "ad exchanges" are employed. These exchanges allow publishers (sellers of ad space) and advertisers(buyers of this ad space) to dynamically broker traffic through ad networks to efficiently maximize profits for all parties. Unfortunately, the complexities of these systems invite a considerable amount of abuse from cybercriminals, who profit at the expense of the advertisers. In this paper, we present a detailed view of how one of the largest ad exchanges operates and the associated security issues from the vantage point of a member ad network. More specifically, we analyzed a dataset containing transactions for ingress and egress ad traffic from this ad network. In addition, we examined information collected from a command-and-control server used to operate a botnet that is leveraged to perpetrate ad fraud against the same ad exchange.},
  iSBN      = {978-1-4503-1013-0},
  doi       = {10.1145/2068816.2068843},
  series    = {IMC},
  kind      = {conference},
  timestamp = {2011-11-02},
  paper     = {yes},
}

@InProceedings{Stone-Gross2008VeriKey_A,
  title       = {{VeriKey}: {A} {Dynamic} {Certificate} {Verification} {System} for {Public} {Key} {Exchanges}},
  author      = {Stone-Gross, Brett and Sigal, David and Cohn, Rob and Morse, John and Almeroth, Kevin and Kruegel, Christopher},
  booktitle   = {Proceedings of the 5th Detection of {Intrusions} and {Malware}, and {Vulnerability} {Assessment}},
  year        = {2008},
  month       = jul,
  address     = {Paris, France},
  series      = {DIMVA},
  kind        = {conference},
  timestamp   = {2008-07-10},
  paper       = {yes}, 
}

@InProceedings{Stone-Gross2009FIRE_FInding,
  title       = {{FIRE}: {FInding} {Rogue} {nEtworks}},
  author      = {Stone-Gross, Brett and Moser, Andy and Kruegel, Christopher and Kirda, Engin and Almeroth, Kevin},
  booktitle   = {{Proceedings of the 25th Annual Computer Security Applications Conference}},
  year        = {2009},
  address     = {Honolulu, HI},
  month       = dec,
  series      = {ACSAC},
  kind        = {conference},
  timestamp   = {2009-12-07},
  paper       = {yes}, 
}

@InProceedings{Stone-Gross2011The_Underground,
  title       = {The {Underground} {Economy} of {Spam}: {A} {Botmaster}'s {Perspective} of {Coordinating} {Large}-scale {Spam} {Campaigns}},
  author      = {Stone-Gross, Brett and Holz, Thorsten and Stringhini, Gianluca and Vigna, Giovanni},
  booktitle   = {Proceedings of the 4th {USENIX} {Workshop} on {Large}-{Scale} {Exploits} and {Emergent} {Threats}},
  year        = {2011},
  month       = mar, 
  address     = {Berkeley, CA, USA},
  pages       = {4--4},
  publisher   = {USENIX Association},
  abstract    = {Spam accounts for a large portion of the email exchange on the Internet. In addition to being a nuisance and a waste of costly resources, spam is used as a delivery mechanism for many criminal scams and large-scale compromises. Most of this spam is sent using botnets, which are often rented for a fee to criminal organizations. Even though there has been a considerable corpus of research focused on combating spam and analyzing spam-related botnets, most of these efforts have had a limited view of the entire spamming process. In this paper, we present a comprehensive analysis of a large-scale botnet from the botmaster's perspective, that highlights the intricacies involved in orchestrating spam campaigns such as the quality of email address lists, the effectiveness of IP-based blacklisting, and the reliability of bots. This is made possible by having access to a number of command-and-control servers used by the Pushdo/Cutwail botnet. In addition, we study Spamdot.biz, a private forum used by some of the most notorious spam gangs, to provide novel insights into the underground economy of large-scale spam operations.},
  url         = {http://dl.acm.org/citation.cfm?id=1972441.1972447},
  series      = {LEET},
  kind        = {conference},
  timestamp   = {2011-03-29},
  paper       = {yes}, 
}

@InProceedings{Stone-Gross2011Peering_Through,
  title       = {Peering {Through} the {iFrame}},
  author      = {Stone-Gross, Brett and Cova, Marco and Kruegel, Christopher and Vigna, Giovanni},
  booktitle   = {Proceedings of the 30th {International} {Conference} on {Computer} {Communications}},
  year        = {2011},
  address     = {Shanghai, China},
  month       = apr,
  series      = {INFOCOM},
  kind        = {conference},
  timestamp   = {2011-04-10},
  paper       = {yes}, 
}

@Article{Stone-Gross2011Analysis_of,
  title       = {Analysis of a {Botnet} {Takeover}},
  author      = {Stone-Gross, Brett and Cova, Marco and Gilbert, Bob and Kemmerer, Richard and Kruegel, Christopher and Vigna, Giovanni},
  journal     = {IEEE Security Privacy},
  year        = {2011},
  month       = jan,
  number      = {1},
  pages       = {64--72},
  volume      = {9},
  abstract    = {Botnets, networks of malware-infected machines (bots) that are controlled by an adversary, are the root cause of a large number of security problems on the Internet. A particularly sophisticated and insidious type of bot is Torpig, a malware program designed to harvest sensitive information (such as bank account and credit-card data) from its victims. In this article, the authors report on their efforts to take control of the Torpig botnet and study its operations for a period of 10 days. During this time, they observed more than 180,000 infections and recorded almost 70 Gbytes of data that the bots collected. They also report on what happened in the year that has passed since they lost control of the Torpig botnet.},
  iSSN        = {1540-7993},
  kind        = {journal},
  timestamp   = {2011-01-01},
  paper       = {yes}, 
}

@InProceedings{Stone-Gross2009Your_Botnet,
  Paper       = {yes},
  title       = {Your {Botnet} is {My} {Botnet}: {Analysis} of a {Botnet} {Takeover}},
  author      = {Stone-Gross, Brett and Cova, Marco and Gilbert, Bob and Cavallaro, Lorenzo and Szydlowski, Martin and Kruegel, Christopher and Vigna, Giovanni and Kemmerer, Richard},
  booktitle   = {Proceedings of the 16th {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
  year        = {2009},
  address     = {Chicago, IL},
  month       = nov,
  series      = {CCS},
  kind        = {conference},
  timestamp   = {2009-11-09},
  paper       = {yes}, 
}

@InProceedings{Stone-Gross2013The_Underground,
  title       = {The Underground Economy of Fake Antivirus Software},
  author      = {Stone-Gross, Brett and Abman, Ryan and Kemmerer, Richard A. and Kruegel, Christopher and Steigerwald, Douglas G. and Vigna, Giovanni},
  booktitle   = {Economics of {Information} {Security} and {Privacy} {III}},
  year        = {2013},
  pages       = {55--78},
  publisher   = {Springer},
  url         = {http://link.springer.com/chapter/10.1007/978-1-4614-1981-5_4},
  series      = {III},
  kind        = {conference},
  timestamp   = {2013-01-01},
  paper       = {yes}, 
}

@InProceedings{Stamminger2009Automated_Spyware,
  Paper       = {yes},
  title       = {Automated {Spyware} {Collection} and {Analysis}},
  author      = {Stamminger, Andreas and Kruegel, Christopher and Vigna, Giovanni and Kirda, Engin},
  booktitle   = {Proceedings of the 12th {Information} {Security} {Conference}},
  year        = {2009},
  address     = {Pisa, Italy},
  month       = sep,
  series      = {ISC},
  kind        = {conference},
  timestamp   = {2009-09-07},
  paper       = {yes}, 
}

@InProceedings{Spagnuolo2014BitIodine_Extracting,
  title       = {{BitIodine}: {Extracting} {Intelligence} from the {Bitcoin} {Network}},
  author      = {Spagnuolo, Michele and Maggi, Federico and Zanero, Stefano},
  booktitle   = {Financial {Cryptography} and {Data} {Security}},
  year        = {2014},
  address     = {Barbados},
  month       = mar,
  pages       = {457--468},
  publisher   = {Springer Berlin Heidelberg},
  series      = {Lecture {Notes} in {Computer} {Science} ({LNCS})},
  abstract    = {Bitcoin, the famous peer-to-peer, decentralized electronic currency system, allows users to benefit from pseudonymity, by generating an arbitrary number of aliases (or addresses) to move funds. However, the complete history of all transactions ever performed, called "blockchain", is public and replicated on each node. The data it contains is difficult to analyze manually, but can yield a high number of relevant information.
In this paper we present a modular framework, BitIodine, which parses the blockchain, clusters addresses that are likely to belong to a same user or group of users, classifies such users and labels them, and finally visualizes complex information extracted from the Bitcoin network.
BitIodine labels users (semi-)automatically with information on their identity and actions which is automatically scraped from openly available information sources. BitIodine also supports manual investigation by finding paths and reverse paths between addresses or users.
We tested BitIodine on several real-world use cases, identified an address likely to belong to the encrypted Silk Road cold wallet, or investigated the CryptoLocker ransomware and accurately quantified the number of ransoms paid, as well as information about the victims.
We release an early prototype of BitIodine as a library for building more complex Bitcoin forensic analysis tools.},
  iSBN        = {978-3-662-45471-8},
  series      = {FC},
  kind        = {conference},
  timestamp   = {2014-03-07},
  paper       = {yes}, 
}

@InProceedings{Soman2003Detecting_Malicious,
  Paper       = {yes},
  title       = {Detecting {Malicious} {Java} {Code} {Using} {Virtual} {Machine} {Auditing}},
  author      = {Soman, Sunil and Krintz, Chandra and Vigna, Giovanni},
  booktitle   = {{Proceedings of the 12th USENIX Security Symposium}},
  year        = {2003},
  address     = {Washington, DC},
  month       = aug,
  pages       = {153--167},
  publisher   = {USENIX},
  series      = {USENIX Security},
  kind        = {conference},
  timestamp   = {2003-08-04},
  paper       = {yes}, 
}

@InProceedings{Shoshitaishvili2014Do_you,
  title       = {Do you feel lucky?: a large-scale analysis of risk-rewards trade-offs in cyber security},
  author      = {Shoshitaishvili, Yan and Invernizzi, Luca and Doup, Adam and Vigna, Giovanni},
  booktitle   = {Proceedings of the 29th {Annual} {ACM} {Symposium} on {Applied} {Computing}},
  year        = {2014},
  pages       = {1649--1656},
  publisher   = {ACM},
  url         = {http://dl.acm.org/citation.cfm?id=2554880},
  series      = {SAC},
  kind        = {conference},
  timestamp   = {2014-07-10},
  paper       = {yes}, 
}

@InProceedings{Schiavoni2014Phoenix_DGA-Based,
  Paper       = {yes},
  title       = {Phoenix: {DGA}-{Based} {Botnet} {Tracking} and {Intelligence}},
  author      = {Schiavoni, Stefano and Maggi, Federico and Cavallaro, Lorenzo and Zanero, Stefano},
  booktitle   = {Proceedings of the 11th Detection of {Intrusions} and {Malware}, and {Vulnerability} {Assessment}},
  year        = {2014},
  month       = jul,
  pages       = {192--211},
  publisher   = {Springer International Publishing},
  series      = {Lecture {Notes} in {Computer} {Science}},
  abstract    = {Modern botnets rely on domain-generation algorithms (DGAs) to build resilient command-and-control infrastructures. Given the prevalence of this mechanism, recent work has focused on the analysis of DNS traffic to recognize botnets based on their DGAs. While previous work has concentrated on detection, we focus on supporting intelligence operations. We propose Phoenix, a mechanism that, in addition to telling DGA- and non-DGA-generated domains apart using a combination of string and IP-based features, characterizes the DGAs behind them, and, most importantly, finds groups of DGA-generated domains that are representative of the respective botnets. As a result, Phoenix can associate previously unknown DGA-generated domains to these groups, and produce novel knowledge about the evolving behavior of each tracked botnet. We evaluated Phoenix on 1,153,516 domains, including DGA-generated domains from modern, well-known botnets: without supervision, it correctly distinguished DGA- vs. non-DGA-generated domains in 94.8 percent of the cases, characterized families of domains that belonged to distinct DGAs, and helped researchers on the field in gathering intelligence on suspicious domains to identify the correct botnet.},
  copyright   = {2014 Springer International Publishing Switzerland},
  iSBN        = {978-3-319-08508-1 978-3-319-08509-8},
  language    = {en},
  url         = {http://link.springer.com/chapter/10.1007/978-3-319-08509-8_11},
  series      = {DIMVA},
  kind        = {conference},
  timestamp   = {2014-07-10},
  paper       = {yes}, 
}


@InProceedings{Roveta2011BURN_Baring,
  Paper       = {yes},
  title       = {{BURN}: {Baring} {Unknown} {Rogue} {Networks}},
  author      = {Roveta, Francesco and Di Mario, Luca and Maggi, Federico and Caviglia, Giorgio and Zanero, Stefano and Ciuccarelli, Paolo},
  booktitle   = {Proceedings of the 8th {International} {Symposium} on {Visualization} for {Cyber} {Security}},
  year        = {2011},
  address     = {New York, NY, USA},
  month       = jun,
  pages       = {6:1--6:10},
  publisher   = {ACM},
  abstract    = {Manual analysis of security-related events is still a necessity to investigate non-trivial cyber attacks. This task is particularly hard when the events involve slow, stealthy and large-scale activities typical of the modern cybercriminals' strategy. In this regard, visualization tools can effectively help analysts in their investigations. In this paper, we present BURN, an interactive visualization tool for displaying autonomous systems exhibiting rogue activity that helps at finding misbehaving networks through visual and interactive exploration. Up to seven values are displayed in a single visual element, while avoiding cumbersome and confusing maps. To this end, animations and alpha channels are leveraged to create simple views that highlight relevant activity patterns. In addition, BURN incorporates a simple algorithm to identify migrations of nefarious services across autonomous systems, which can support, for instance, root-cause analysis and law enforcement investigations.},
  iSBN        = {978-1-4503-0679-9},
  series      = {VizSec},
  kind        = {conference},
  timestamp   = {2011-07-20},
  paper       = {yes}, 
}

@InProceedings{Robertson2009Static_Enforcement,
  title       = {Static {Enforcement} of {Web} {Application} {Integrity} {Through} {Strong} {Typing}},
  author      = {Robertson, William and Vigna, Giovanni},
  booktitle   = {{Proceedings of the 18th USENIX Security Symposium}},
  year        = {2009},
  address     = {Montreal, Canada},
  month       = aug,
  series      = {USENIX Security},
  kind        = {conference},
  timestamp   = {2009-08-10},
  paper       = {yes}, 
}

@InProceedings{Robertson2010Effective_Anomaly,
  title       = {Effective {Anomaly} {Detection} with {Scarce} {Training} {Data}},
  author      = {Robertson, William and Maggi, Federico and Kruegel, Christopher and Vigna, Giovanni},
  booktitle   = {{Proceedings of the 17th Network and Distributed Systems Security Symposium}},
  year        = {2010},
  month       = feb,
  publisher   = {The Internet Society},
  abstract    = {Learning-based anomaly detection has proven to be an effective black-box technique for detecting unknown attacks. However, the effectiveness of this technique crucially depends upon both the quality and the completeness of the training data. Unfortunately, in most cases, the traffic to the system (e.g., a web application or daemon process) protected by an anomaly detector is not uniformly distributed. Therefore, some components (e.g., authentication, payments, or content publishing) might not be exercised enough to train an anomaly detection system in a reasonable time frame. This is of particular importance in real-world settings, where anomaly detection systems are deployed with little or no manual configuration, and they are expected to automatically learn the normal behavior of a system to detect or block attacks. In this work, we first demonstrate that the features utilized to train a learning-based detector can be semantically grouped, and that features of the same group tend to induce similar models. Therefore, we propose addressing local training data deficiencies by exploiting clustering techniques to construct a knowledge base of well-trained models that can be utilized in case of undertraining. Our approach, which is independent of the particular type of anomaly detector employed, is validated using the realistic case of a learning-based system protecting a pool of web servers running several web applications such as blogs, forums, or Web services. We run our experiments on a real-world data set containing over 58 million HTTP requests to more than 36,000 distinct web application components. The results show that by using the proposed solution, it is possible to achieve effective attack detection even with scarce training data.},
  series      = {NDSS},
  kind        = {conference},
  timestamp   = {2010-02-28},
  paper       = {yes}, 
}

@InProceedings{Ren2016ReCon_Revealing,
  Paper       = {yes},
  title       = {{ReCon}: {Revealing} and {Controlling} {PII} {Leaks} in {Mobile} {Network} {Traffic}},
  author      = {Ren, Jingjing and Rao, Ashwin and Lindorfer, Martina and Legout, Arnaud and Choffnes, David},
  booktitle   = {Proceedings of the {International} {Conference} on {Mobile} {Systems}, {Applications} and {Services}},
  year        = {2016},
  address     = {Singapore},
  month       = may,
  abstract    = {It is well known that apps running on mobile devices extensively track and leak users personally identifiable information (PII); however, these users have little visibility into PII leaked through the network traffic generated by their devices, and have poor control over how, when and where that traffic is sent and handled by third parties. In this paper, we present the design, implementation, and evaluation of ReCon: a cross-platform system that reveals PII leaks and gives users control over them without requiring any special privileges or custom OSes. ReCon leverages machine learning to reveal potential PII leaks by inspecting network traffic, and provides a visualization tool to empower users with the ability to control these leaks via blocking or substitution of PII. We evaluate ReCons effectiveness with measurements from controlled experiments using leaks from the 100 most popular iOS, Android, and Windows Phone apps, and via an IRB-approved user study with 92 participants. We show that ReCon is accurate, efficient, and identifies a wider range of PII than previous approaches.},
  series      = {MobiSys},
  kind        = {conference},
  timestamp   = {2016-05-26},
  paper       = {yes}, 
}


@InProceedings{Polino2015Jackdaw_Towards,
  title     = {Jackdaw: {Towards} {Automatic} {Reverse} {Engineering} of {Large} {Datasets} of {Binaries}},
  author    = {Polino, Mario and Scorti, Andrea and Maggi, Federico and Zanero, Stefano},
  booktitle = {Proceedings of the 12th Detection of {Intrusions} and {Malware}, and {Vulnerability} {Assessment}},
  year      = {2015},
  month     = jul,
  doi       = {10.1007/978-3-319-20550-2_7},
  pages     = {121--143},
  publisher = {Springer International Publishing},
  series    = {Lecture {Note} in {Computer} {Science}},
  abstract  = {When analyzing an untrusted binary, reverse engineers usually rely on ad-hoc collections of interesting dynamic patternsknown as behaviors in the malware-analysis communityand static patternsknown as signatures in the antivirus community. Such patterns are often part of the skill set of the analyst, sometimes implemented in manually-created post-processing scripts. It would be desirable to be able to automatically find such behaviors, present them to analysts, and create a systematic catalog of matching rules and relevant implementations. We propose Jackdaw, a system that finds interesting dynamic patterns, and ranks them to unveil potentially interesting behaviors. Then, it annotates them with static information, capturing the distinct implementations of each across different malware families. Finally, Jackdaw associates semantic information to the behaviors, so as to create a descriptive summary that helps the analysts in querying the catalog of behaviors by type. To do this, it leverages the dynamic information and an indexed Web-based knowledge databases. We implement and demonstrate Jackdaw on the Win32 API (even if the technique can be generalized to any OS). On a dataset of 2,136 distinct binaries, including both malicious and benign libraries and executables, we compared the behaviors extracted automatically against a ground truth of 44 behaviors created manually by expert analysts. Jackdaw found 77.3 \% of them and was able to exclude spurious behaviors in 99.6 \% cases. We also discovered 466 novel behaviors, among which manual exploration and review by expert reverse engineers revealed interesting findings and confirmed the correctness of the semantic tagging.},
  copyright = {2015 Springer International Publishing Switzerland},
  iSBN      = {978-3-319-20549-6 978-3-319-20550-2},
  language  = {en},
  url       = {http://link.springer.com/chapter/10.1007/978-3-319-20550-2_7},
  series    = {DIMVA},
  kind      = {conference},
  timestamp = {2015-07-09},
  paper     = {yes},
}

@InProceedings{Polakis2012All_Your,
  title       = {All {Your} {Face} {Are} {Belong} to {Us}: {Breaking} {Facebook}'s {Social} {Authentication}},
  author      = {Polakis, Jason and Lancini, Marco and Kontaxis, Georgios and Maggi, Federico and Ioannidis, Sotiris and Keromytis, Angelos and Zanero, Stefano},
  booktitle   = {{Proceedings of the 28th Annual Computer Security Applications Conference}},
  year        = {2012},
  address     = {New York, NY, USA},
  month       = dec,
  pages       = {399--408},
  publisher   = {ACM},
  abstract    = {Two-factor authentication is widely used by high-value services to prevent adversaries from compromising accounts using stolen credentials. Facebook has recently released a two-factor authentication mechanism, referred to as Social Authentication, which requires users to identify some of their friends in randomly selected photos. A recent study has provided a formal analysis of social authentication weaknesses against attackers inside the victims social circles. In this paper, we extend the threat model and study the attack surface of social authentication in practice, and show how any attacker can obtain the information needed to solve the challenges presented by Facebook. We implement a proof-of-concept system that utilizes widely available face recognition software and cloud services, and evaluate it using real public data collected from Facebook. Under the assumptions of Facebooks threat model, our results show that an attacker can obtain access to (sensitive) information for at least 42\% of a users friends that Facebook uses to generate social authentication challenges. By relying solely on publicly accessible information, a casual attacker can solve 22\% of the social authentication tests in an automated fashion, and gain a significant advantage for an additional 56\% of the tests, as opposed to just guessing. Additionally, we simulate the scenario of a determined attacker placing himself inside the victims social circle by employing dummy accounts. In this case, the accuracy of our attack greatly increases and reaches 100\% when 120 faces per friend are accessible by the attacker, even though it is very accurate with as little as 10 faces.},
  iSBN        = {978-1-4503-1312-4},
  series      = {ACSAC},
  kind        = {conference},
  timestamp   = {2012-12-03},
  paper       = {yes}, 
}

@InProceedings{Polakis2014Security_and,
  Paper       = {yes},
  title       = {Security and {Privacy} {Measurements} on {Social} {Networks}: {Experiences} and {Lessons} {Learned}},
  author      = {Polakis, Iasonas and Maggi, Federico and Zanero, Stefano and Keromytis, Angelos D.},
  booktitle   = {Proceedings of the 1st {Workshop} on {Building} {Analysis} {Datasets} and {Gathering} {Experience} {Returns} for {Security}},
  year        = {2014},
  address     = {Wroclaw, Poland},
  month       = sep,
  series      = {{BADGERS}},
  volume      = {(to appear)},
  kind        = {conference},
  timestamp   = {2014-09-11},
  paper       = {yes}, 
}

@InProceedings{Polakis2014Faces_in,
  Paper       = {yes},
  title       = {Faces in the {Distorting} {Mirror}: {Revisiting} {Photo}-based {Social} {Authentication}},
  author      = {Polakis, Iasonas and Ilia, Panagiotis and Maggi, Federico and Lancini, Marco and Kontaxis, Georgios and Zanero, Stefano and Ioannidis, Sotiris and Keromytis, Angelos D.},
  booktitle   = {Proceedings of the 2014 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
  year        = {2014},
  address     = {New York, NY, USA},
  month       = nov,
  pages       = {501--512},
  publisher   = {ACM},
  series      = {{CCS}},
  abstract    = {In an effort to hinder attackers from compromising user accounts, Facebook launched a form of two-factor authentication called social authentication (SA), where users are required to identify photos of their friends to complete a log-in attempt. Recent research, however, demonstrated that attackers can bypass the mechanism by employing face recognition software. Here we demonstrate an alternative attack. that employs image comparison techniques to identify the SA photos within an offline collection of the users' photos. In this paper, we revisit the concept of SA and design a system with a novel photo selection and transformation process, which generates challenges that are robust against these attacks. The intuition behind our photo selection is to use photos. that fail software-based face recognition, while remaining recognizable to humans who are familiar with the depicted people. The photo transformation process. creates challenges in the form of photo collages, where faces are transformed so as to render image matching techniques ineffective. We experimentally confirm the robustness of our approach against three template. matching algorithms that solve 0.4\% of the challenges, while requiring four orders of magnitude more processing effort. Furthermore, when the transformations are applied, face detection software fails to detect even a single face. Our user studies confirm that users are able to identify their friends in over 99\% of the photos with faces unrecognizable by software, and can solve over 94{\textbackslash}\% of the challenges with transformed photos.},
  iSBN        = {978-1-4503-2957-6},
  doi         = {10.1145/2660267.2660317},
  kind        = {conference},
  timestamp   = {2014-11-03},
  paper       = {yes}, 
}

@InProceedings{Poeplau2014Execute_This!,
  Paper       = {yes},
  title       = {Execute {This}! {Analyzing} {Unsafe} and {Malicious} {Dynamic} {Code} {Loading} in {Android} {Applications}},
  author      = {Poeplau, Sebastian and Fratantonio, Yanick and Bianchi, Antonio and Kruegel, Christopher and Vigna, Giovanni},
  booktitle   = {Proceedings of the 21st Network and Distributed Systems Security Symposium},
  year        = {2014},
  address     = {San Diego, CA},
  month       = feb,
  series      = {NDSS},
  kind        = {conference},
  timestamp   = {2014-02-23},
  paper       = {yes}, 
}

@InProceedings{Platzer2014Skin_Sheriff,
  Paper       = {yes},
  title       = {Skin {Sheriff}: {A} {Machine} {Learning} {Solution} for {Detecting} {Explicit} {Images}},
  author      = {Platzer, Christian and Stuetz, Martin and Lindorfer, Martina},
  booktitle   = {Proceedings of the 2nd {International} {Workshop} on {Security} and {Forensics} in {Communication} {Systems}},
  year        = {2014},
  address     = {Kyoto, Japan},
  month       = jun,
  abstract    = {Digital forensics experts are increasingly confronted with investigating large amounts of data and judging if it contains digital contraband. In this paper, we present an adaptable solution for detecting nudity or pornography in color images. We combine a novel skin detection approach with machine learning techniques to alleviate manual image screening. We upgrade previous approaches by leveraging machine learning and introducing several novel methods to enhance detection rates.
Our nudity assessment uses skin detection and positioning of skin areas within a picture. Sizes, shapes and placements of detected skin regions as well as the total amount of skin in an image are used as features for a support vector machine that finally classifies the image as non-pornographic or pornographic. With a recall of 65.7\% and 6.4\% false positive rate, our approach outperforms the best reported detection approaches.},
  series      = {{ASIACCS}-{SFCS}},
  kind        = {conference},
  timestamp   = {2014-06-03},
  paper       = {yes}, 
}

@InProceedings{Onaolapo2014What_Happens,
  Paper       = {yes},
  title       = {What {Happens} {After} {You} {Are} {Pwnd}: {Understanding} {The} {Use} of {Leaked} {Webmail} {Credentials} {In} {The} {Wild}},
  author      = {Onaolapo, Jeremiah and Mariconti, Enrico and Stringhini, Gianluca},
  booktitle   = {Proceedings of the 2016 {ACM} {SIGCOMM} {Internet} {Measurement} {Conference}},
  year        = {2016},
  address     = {Santa Monica, CA},
  month       = nov,
  publisher   = {ACM},
  Abstract    = {What Happens After You Are Pwnd:
Understanding the Use of Leaked Webmail
Credentials in the Wild},
  series      = {IMC},
  kind        = {conference},
  timestamp   = {2014-11-14},
  paper       = {yes}, 
}

@InProceedings{Nikiforakis2014Stranger_Danger,
  title     = {Stranger {Danger}: {Exploring} the {Ecosystem} of {Ad}-based {URL} {Shortening} {Services}},
  author    = {Nikiforakis, Nick and Maggi, Federico and Stringhini, Gianluca and Rafique, Zubair and Joosen, Wouter and Kruegel, Christopher and Piessens, Frank and Vigna, Giovanni and Zanero, Stefano},
  booktitle = {Proceedings of the 23rd international conference on {World} {Wide} {Web}},
  year      = {2014},
  address   = {Seoul, Korea},
  month     = apr,
  pages     = {51--62},
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract  = {URL shortening services facilitate the need of exchanging long URLs using limited space, by creating compact URL aliases that redirect users to the original URLs when followed. Some of these services show advertisements (ads) to link-clicking users and pay a commission of their advertising earnings to link-shortening users. In this paper, we investigate the ecosystem of these increasingly popular ad-based URL shortening services. Even though traditional URL shortening services have been thoroughly investigated in previous research, we argue that, due to the monetary incentives and the presence of third-party advertising networks, ad-based URL shortening services and their users are exposed to more hazards than traditional shortening services. By analyzing the services themselves, the advertisers involved, and their users, we uncover a series of issues that are actively exploited by malicious advertisers and endanger the users. Moreover, next to documenting the ongoing abuse, we suggest a series of defense mechanisms that services and users can adopt to protect themselves.},
  iSBN      = {978-1-4503-2744-2},
  doi       = {10.1145/2566486.2567983},
  series    = {WWW},
  kind      = {conference},
  timestamp = {2014-05-19},
  paper     = {yes},
}

@InProceedings{Nikiforakis2013Cookieless_monster,
  Paper       = {yes},
  title       = {Cookieless monster: {Exploring} the ecosystem of web-based device fingerprinting},
  author      = {Nikiforakis, Nick and Kapravelos, Alexandros and Joosen, Wouter and Kruegel, Christopher and Piessens, Frank and Vigna, Giovanni},
  booktitle   = {Proceedings of the 34th {IEEE} {Symposium} on {Security} and {Privacy}},
  year        = {2013},
  month       = may,
  address     = {S. Francisco, CA},
  pages       = {541--555},
  publisher   = {IEEE},
  url         = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6547132},
  series      = {S&P},
  kind        = {conference},
  timestamp   = {2013-05-19},
  paper       = {yes}, 
}

@InProceedings{Nikiforakis2012You_are,
  Paper       = {yes},
  title       = {You are what you include: large-scale evaluation of remote javascript inclusions},
  author      = {Nikiforakis, Nick and Invernizzi, Luca and Kapravelos, Alexandros and Van Acker, Steven and Joosen, Wouter and Kruegel, Christopher and Piessens, Frank and Vigna, Giovanni},
  booktitle   = {{Proceedings of the 19th {Conference} on {Computer} and {Communication} {Security}}},
  year        = {2012},
  month       = feb,
  pages       = {736--747},
  publisher   = {ACM},
  series      = {CCS},
  kind        = {conference},
  timestamp   = {2012-02-27},
  paper       = {yes}, 
}

@InProceedings{Neuner2014Enter_Sandbox,
  title       = {Enter {Sandbox}: {Android} {Sandbox} {Comparison}},
  author      = {Neuner, Sebastian and Van Der Veen, Victor and Lindorfer, Martina and Huber, Markus and Merzdovnik, Georg and Mulazzani, Martin and Weippl, Edgar},
  booktitle   = {Proceedings of the 3rd {IEEE} {Mobile} {Security} {Technologies} {Workshop}},
  year        = {2014},
  address     = {San Jose, CA},
  month       = may,
  abstract    = {Expecting the shipment of 1 billion Android devices in 2017, cyber criminals have naturally extended their vicious activities towards Googles mobile operating system. With an estimated number of 700 new Android applications released every day, keeping control over malware is an increasingly challenging task. In recent years, a vast number of static and dynamic code analysis platforms for analyzing Android applications and making decision regarding their maliciousness have been introduced in academia and in the commercial world. These platforms differ heavily in terms of feature support and application properties being analyzed. In this paper, we give an overview of the state-of-the-art dynamic code analysis platforms for Android and evaluate their effectiveness with samples from known malware corpora as well as known Android bugs like Master Key. Our results indicate a low level of diversity in analysis platforms resulting from code reuse that leaves the evaluated systems vulnerable to evasion. Furthermore the Master Key bugs could be exploited by malware to hide malicious behavior from the sandboxes.},
  series      = {MoST},
  kind        = {conference},
  timestamp   = {2014-05-17},
  paper       = {yes}, 
}

@InProceedings{Neugschwandtner2016Runtime_Integrity,
  Paper       = {yes},
  title       = {Runtime {Integrity} {Checking} for {Exploit} {Mitigation} on {Lightweight} {Embedded} {Devices}},
  author      = {Neugschwandtner, Matthias and Mulliner, Collin and Robertson, William and Kirda, Engin},
  booktitle   = {Proceedings of the 9th {International} {Conference} on {Trust} \& {Trustworthy} {Computing}},
  year        = {2016},
  month       = aug,
  abstract    = {Entering the age of the Internet of things, embedded devices are everywhere. They are built using common hardware such as RISC-based ARM and MIPS platforms, and lightweight open software components. Because of their limited resources, such systems often lack the protection mechanisms that have been introduced to the desktop and server world. In this paper, we present BINtegrity, a novel approach for exploit mitigation that is specifically tailored towards embedded systems that are based on the common RISC architecture. BINtegrity leverages architectural features of RISC CPUs to extract a combination of static and dynamic properties relevant to OS service requests from executables, and enforces them during runtime. Our technique borrows ideas from several areas including system call monitoring, static analysis, and code emulation, and combines them in a low-overhead fashion directly in the operating system kernel. We implemented BINtegrity for the Linux operating system. BINtegrity is practical, and restricts the ability of attackers to exploit generic memory corruption vulner- abilities in COTS binaries. In contrast to other approaches, BINtegrity does not require access to source code, binary modification, or application specific configuration such as policies. Our evaluation demonstrates that BINtegrity incurs a very low overhead  only 2\%,  and shows that our approach mitigates both code injection and code reuse attacks.},
  series      = {TRUST},
  kind        = {conference},
  timestamp   = {2016-08-29},
  paper       = {yes}, 
}

@InProceedings{Neugschwandtner2011Detecting_Malware,
  Paper       = {yes},
  title       = {Detecting {Malware}'s {Failover} {C}\&{C} {Strategies} with {SQUEEZE}},
  author      = {Neugschwandtner, Matthias and Milani Comparetti, Paolo and Platzer, Christian},
  booktitle   = {{Proceedings of the 27th Annual Computer Security Applications Conference}},
  year        = {2011},
  month       = dec,
  abstract    = {The ability to remote-control infected PCs is a fundamental component of modern malware campaigns. At the same time, the command and control (C\&C) infrastructure that provides this capability is an attractive target for mitigation. In recent years, more or less successful takedown operations have been conducted against botnets employing both client-server and peer-to-peer C\&C architectures. To improve their robustness against such disruptions of their illegal business, botnet operators routinely deploy redundant C\&C infrastructure and implement failover C\&C strategies.
In this paper, we propose techniques based on multi-path exploration to discover how malware behaves when faced with the simulated take-down of some of the network endpoints it communicates with. We implement these techniques in a tool called SQUEEZE, and show that it allows us to detect backup C\&C servers, increasing the coverage of an automatically generated C\&C blacklist by 19.7\%, and can trigger domain generation algorithms that malware implements for disaster-recovery.},
  series      = {ACSAC},
  kind        = {conference},
  timestamp   = {2011-12-05},
  paper       = {yes}, 
}

@InProceedings{Neugschwandtner2011ForeCast_-,
  title       = {{ForeCast} - {Skimming} off the {Malware} {Cream}},
  author      = {Neugschwandtner, Matthias and Milani Comparetti, Paolo and Jacob, Gregoire and Kruegel, Christopher},
  booktitle   = {{Proceedings of the 27th Annual Computer Security Applications Conference}},
  year        = {2011},
  month       = dec,
  abstract    = {To handle the large number of malware samples appearing in the wild each day, security analysts and vendors employ automated tools to detect, classify and analyze malicious code. Because malware is typically resistant to static analysis, automated dynamic analysis is widely used for this purpose. Executing malicious software in a controlled environment while observing its behavior can provide rich information on a malwares capabilities. However, running each malware sample even for a few minutes is expensive. For this reason, malware analysis efforts need to select a subset of samples for analysis. To date, this selection has been performed either randomly or using techniques focused on avoiding re-analysis of polymorphic malware variants.
In this paper, we present a novel approach to sample selection that attempts to maximize the total value of the information obtained from analysis, according to an application-dependent scoring function. To this end, we leverage previous work on behavioral malware clustering and introduce a machine-learning-based system that uses all statically-available information to predict into which behavioral class a sample will fall, before the sample is actually executed. We discuss scoring functions tailored at two prac- tical applications of large-scale dynamic analysis: the compilation of network blacklists of command and control servers and the gen- eration of remediation procedures for malware infections. We implement these techniques in a tool called FORECAST. Large-scale evaluation on over 600,000 malware samples shows that our prototype can increase the amount of potential command and control servers detected by up to 137\% over a random selection strategy and 54\% over a selection strategy based on sample diversity.},
  series      = {ACSAC},
  kind        = {conference},
  timestamp   = {2011-12-05},
  paper       = {yes}, 
}

@InProceedings{Neugschwandtner2015The_BORG,
  title       = {The {BORG}: {Nanoprobing} {Binaries} for {Buffer} {Overreads}},
  author      = {Neugschwandtner, Matthias and Milani Comparetti, Paolo and Haller, Istvan and Bos, Herbert},
  booktitle   = {Proceedings of the 5th {ACM} {Conference} on {Data} and {Application} {Security} and {Privacy}},
  year        = {2015},
  month       = mar,
  abstract    = {Automated program testing tools typically try to explore, and cover, as much of a tested program as possible, while attempting to trigger and detect bugs. An alternative and complementary approach can be to first select a specific part of a program that may be subject to a specific class of bug, and then narrowly focus exploration towards program paths that could trigger such a bug.
In this work, we introduce the BORG (Buffer Over-Read Guard), a testing tool that uses static and dynamic program analysis, taint propagation and symbolic execution to detect buffer overread bugs in real-world programs. BORG works by first selecting buffer accesses that could lead to an overread and then guiding symbolic execution towards those accesses along program paths that could actually lead to an overread. BORG operates on binaries and does not require source code. To demonstrate BORGs effectiveness, we use it to detect overreads in six complex server applications and libraries, including lighttpd, FFmpeg and ClamAV.},
  series      = {CODASPY},
  kind        = {conference},
  timestamp   = {2015-03-02},
  paper       = {yes}, 
}

@InProceedings{Neugschwandtner2013A_View,
  title       = {A {View} {To} {A} {Kill}: {WebView} {Exploitation}},
  author      = {Neugschwandtner, Matthias and Lindorfer, Martina and Platzer, Christian},
  booktitle   = {Proceedings of the 6th {USENIX} {Workshop} on {Large}-{Scale} {Exploits} and {Emergent} {Threats}},
  year        = {2013},
  address     = {Washington, D.C.},
  month       = aug,
  abstract    = {WebView is a technique to mingle web and native applications for mobile devices. The fact that its main incentive requires making data stored on, as well as the functionality of mobile devices, directly accessible to active web content, is not without consequences to security.
In this paper, we present a threat scenario that targets WebView apps and show its practical applicability in a case study of selected apps. We further show results of our examination of over 287,000 apps in regard to WebView-related vulnerabilities.},
  series      = {LEET},
  kind        = {conference},
  timestamp   = {2013-08-12},
  paper       = {yes}, 
}

@Article{Nacci2013Adaptive_and,
  Paper       = {yes},
  title       = {Adaptive and {Flexible} {Smartphone} {Power} {Modeling}},
  author      = {Nacci, Alessandro and Trov, Francesco and Maggi, Federico and Ferroni, Matteo and Cazzola, Andrea and Sciuto, Donatella and Santambrogio, Marco},
  journal     = {Mobile Networks and Applications},
  year        = {2013},
  month       = oct,
  pages       = {1--10},
  abstract    = {Mobile devices have become the main interaction mean between users and the surrounding environment. An indirect measure of this trend is the increasing amount of security threats against mobile devices, which in turn created a demand for protection tools. Protection tools, unfortunately, add an additional burden for the smartphone's battery power, which is a precious resource. This observation motivates the need for smarter (security) applications, designed and capable of running within adaptive energy goals. Although this problem affects other areas, in the security area this research direction is referred to as "green security". In general, a fundamental need to the researches toward creating energy-aware applications, consist in having appropriate power models that capture the full dynamic of devices and users. This is not an easy task because of the highly dynamic environment and usage habits. In practice, this goal requires easy mechanisms to measure the power consumption and approaches to create accurate models. The existing approaches that tackle this problem are either not accurate or not applicable in practice due to their limiting requirements. We propose MPower, a power-sensing platform and adaptive power modeling platform for Android mobile devices. The MPower approach creates an adequate and precise knowledge base of the power "behavior" of several different devices and users, which allows us to create better device-centric power models that considers the main hardware components and how they contributed to the overall power consumption. In this paper we consolidate our perspective work on MPower by providing the implementation details and evaluation on 278 users and about 22.5 million power-related data. Also, we explain how MPower is useful in those scenarios where low-power, unobtrusive, accurate power modeling is necessary (e.g., green security applications).},
  iSSN        = {1383-469X},
  kind        = {journal},
  timestamp   = {2013-10-01},
  paper       = {yes}, 
}

@InProceedings{Mutz2007Exploiting_Execution,
  Paper       = {yes},
  title       = {Exploiting {Execution} {Context} for the {Detection} of {Anomalous} {System} {Calls}},
  author      = {Mutz, Darren and Robertson, William and Vigna, Giovanni and Kemmerer, Richard},
  booktitle   = {Proceedings of the 10th {International} {Symposium} on {Recent} {Advances} in {Intrusion} {Detection}},
  year        = {2007},
  address     = {Gold Coast, Australia},
  month       = sep,
  pages       = {1--20},
  series      = {RAID},
  kind        = {conference},
  timestamp   = {2007-09-07},
  paper       = {yes}, 
}

@InProceedings{Mutz2003An_Experience,
  title       = {An {Experience} {Developing} an {IDS} {Stimulator} for the {Black}-{Box} {Testing} of {Network} {Intrusion} {Detection} {Systems}},
  author      = {Mutz, Darren and Vigna, Giovanni and Kemmerer, Richard},
  booktitle   = {{Proceedings of the 19th Annual Computer Security Applications Conference}},
  year        = {2003},
  address     = {Las Vegas, Nevada},
  month       = dec,
  pages       = {374--383},
  series      = {ACSAC},
  kind        = {conference},
  timestamp   = {2003-12-08},
  paper       = {yes}, 
}


@InProceedings{Murdoch2016Are_Payment,
  title       = {Are {Payment} {Card} {Contracts} {Unfair}?},
  author      = {Murdoch, Steven J. and Becker, Ingolf and Abu-Salma, Ruba and Anderson, Ross and Bohm, Nicholas and Hutchings, Alice and Sasse, M. Angela and Stringhini, Gianluca},
  booktitle   = {Financial {Cryptography} and {Data} {Security}},
  year        = {2016},
  address     = {Barbados},
  month       = feb,
  publisher   = {Springer},
  abstract    = {Fraud victims are often refused a refund by their bank on the
grounds that they failed to comply with their banks terms and conditions
about PIN safety. We, therefore, conducted a survey of how many PINs
people have, and how they manage them. We found that while only a
third of PINs are ever changed, almost half of bank customers write at
least one PIN down. We also found bank conditions that are too vague
to test, or even contradictory on whether PINs could be shared across
cards. Yet, some hazardous practices are not forbidden by many banks: of
the 22.9\% who re-use PINs across devices, half also use their bank PINs
on their mobile phones. We conclude that many bank contracts fail a
simple test of reasonableness, and strong authentication, as required by
the Payment Services Directive II, should include usability testing.},
  series      = {FC},
  kind        = {conference},
  timestamp   = {2016-02-22},
  paper       = {yes}, 
}

@InProceedings{Mulliner2006Vulnerability_Analysis,
  Paper       = {yes},
  title       = {Vulnerability {Analysis} of {MMS} {User} {Agents}},
  author      = {Mulliner, Collin and Vigna, Giovanni},
  booktitle   = {{Proceedings of the 22th Annual Computer Security Applications Conference}},
  year        = {2006},
  address     = {Miami, FL},
  month       = dec,
  series      = {ACSAC},
  kind        = {conference},
  timestamp   = {2006-12-11},
  paper       = {yes}, 
}

@InProceedings{Mittal2002Sensor-Based_Intrusion,
  title       = {Sensor-{Based} {Intrusion} {Detection} for {Intra}-{Domain} {Distance}-{Vector} {Routing}},
  author      = {Mittal, Vishal and Vigna, Giovanni},
  booktitle   = {Proceedings of the 9th {Conference} on {Computer} and {Communication} {Security}},
  year        = {2002},
  address     = {Washington, DC},
  month       = nov,
  pages       = {127--137},
  publisher   = {ACM Press},
  series      = {CCS},
  kind        = {conference},
  timestamp   = {2002-11-18},
  paper       = {yes}, 
}

@Article{McDaniel2007EVEREST_Evaluation,
  title       = {{EVEREST}: {Evaluation} and {Validation} of {Election}-{Related} {Equipment}, {Standards} and {Testing}},
  journal     = {EVEREST voting system},
  author      = {McDaniel, Patrik and Blaze, Matt and Vigna, Giovanni},
  year        = {2007},
  month       = dec,
  kind        = {journal},
  timestamp   = {2007-12-07},
  paper       = {yes}, 
}

@InProceedings{Mariconti2017MaMaDroid_Detecting,
  title       = {{MaMaDroid}: {Detecting} {Android} {Malware} by {Building} {Markov} {Chains} of {Behavioral} {Models}},
  author      = {Mariconti, Enrico and Onwuzurike, Lucky and Andriotis, Panagiotis and De Cristofaro, Emiliano and Ross, Gordon and Stringhini, Gianluca},
  booktitle   = {Proceedings of the 24th Network and Distributed Systems Security Symposium},
  year        = {2017},
  address     = {San Diego, CA},
  abstract    = {The rise in popularity of the Android platform
has resulted in an explosion of malware threats targeting it. As
both Android malware and the operating system itself constantly
evolve, it is very challenging to design robust malware mitigation
techniques that can operate for long periods of time without
the need for modifications or costly re-training. In this paper,
we present MAMADROID, an Android malware detection system
that relies on app behavior. MAMADROID builds a behavioral
model, in the form of a Markov chain, from the sequence of
abstracted API calls performed by an app, and uses it to extract
features and perform classification. By abstracting calls to their
packages or families, MAMADROID maintains resilience to API
changes and keeps the feature set size manageable. We evaluate
its accuracy on a dataset of 8.5K benign and 35.5K malicious
apps collected over a period of six years, showing that it not
only effectively detects malware (with up to 99\% F-measure),
but also that the model built by the system keeps its detection
capabilities for long periods of time (on average, 86\% and 75\%
F-measure, respectively, one and two years after training). Finally,
we compare against DROIDAPIMINER, a state-of-the-art system
that relies on the frequency of API calls performed by apps,
showing that MAMADROID significantly outperforms it.},
  series      = {NDSS},
  kind        = {conference},
  timestamp   = {2017-02-26},
  paper       = {yes}, 
}

@InProceedings{Mariconti2016Whats_Your,
  Paper       = {yes},
  title       = {What's Your Major Threat? {On} The Differences Between the Network Behavior of Targeted and Commodity Malware},
  author      = {Mariconti, Enrico and Onaolapo, Jeremiah and Ross, Gordon and Stringhini, Gianluca},
  booktitle   = {Proceedings of the 1st International {Workshop} on {Malware} {Analysis}},
  year        = {2016},
  address     = {Salzburg},
  month       = sep,
  abstract    = {This work uses statistical classification techniques
to learn about the different network behavior patterns demonstrated
by targeted malware and generic malware. Targeted
malware is a recent type of threat, involving bespoke software
that has been created to target a specific victim. It is considered a
more dangerous threat than generic malware, because a targeted
attack can cause more serious damage to the victim. Our work
aims to automatically distinguish between the network activity
generated by the two types of malware, which then allows samples
of malware to be classified as being either targeted or generic.
For a network administrator, such knowledge can be important
because it assists to understand which threats require particular
attention. Because a network administrator usually manages
more than an alarm simultaneously, the aim of the work is
particularly relevant. We set up a sandbox and infected virtual
machines with malware, recording all resulting malware activity
on the network. Using the network packets produced by the
malware samples, we extract features to classify their behavior.
Before performing classification, we carefully analyze the features
and the dataset to study all their details and gain a deeper
understanding of the malware under study. Our use of statistical
classifiers is shown to give excellent results in some cases, where
we achieved an accuracy of almost 96\% in distinguishing between
the two types of malware. We can conclude that the network
behaviors of the two types of malicious code are very different.},
  url         = {http://www0.cs.ucl.ac.uk/staff/G.Stringhini/papers/targeted-wma2016.pdf},
  series      = {WMA},
  kind        = {conference},
  timestamp   = {2016-08-31},
  paper       = {yes}, 
}

@InProceedings{Mariconti2016Why_Allowing,
  title       = {Why {Allowing} {Profile} {Name} {Reuse} {Is} {A} {Bad} {Idea}},
  author      = {Mariconti, Enrico and Onaolapo, Jeremiah and Ahmad, Syed Sharique and Nikiforou, Nicolas and Egele, Manuel and Nikiforakis, Nick and Stringhini, Gianluca},
  booktitle   = {Proceedings of the 9th European {Workshop} on {System} {Security}},
  year        = {2016},
  address     = {London},
  month       = apr,
  publisher   = {ACM},
  abstract    = {Twitter allows their users to change profile name at their
discretion. Unfortunately, this design decision can be used
by attackers to effortlessly hijack user names of popular accounts.
We call this practice profile name squatting. In
this paper, we investigate this name squatting phenomenon,
and show how this can be used to mount impersonation attacks
and attract a larger number of victims to potentially
malicious content. We observe that malicious users are already
performing this attack on Twitter and measure its
prevalence. We provide insights into the characteristics of
such malicious users, and argue that these problems could
be solved if the social network never released old user names
for others to use.},
  series      = {EUROSEC},
  kind        = {conference},
  timestamp   = {2016-04-18},
  paper       = {yes}, 
}

@InProceedings{Mariconti2017Whats_in,
  Paper       = {yes},
  title       = {What's in a {Name}? {Understanding} {Profile} {Name} {Reuse} on {Twitter}},
  author      = {Mariconti, Enrico and Onaolapo, Jeremiah and Ahmad, Syed Sharique and Nikiforou, Nicolas and Egele, Manuel and Nikiforakis, Nick and Stringhini, Gianluca},
  booktitle   = {Proceedings of the 26th international conference on {World} {Wide} {Web}},
  year        = {2017},
  address     = {Perth, Australia},
  month       = apr,
  publisher   = {ACM},
  abstract    = {Users on Twitter are commonly identified by their profile
names. These names are used when directly addressing users
on Twitter, are part of their profile page URLs, and can become
a trademark for popular accounts, with people referring
to celebrities by their real name and their profile name,
interchangeably. Twitter, however, has chosen to not permanently
link profile names to their corresponding user accounts.
In fact, Twitter allows users to change their profile
name, and afterwards makes the old profile names available
for other users to take.
In this paper, we provide a large-scale study of the phenomenon
of profile name reuse on Twitter. We show that
this phenomenon is not uncommon, investigate the dynamics
of profile name reuse, and characterize the accounts that
are involved in it. We find that many of these accounts adopt
abandoned profile names for questionable purposes, such as
spreading malicious content, and using the profile names
popularity for search engine optimization. Finally, we show
that this problem is not unique to Twitter (as other popular
online social networks also release profile names) and argue
that the risks involved with profile-name reuse outnumber
the advantages provided by this feature.},
  series      = {WWW},
  kind        = {conference},
  timestamp   = {2017-04-07},
  paper       = {yes}, 
}

@InProceedings{Maio2014PExy_The,
  title     = {{PExy}: {The} {Other} {Side} of {Exploit} {Kits}},
  author    = {Maio, Giancarlo De and Kapravelos, Alexandros and Shoshitaishvili, Yan and Kruegel, Christopher and Vigna, Giovanni},
  booktitle = {Proceedings of the 15th Detection of {Intrusions} and {Malware}, and {Vulnerability} {Assessment}},
  year      = {2014},
  month     = jul,
  doi       = {10.1007/978-3-319-08509-8_8},
  pages     = {132--151},
  publisher = {Springer International Publishing},
  series    = {DIMVA},
  abstract  = {The drive-by download scene has changed dramatically in the last few years. What was a disorganized ad-hoc generation of malicious pages by individuals has evolved into sophisticated, easily extensible frameworks that incorporate multiple exploits at the same time and are highly configurable. We are now dealing with exploit kits. In this paper we focus on the server-side part of drive-by downloads by automatically analyzing the source code of multiple exploit kits. We discover through static analysis what checks exploit-kit authors perform on the server to decide which exploit is served to which client and we automatically generate the configurations to extract all possible exploits from every exploit kit. We also examine the source code of exploit kits and look for interesting coding practices, their detection mitigation techniques, the similarities between them and the rise of Exploit-as-a-Service through a highly customizable design. Our results indicate that even with a perfect drive-by download analyzer it is not trivial to trigger the expected behavior from an exploit kit so that it is classified appropriately as malicious.},
  copyright = {2014 Springer International Publishing Switzerland},
  iSBN      = {978-3-319-08508-1 978-3-319-08509-8},
  language  = {en},
  url       = {http://link.springer.com/chapter/10.1007/978-3-319-08509-8_8},
  kind      = {conference},
  timestamp = {2014-07-10},
  paper     = {yes},
}

@Article{Maggi2008Seeing_the,
  title       = {Seeing the invisible: forensic uses of anomaly detection and machine learning},
  author      = {Maggi, Federico and Zanero, Stefano and Iozzo, Vincenzo},
  journal     = {Operating Systems Review of the ACM Special Interest Group on Operating Systems},
  year        = {2008},
  month       = apr,
  number      = {3},
  pages       = {51--58},
  volume      = {42},
  abstract    = {Anti-forensics is the practice of circumventing classical forensics analysis procedures making them either unreliable or impossible. In this paper we propose the use of machine learning algorithms and anomaly detection to cope with a wide class of definitive anti-forensics techniques. We test the proposed system on a dataset we created through the implementation of an innovative technique of anti-forensics, and we show that our approach yields promising results in terms of detection.},
  iSSN        = {0163-5980},
  kind        = {journal},
  timestamp   = {2008-04-01},
  paper       = {yes}, 
}

@InProceedings{Maggi2007On_the,
  title       = {On the {Use} of {Different} {Statistical} {Tests} for {Alert} {Correlation} - {Short} {Paper}},
  author      = {Maggi, Federico and Zanero, Stefano},
  booktitle   = {Proceedings of the 10th {International} {Symposium} on {Recent} {Advances} in {Intrusion} {Detection}},
  year        = {2007},
  month       = sep,
  pages       = {167--177},
  abstract    = {In this paper we analyze the use of different types of statistical tests for the correlation of anomaly detection alerts. We show that the Granger Causality Test, one of the few proposals that can be extended to the anomaly detection domain, strongly depends on good choices of a parameter which proves to be both sensitive and difficult to estimate. We propose a different approach based on a set of simpler statistical tests, and we prove that our criteria work well on a simplified correlation task, without requiring complex configuration parameters.},
  series      = {RAID},
  kind        = {conference},
  timestamp   = {2007-09-07},
  paper       = {yes}, 
}

@InProceedings{Maggi2011System_Security,
  Paper       = {yes},
  title       = {System {Security} research at {Politecnico} di {Milano}},
  author      = {Maggi, Federico and Zanero, Stefano},
  booktitle   = {Proceedings of the 1st {SysSec} {Workshop}},
  year        = {2011},
  month       = jul,
  publisher   = {IEEE Computer Society},
  abstract    = {This paper summarizes the past, present and future lines of research in the systems security area pursued by the Performance Evaluation Lab of Politecnico di Milano. We describe our past research in the area of learning algorithms applied to intrusion detection, our current work in the area of malware analysis, and our future research outlook, oriented to the cloud, to mobile device security, and to cyber-physical systems.},
  series      = {SysSec},
  kind        = {conference},
  timestamp   = {2011-07-06},
  paper       = {yes}, 
}

@InProceedings{Maggi2011Is_the,
  Paper       = {yes},
  title       = {Is the future {Web} more insecure? {Distractions} and solutions of new-old security issues and measures},
  author      = {Maggi, Federico and Zanero, Stefano},
  booktitle   = {Proceedings of the 2nd {Worldwide} {Cybersecurity} {Summit}},
  year        = {2011},
  month       = jun,
  pages       = {1--9},
  publisher   = {EWI},
  abstract    = {The world of information and communication technology is experiencing changes that, regardless of some skepticism, are bringing to life the concept of utility computing. The nostalgics observed a parallel between the emerging paradigm of cloud computing and the traditional time-sharing era, depicting clouds as the modern reincarnation of mainframes available on a pay-per-use basis, and equipped with virtual, elastic, disks-as-a-service that replace the old physical disks with quotas. This comparison is fascinating, but more importantly, in our opinion, it prepares the ground for constructive critiques regarding the security of such a computing paradigm and, especially, one of its key components: web services. In this paper we discuss our position about the current countermeasures (e.g., intrusion detection systems, anti-malware), developed to mitigate well-known web security threats. By reasoning on said affinities, we focus on the simple case study of anomaly-based approaches, which are employed in many modern protection tools, not just in intrusion detectors. We illustrate our position by the means of a simple running example and show that attacks against injection vulnerabilities, a widespread menace that is easily recognizable with ordinary anomaly-based checks, can be difficult to detect if web services are protected as they were regular web applications. Along this line, we concentrate on a few, critical hypotheses that demand particular attention. Although in this emerging landscape only a minority of threats qualify as novel, they could be difficult to recognize with the current countermeasures and thus can expose web services to new attacks. We conclude by proposing simple modifications to the current countermeasures to cope with the aforesaid security issues.},
  iSBN        = {978-1-4577-1449-8},
  series      = {WCS},
  kind        = {conference},
  timestamp   = {2011-06-01},
  paper       = {yes}, 
}

@InProceedings{Maggi2011Integrated_Detection,
  Paper       = {yes},
  title       = {Integrated {Detection} of {Anomalous} {Behavior} of {Computer} {Infrastructures}},
  author      = {Maggi, Federico and Zanero, Stefano},
  booktitle   = {Proceedings of the 2012 {IEEE}/{IFIP} {Network} {Operations} and {Management} {Symposium}},
  year        = {2012},
  month       = apr,
  pages       = {866--871},
  publisher   = {IEEE},
  abstract    = {Our research concentrates on anomaly detection techniques, which have both industrial applications such as network monitoring and protection, as well as research applications such as software behavioral analysis or malware classification. During our doctoral research, we worked on anomaly detection from three different perspective, as a complex computer infrastructure has several weak spots that must be protected. We first focused on the operating system, central to any computer, to avoid malicious code to subvert its normal activity. Secondly, we concentrated on web applications, which are the main interface to modern computing: Because of their immense popularity, they have indeed become the most targeted entry point of intrusions. Last, we developed novel techniques with the aim of identifying related events (e.g., alerts reported by intrusion detection systems) to build new and more compact knowledge to detect malicious activity on large-scale systems. During our research we enhanced existing anomaly detection tools and also contributed with new ones. Such tools have been tested over different datasets, both synthetic data and real network traffic, and lead to interesting results that were accepted for publication at main security venues.},
  iSBN        = {978-1-4673-0269-2},
  series      = {NOMS},
  kind        = {conference},
  timestamp   = {2011-04-16},
  paper       = {yes}, 
}

@InProceedings{Maggi2011POSTER_Fast,
  title       = {{POSTER}: {Fast}, {Automatic} {iPhone} {Shoulder} {Surfing}},
  author      = {Maggi, Federico and Volpatto, Alberto and Gasparini, Simone and Boracchi, Giacomo and Zanero, Stefano},
  booktitle   = {Proceedings of the 18th {Conference} on {Computer} and {Communication} {Security}},
  year        = {2011},
  month       = oct,
  publisher   = {ACM},
  abstract    = {Touchscreen devices increase the risk of shoulder surfing to such an extent that attackers could steal sensitive information by simply following the victim and observe his or her portable device. We underline this concern by proposing an automatic shoulder surfing attack against modern touchscreen keyboards that display magnified keys in predictable positions. We demonstrate this attack against the Apple iPhonealthough it can work with other layouts and different devicesand show that it recognizes up to 97.07\% (91.03\% on average) of the keystrokes, with only 1.15\% of errors, at 37 to 51 keystrokes per minute: About eight times faster than a human analyzing a recorded video. Our attack accurately recovers the sequence of keystrokes input by the user. A previous attack, which targeted desktop scenarios and thus worked with very restrictive settings, is similar in spirit to ours. However, as it assumes that camera and target keyboard are both in fixed, perpendicular position, it cannot suite mobile settings, characterized by moving target and skewed, rotated viewpoints. Our attack, instead, requires no particular settings and even allows for natural movements of both target device and shoulder surfer's camera. In addition, our attack yields accurate output without any grammar or syntax checks, so that it can detect large context-free text or non-dictionary words.},
  series      = {CCS},
  kind        = {conference},
  timestamp   = {2011-10-17},
  paper       = {yes}, 
}

@InProceedings{Maggi2011Protecting_a,
  Paper       = {yes},
  title       = {Protecting a {Moving} {Target}: {Addressing} {Web} {Application} {Concept} {Drift}},
  author      = {Maggi, Federico and Robertson, William and Kruegel, Christopher and Vigna, Giovanni},
  booktitle   = {Proceedings of the 12th {International} {Symposium} on {Recent} {Advances} in {Intrusion} {Detection}},
  year        = {2009},
  month       = sep,
  abstract    = {Because of the ad hoc nature of web applications, intrusion detection systems that leverage machine learning techniques are particularly well-suited for protecting websites. The reason is that these systems are able to characterize the applications' normal behavior in an automated fashion. However, anomaly-based detectors for web applications suffer from false positives that are generated whenever the applications being protected change. These false positives need to be analyzed by the security officer who then has to interact with the web application developers to confirm that the reported alerts were indeed erroneous detections. In this paper, we propose a novel technique for the automatic detection of changes in web applications, which allows for the selective retraining of the affected anomaly detection models. We demonstrate that, by correctly identifying legitimate changes in web applications, we can reduce false positives and allow for the automated retraining of the anomaly models. We have evaluated our approach by analyzing a number of real-world applications. Our analysis shows that web applications indeed change substantially over time, and that our technique is able to effectively detect changes and automatically adapt the anomaly detection models to the new structure of the changed web applications.},
  series      = {RAID},
  kind        = {conference},
  timestamp   = {2011-09-23},
  paper       = {yes}, 
}

@InProceedings{Maggi2011A_Social-Engineering-centric,
  Paper       = {yes},
  title       = {A Social-Engineering-centric Data Collection Initiative to Study Phishing},
  author      = {Maggi, Federico and Sisto, Alessandro and Zanero, Stefano},
  booktitle   = {Proceedings of the 1st {Workshop} on {Building} {Analysis} {Datasets} and {Gathering} {Experience} {Returns} for {Security}},
  year        = {2011},
  address     = {New York, NY, USA},
  month       = apr,
  pages       = {107--108},
  publisher   = {ACM},
  abstract    = {Phishers nowadays rely on a variety of channels, ranging from old-fashioned emails to instant messages, social networks, and the phone system (with both calls and text messages), with the goal of reaching more victims. As a consequence, modern phishing became a multi-faceted, even more pervasive threat that is inherently more difficult to study than traditional, email-based phishing. This short paper describes the status of a data collection system we are developing to capture different aspects of phishing campaigns, with a particular focus on the emerging use of the voice channel. The general approach is to record inbound calls received on decoy phone lines, place outbound calls to the same caller identifiers (when available) and also to telephone numbers obtained from different sources. Specifically, our system analyzes instant messages (e.g., automated social engineering attempts) and suspicious emails (e.g., spam, phishing), and extracts telephone numbers, URLs and popular words from the content. In addition, users can voluntarily submit voice phishing (vishing) attempts through a public website. Extracted telephone numbers, URLs and popular words will be correlated to recognize campaigns by means of cross-channel relationships between messages.},
  iSBN        = {978-1-4503-0768-0},
  series      = {BADGERS},
  kind        = {conference},
  timestamp   = {2011-04-01},
  paper       = {yes}, 
}

@InProceedings{Maggi2011AndroTotal_A,
  Paper       = {yes},
  title       = {{AndroTotal}: {A} {Flexible}, {Scalable} {Toolbox} and {Service} for {Testing} {Mobile} {Malware} {Detectors}},
  author      = {Maggi, Federico and Valdi, Andrea and Zanero, Stefano},
  booktitle   = {Proceedings of the 3rd {ACM} {Workshop} on {Security} and {Privacy} in {Smartphones} \& {Mobile} {Devices}},
  year        = {2013},
  address     = {New York, NY, USA},
  pages       = {49--54},
  publisher   = {ACM},
  series      = {{SPSM}},
  abstract    = {Although there are controversial opinions regarding how large the mobile malware phenomenon is in terms of absolute numbers, hype aside, the amount of new Android malware variants is increasing. This trend is mainly due to the fact that, as it happened with traditional malware, the authors are striving to repackage, obfuscate, or otherwise transform the executable code of their malicious apps in order to evade mobile security apps. There are about 85 of these apps only on the official marketplace. However, it is not clear how effective they are. Indeed, the sandboxing mechanism of Android does not allow (security) apps to audit other apps. We present AndroTotal, a publicly available tool, malware repository and research framework that aims at mitigating the above challenges, and allow researchers to automatically scan Android apps against an arbitrary set of malware detectors. We implemented AndroTotal and released it to the research community in April 2013. So far, we collected 18,758 distinct submitted samples and received the attention of several research groups (1,000 distinct accounts), who integrated their malware-analysis services with ours.},
  iSBN        = {978-1-4503-2491-5},
  doi         = {10.1145/2516760.2516768},
  kind        = {conference},
  timestamp   = {2011-11-08},
  paper       = {yes}, 
}

@InProceedings{Maggi2011A_Fast,
  title       = {A {Fast} {Eavesdropping} {Attack} {Against} {Touchscreens}},
  author      = {Maggi, Federico and Volpatto, Alberto and Gasparini, Simone and Boracchi, Giacomo and Zanero, Stefano},
  booktitle   = {Proceedings of the 7th {International} {Conference} on {Information} {Assurance} and {Security}},
  year        = {2011},
  month       = dec,
  pages       = {320--325},
  abstract    = {The pervasiveness of mobile devices increases the risk of exposing sensitive information on the go. In this paper, we arise this concern by presenting an automatic attack against modern touchscreen keyboards. We demonstrate the attack against the Apple iPhone2010's most popular touchscreen devicealthough it can be adapted to other devices (e.g., Android) that employ similar key-magnifying keyboards. Our attack processes the stream of frames from a video camera (e.g., surveillance or portable camera) and recognizes keystrokes online, in a fraction of the time needed to perform the same task by direct observation or offline analysis of a recorded video, which can be unfeasible for large amount of data. Our attack detects, tracks, and rectifies the target touchscreen, thus following the device or camera's movements and eliminating possible perspective distortions and rotations In real-world settings, our attack can automatically recognize up to 97.07 percent of the keystrokes (91.03 on average), with 1.15 percent of errors (3.16 on average) at a speed ranging from 37 to 51 keystrokes per minute.},
  iSBN        = {978-1-4577-2154-0},
  series      = {IAS},
  kind        = {conference},
  timestamp   = {2011-10-20},
  paper       = {yes}, 
}

% rename paper
@Article{Maggi2008Detecting_Intrusions,
  Paper       = {yes},
  title       = {Detecting {Intrusions} through {System} {Call} {Sequence} and {Argument} {Analysis}},
  author      = {Maggi, Federico and Matteucci, Matteo and Zanero, Stefano},
  journal     = {IEEE Transactions on Dependable and Secure Computing (T},
  year        = {2008},
  month       = nov,
  number      = {4},
  pages       = {381--395},
  volume      = {7},
  abstract    = {We describe an unsupervised host-based intrusion detection system based on system calls arguments and sequences. We define a set of anomaly detection models for the individual parameters of the call. We then describe a clustering process which helps to better fit models to system call arguments, and creates inter-relations among different arguments of a system call. Finally, we add a behavioral Markov model in order to capture time correlations and abnormal behaviors. The whole system needs no prior knowledge input; it has a good signal to noise ratio, and it is also able to correctly contextualize alarms, giving the user more information to understand whether a true or false positive happened, and to detect variations over the entire execution flow, as opposed to punctual variations over individual instances.},
  ISSN        = {1545-5971},
  kind        = {journal},
  timestamp   = {2008-11-09},
  paper       = {yes}, 
}

% rename paper
@Article{Maggi2009Reducing_false,
  title       = {Reducing false positives in anomaly detectors through fuzzy alert aggregation},
  author      = {Maggi, Federico and Matteucci, Matteo and Zanero, Stefano},
  journal     = {Information Fusion},
  year        = {2009},
  month       = oct,
  number      = {4},
  pages       = {300--311},
  volume      = {10},
  abstract    = {In this paper we focus on the aggregation of IDS alerts, an important component of the alert fusion process. We exploit fuzzy measures and fuzzy sets to design simple and robust alert aggregation algorithms. Exploiting fuzzy sets, we are able to robustly state whether or not two alerts are close in time, dealing with noisy and delayed detections. A performance metric for the evaluation of fusion systems is also proposed. Finally, we evaluate the fusion method with alert streams from anomaly-based IDS.},
  ISSN        = {1566-2535},
  kind        = {journal},
  timestamp   = {2009-07-09},
  paper       = {yes}, 
}

% rename paper
@InProceedings{Maggi2013Two_years,
  Paper       = {yes},
  title       = {Two years of short {URLs} internet measurement: security threats and countermeasures},
  author      = {Maggi, Federico and Frossi, Alessandro and Zanero, Stefano and Stringhini, Gianluca and Stone-Gross, Brett and Kruegel, Christopher and Vigna, Giovanni},
  booktitle   = {Proceedings of the 22nd international conference on {World} {Wide} {Web}},
  year        = {2013},
  address     = {Republic and Canton of Geneva, Switzerland},
  month       = may,
  pages       = {861--872},
  publisher   = {International World Wide Web Conferences Steering Committee},
  abstract    = {URL shortening services have become extremely popular. However, it is still unclear whether they are an effective and reliable tool that can be leveraged to hide malicious URLs, and to what extent these abuses can impact the end users. With these questions in mind, we first analyzed existing countermeasures adopted by popular shortening services. Surprisingly, we found such countermeasures to be ineffective and trivial to bypass. This first measurement motivated us to proceed further with a large-scale collection of the HTTP interactions that originate when web users access live pages that contain short URLs. To this end, we monitored 622 distinct URL shortening services between March 2010 and April 2012, and collected 24,953,881 distinct short URLs. With this large dataset, we studied the abuse of short URLs. Despite short URLs are a significant, new security risk, in accordance with the reports resulting from the observation of the overall phishing and spamming activity, we found that only a relatively small fraction of users ever encountered malicious short URLs. Interestingly, during the second year of measurement, we noticed an increased percentage of short URLs being abused for drive-by download campaigns and a decreased percentage of short URLs being abused for spam campaigns. In addition to these security-related findings, our unique monitoring infrastructure and large dataset allowed us to complement previous research on short URLs and analyze these web services from the users perspective.},
  iSBN        = {978-1-4503-2035-1},
  series      = {www},
  kind        = {conference},
  timestamp   = {2013-05-13},
  paper       = {yes}, 
}

% rename paper
@InProceedings{Maggi2011Finding_Non-trivial,
  Paper       = {yes},
  title       = {Finding {Non}-trivial {Malware} {Naming} {Inconsistencies}},
  author      = {Maggi, Federico and Bellini, Andrea and Salvaneschi, Guido and Zanero, Stefano},
  booktitle   = {Proceedings of the 7th {International} {Conference} on {Information} {Systems} {Security}},
  year        = {2011},
  month       = dec,
  pages       = {144--159},
  publisher   = {Springer-Verlag},
  volume      = {7093},
  abstract    = {Malware analysts, and in particular antivirus vendors, never agreed on a single naming convention for malware specimens. This leads to confusion and difficultymore for researchers than for practitionersfor example, when comparing coverage of different antivirus engines, when integrating and systematizing known threats, or comparing the classifications given by different detectors. Clearly, solving naming inconsistencies is a very difficult task, as it requires that vendors agree on a unified naming convention. More importantly, solving inconsistencies is impossible without knowing exactly where they are. Therefore, in this paper we take a step back and concentrate on the problem of finding inconsistencies. To this end, we first represent each vendor's naming convention with a graph-based model. Second, we give a precise definition of inconsistency with respect to these models. Third, we define two quantitative measures to calculate the overall degree of inconsistency between vendors. In addition, we propose a fast algorithm that finds non-trivial (i.e., beyond syntactic differences) inconsistencies. Our experiments on four major antivirus vendors and 98,798 real-world malware samples confirm anecdotal observations that different vendors name viruses differently. More importantly, we were able to find inconsistencies that cannot be inferred at all by looking solely at the syntax.},
  series      = {ICISS},
  kind        = {conference},
  timestamp   = {2011-12-15},
  paper       = {yes}, 
}

% rename paper
@InProceedings{Maggi2014A_Recognizer,
  Paper       = {yes},
  title       = {A {Recognizer} of {Rational} {Trace} {Languages}},
  author      = {Maggi, Federico},
  booktitle   = {Proceedings of the 10th {International} {Conference} on {Computer} and {Information} {Technology}},
  year        = {2010},
  month       = jun,
  pages       = {257--264},
  publisher   = {IEEE Computer Society},
  abstract    = {A one-pass recognition algorithm is presented to solve the membership problem for rational trace languages. The algorithm is detailed through the formal specification of the Buffer Machine, a non-deterministic, finite-state automaton with multiple buffers that can solve the membership problem in polynomial time. The performances and characteristics of the proposed solution are evaluated on a testbed implementation using pseudo-random traces, strings, languages and dependency relations.},
  ISBN        = {978-0-7695-4108-2},
  series      = {CIT},
  kind        = {conference},
  timestamp   = {2014-06-29},
  paper       = {yes}, 
}

@InProceedings{Maggi2014Are_the,
  title       = {Are the {Con} {Artists} {Back}? {A} {Preliminary} {Analysis} of {Modern} {Phone} {Frauds}},
  author      = {Maggi, Federico},
  booktitle   = {Proceedings of the 10th {International} {Conference} on {Computer} and {Information} {Technology}},
  year        = {2010},
  month       = jun,
  pages       = {824--831},
  publisher   = {IEEE Computer Society},
  abstract    = {Phishing is the practice of eliciting a person's confidential information such as name, date of birth or credit card details. Typically, the phishers use simple technologies (e.g., e-mailing) to spread social engineering attacks with the goal of persuading a large amount of victims into voluntarily disclose sensitive data. Phishing based on e-mail and web technologies is certainly the most popular form. It has indeed received ample attention and some mitigation measures have been implemented. In this paper we describe our study on vishing (voice phishing), a form of phishing where the scammers exploit the phone channel to ask for sensitive information, rather than sending e-mails and cloning trustworthy websites. In some sense, the traditional ala-Mitnick phone scams are streamlined by attackers using techniques that are typical of modern, e-mail-based phishing. We detail our analysis of an embryonic, real-world database of vishing attacks reported by victims through a publicly-available web application that we build for this purpose. The vishing activity that we registered in our preliminary analysis is targeted against the U.S. customers. According to our samples, we analyzed to what extent the criminals rely on automated responders to streamline the vishing campaigns. In addition, we analyzed the content of the conversations and found that words such as credit, press (a key) or account are fairly popular. In addition, we describe the data collection infrastructure and motivate why gathering data about vishing is more difficult than for regular e-mail phishing.},
  ISBN        = {978-0-7695-4108-2},
  series      = {CIT},
  kind        = {conference},
  timestamp   = {2014-06-29},
  paper       = {yes}, 
}

%rename paper
@InProceedings{Lindorfer2014AndRadar_Fast,
  title       = {{AndRadar}: {Fast} {Discovery} of {Android} {Applications} in {Alternative} {Markets}},
  author      = {Lindorfer, Martina and Volanis, Stamatis and Sisto, Alessandro and Neugschwandtner, Matthias and Athanasopoulos, Elias and Maggi, Federico and Platzer, Christian and Zanero, Stefano and Ioannidis, Sotiris},
  booktitle   = {Detection of {Intrusions} and {Malware}, and {Vulnerability} {Assessment}},
  year        = {2014},
  month       = jul,
  pages       = {51--71},
  publisher   = {Springer International Publishing},
  series      = {Lecture {Notes} in {Computer} {Science}},
  abstract    = {Compared to traditional desktop software, Android applications are delivered through software repositories, commonly known as application markets. Other mobile platforms, such as Apple iOS and BlackBerry OS also use the marketplace model, but what is unique to Android is the existence of a plethora of alternative application markets. This complicates the task of detecting and tracking Android malware. Identifying a malicious application in one particular market is simply not enough, as many instances of this application may exist in other markets. To quantify this phenomenon, we exhaustively crawled 8 markets between June and November 2013. Our findings indicate that alternative markets host a large number of ad-aggressive apps, a non-negligible amount of malware, and some markets even allow authors to publish known malicious apps without prompt action. Motivated by these findings, we present AndRadar, a framework for discovering multiple instances of a malicious Android application in a set of alternative application markets. AndRadar scans a set of markets in parallel to discover similar applications. Each lookup takes no more than a few seconds, regardless of the size of the marketplace. Moreover, it is modular, and new markets can be transparently added once the search and download URLs are known. Using AndRadar we are able to achieve three goals. First, we can discover malicious applications in alternative markets, second, we can expose app distribution strategies used by malware developers, and third, we can monitor how different markets react to new malware. During a three-month evaluation period, AndRadar tracked over 20,000 apps and recorded more than 1,500 app deletions in 16 markets. Nearly 8\% of those deletions were related to apps that were hopping from market to market. The most established markets were able to react and delete new malware within tens of days from the malicious app publication date while other markets did not react at all.},
  copyright   = {2014 Springer International Publishing Switzerland},
  ISBN        = {978-3-319-08508-1 978-3-319-08509-8},
  language    = {en},
  url         = {http://link.springer.com/chapter/10.1007/978-3-319-08509-8_4},
  kind        = {conference},
  timestamp   = {2014-07-01},
  paper       = {no}, 
}

%rename paper
@InProceedings{Line2014Targeted_Attacks,
  Paper       = {yes},
  title       = {Targeted {Attacks} {Against} {Industrial} {Control} {Systems}: {Is} the {Power} {Industry} {Prepared}?},
  author      = {Line, Maria B. and Zand, Ali and Stringhini, Gianluca and Kemmerer, Richard},
  booktitle   = {Proceedings of the 2nd {Workshop} on {Smart} {Energy} {Grid} {Security}},
  year        = {2014},
  address     = {New York, NY, USA},
  pages       = {13--22},
  publisher   = {ACM},
  series      = {{SEGS}},
  abstract    = {Targeted cyber attacks are on the rise, and the power industry is an attractive target. Espionage and causing physical damage are likely goals of these targeted attacks. In the case of the power industry, the worst possible consequences are severe: large areas, including critical societal infrastructures, can suffer from power outages. In this paper, we try to measure the preparedness of the power industry against targeted attacks. To this end, we have studied well-known targeted attacks and created a taxonomy for them. Furthermore, we conduct a study, in which we interview six power distribution system operators (DSOs), to assess the level of cyber situation awareness among DSOs and to evaluate the efficiency and effectiveness of their currently deployed systems and practices for detecting and responding to targeted attacks. Our findings indicate that the power industry is very well prepared for traditional threats, such as physical attacks. However, cyber attacks, and especially sophisticated targeted attacks, where social engineering is one of the strategies used, have not been addressed appropriately so far. Finally, by understanding previous attacks and learning from them, we try to provide the industry with guidelines for improving their situation awareness and defense (both detection and response) capabilities.},
  ISBN        = {978-1-4503-3154-8},
  doi         = {10.1145/2667190.2667192},
  kind        = {conference},
  timestamp   = {2014-11-04},
  paper       = {no}, 
}

%rename paper
@InProceedings{Lindorfer2013POSTER_Cross-Platform,
  Paper       = {yes},
  title       = {{POSTER}: {Cross}-{Platform} {Malware}: {Write} {Once}, {Infect} {Everywhere}},
  author      = {Lindorfer, Martina and Neumayr, Matthias and Caballero, Juan and Platzer, Christian},
  booktitle   = {Proceedings of the 2013 {ACM} {Conference} on {Computer} and {Communications} {Security}},
  year        = {2013},
  address     = {Berlin, Germany},
  month       = nov,
  abstract    = {In this ongoing work we perform the first systematic investigation of cross-platform (X-platform) malware. As a first step, this paper presents an exploration into existing X-platform malware families and X-platform vulnerabilities used to distribute them. Our exploration shows that X-platform malware uses a wealth of methods to achieve portability. It also shows that exploits for X-platform vulnerabilities are X-platform indeed and readily available in commercial exploit kits, making them an inexpensive distribution vector for X-platform malware.},
  series      = {CCS},
  kind        = {conference},
  timestamp   = {2013-11-01},
  paper       = {yes}, 
}

%rename paper
@InProceedings{Lindorfer2014ANDRUBIS-_1,000,000,
  Paper       = {yes},
  title       = {{ANDRUBIS}- 1,000,000 {Apps} {Later}: {A} {View} on {Current} {Android} {Malware} {Behaviors}},
  author      = {Lindorfer, Martina and Neugschwandtner, Matthias and Weichselbaum, Lukas and Fratantonio, Yanick and van der Veen, Victor and Platzer, Christian},
  booktitle   = {Proceedings of the {International} {Workshop} on {Building} {Analysis} {Datasets} and {Gathering} {Experience} {Returns} for {Security}},
  year        = {2014},
  abstract    = {Android is the most popular smartphone operating system with a market share of 80\%, but as a consequence, also the platform most targeted by malware. To deal with the increasing number of malicious Android apps in the wild, malware analysts typically rely on analysis tools to extract characteristic information about an app in an automated fashion. While the importance of such tools has been addressed by the research community, the resulting prototypes remain limited in terms of analysis capabilities and availability. In this paper we present ANDRUBIS, a fully automated, publicly available and comprehensive analysis system for Android apps. ANDRUBIS combines static analysis with dynamic analysis on both Dalvik VM and system level, as well as several stimulation techniques to increase code coverage. With ANDRUBIS, we collected a dataset of over 1,000,000 Android apps, including 40 \% malicious apps. This dataset allows us to discuss trends in malware behavior observed from apps dating back as far as 2010, as well as to present insights gained from operating ANDRUBIS as a publicly available service for the past two years.},
  series      = {BADGERS},
  kind        = {conference},
  timestamp   = {2014-09-11},
  paper       = {yes}, 
}


% Rename paper 
@InProceedings{Lindorfer2012Lines_Of,
  Paper       = {yes},
  title       = {Lines Of Malicious Code: Insights Into The Malicious Software Industry},
  booktitle   = {{Proceedings of the 28th Annual Computer Security Applications Conference}},
  author      = {Lindorfer, Martina and Di Federico, Alessandro and Maggi, Federico and Comparetti, Paolo Milani and Zanero, Stefano},
  year        = {2012},
  month       = dec,
  abstract    = {Malicious software installed on infected computers is a fundamental component of online crime. Malware development thus plays an essential role in the underground economy of cyber-crime. Malware authors regularly update their software to defeat defenses or to support new or improved criminal business models. A large body of research has focused on detecting malware, defending against it and identifying its functionality. In addition to these goals, however, the analysis of malware can provide a glimpse into the software development industry that develops malicious code. In this work, we present techniques to observe the evolution of a malware family over time. First, we develop techniques to compare versions of malicious code and quantify their differences. Furthermore, we use behavior observed from dynamic analysis to assign semantics to binary code and to identify functional components within a malware binary. By combining these techniques, we are able to monitor the evolution of a malwares functional components. We implement these techniques in a system we call BEAGLE, and apply it to the observation of 16 malware strains over several months. The results of these experiments provide insight into the effort involved in updating malware code, and show that BEAGLE can identify changes to individual malware components.},
  series      = {ACSAC},
  kind        = {conference},
  timestamp   = {2012-12-07},
  paper       = {yes}, 
}

% Rename paper 
@InProceedings{Lindorfer2011Detecting_Environment-Sensitive,
  Paper       = {yes},
  title       = {Detecting {Environment}-{Sensitive} {Malware}},
  author      = {Lindorfer, Martina and Kolbitsch, Clemens and Milani Comparetti, Paolo},
  booktitle   = {Proceedings of the {International} {Symposium} on {Recent} {Advances} in {Intrusion} {Detection}},
  year        = {2011},
  month       = sep,
  abstract    =  {The execution of malware in an instrumented sandbox is a widespread approach for the analysis of malicious code, largely because it sidesteps the difficulties involved in the static analysis of obfuscated code. As malware analysis sandboxes increase in popularity, they are faced with the problem of malicious code detecting the instrumented environment to evade analysis. In the absence of an undetectable, fully transparent analysis sandbox, defense against sandbox evasion is mostly reactive: Sandbox developers and operators tweak their systems to thwart individual evasion techniques as they become aware of them, leading to a never-ending arms race.
The goal of this work is to automate one step of this fight: Screening malware samples for evasive behavior. Thus, we propose novel techniques for detecting malware samples that exhibit semantically different behavior across different analysis sandboxes. These techniques are compatible with any monitoring technology that can be used for dynamic analysis, and are completely agnostic to the way that malware achieves evasion. We implement the proposed techniques in a tool called Disarm, and demonstrate that it can accurately detect evasive malware, leading to the discovery of previously unknown evasion techniques.},
  series      = {RAID},
  kind        = {conference},
  timestamp   = {2011-09-20},
  paper       = {yes}, 
}

% Rename paper 
@InProceedings{Lindorfer2013Take_a,
  Paper       = {yes},
  title       = {Take a {Bite} - {Finding} the {Worm} in the {Apple}},
  author      = {Lindorfer, Martina and Miller, Bernhard and Neugschwandtner, Matthias and Platzer, Christian},
  booktitle   = {Proceedings of the {International} {Conference} on {Information}, {Communications} and {Signal} {Processing}},
  year        = {2013},
  address     = {Tainan, Taiwan},
  month       = dec,
  abstract    = {When it comes to security risks, especially malware, Mac OS X has the questionable reputation of being inherently safe. While there is a substantial body of research and implementations dealing with malware on Windows and, more recently, Android systems, Mac OS X has received little attention so far.
To amend this shortcoming, we built a Mac OS X based high-interaction honeypot and used it to evaluate over 6,000 blacklisted URLs to estimate how widespread malware for Mac OS X is today. We further built a dynamic analysis environment and analyzed 148 malicious samples to gain insight into the current state of Mac OS X malware. To the best of our knowledge, we are the first to tackle this task.},
  series      = {ICICS},
  kind        = {conference},
  timestamp   = {2013-11-20},
  paper       = {yes}, 
}


% Rename paper 
@InProceedings{Lindorfer2015Marvin_Efficient,
  Paper       = {yes},
  title       = {Marvin: {Efficient} and {Comprehensive} {Mobile} {App} {Classification} {Through} {Static} and {Dynamic} {Analysis}},
  author      = {Lindorfer, Martina and Neugschwandtner, Matthias and Platzer, Christian},
  booktitle   = {Proceedings of the {Annual} {International} {Computers}, {Software} \& {Applications} {Conference}},
  year        = {2015},
  address     = {Taichung, Taiwan},
  month       = jul,
  abstract    = {Android dominates the smartphone operating system market and consequently has attracted the attention of malware authors and researchers alike. Despite the considerable number of proposed malware analysis systems, comprehensive and practical malware analysis solutions are scarce and often short-lived. Systems relying on static analysis alone struggle with increasingly popular obfuscation and dynamic code loading techniques, while purely dynamic analysis systems are prone to analysis evasion.
We present MARVIN, a system that combines static with dynamic analysis and which leverages machine learning techniques to assess the risk associated with unknown Android apps in the form of a malice score. MARVIN performs static and dynamic analysis, both off-device, to represent properties and behavioral aspects of an app through a rich and comprehensive feature set. In our evaluation on the largest Android malware classification data set to date, comprised of over 135,000 Android apps and 15,000 malware samples, MARVIN correctly classifies 98.24\% of malicious apps with less than 0.04\% false positives. We further estimate the necessary retraining interval to maintain the detection performance and demonstrate the long-term practicality of our approach.},
  series      = {COMPSAC},
  kind        = {conference},
  timestamp   = {2015-07-01},
  paper       = {yes}, 
}

@InProceedings{Vigna2014Ten_Years,
  Paper       = {yes},
  author       = {Vigna, Giovanni and Borgolte, Kevin and Corbetta, Jacopo and Doup, Adam and Fratantonio, Yanick and Invernizzi, Luca and Kirat, Dhilung and Shoshitaishvili, Yan},
  title        = {{Ten Years of iCTF: The Good, The Bad, and The Ugly}},
  booktitle    = {{Proceedings of the 1st USENIX Summit on Gaming, Games and Gamification in Security Education}},
  year         = {2014},
  series       = {3GSE},
  month        = aug,
  organization = {USENIX},
  abstract     = {Security competitions have become a popular way to foster security education by creating a competitive environment in which participants go beyond the effort usually required in traditional security courses. Live security competitions (also called Capture The Flag, or CTF competitions) are particularly well-suited to support hands-on experience, as they usually have both an attack and a defense component. Unfortunately, because these competitions put several (possibly many) teams against one another, they are difficult to design, implement, and run. This paper presents a framework that is based on the lessons learned in running, for more than 10 years, the largest educational CTF in the world, called iCTF. The frameworks goal is to provide educational institutions and other organizations with the ability to run customizable CTF competitions.  The framework is open and leverages the security community for the creation of a corpus of educational security challenges.},
  kind         = {conference},
  timestamp    = {2014-08-18},
  paper        = {yes},
  video_url    = {https://www.youtube.com/watch?v=WHR0SFVKZkQ}
}

@InProceedings{Borgolte2013Delta_Automatic,
  author    = {Borgolte, Kevin and Kruegel, Christopher and Vigna, Giovanni},
  title     = {{Delta: Automatic Identification of Unknown Web-based Infection Campaigns}},
  booktitle = {{Proceedings of the 20th ACM Conference on Computer and Communications Security}},
  year      = {2013},
  series    = {CCS},
  month     = nov,
  publisher = {ACM},
  abstract  = {Identifying malicious web sites has become a major challenge in today's Internet.  Previous work focused on detecting if a web site is malicious by dynamically executing JavaScript in instrumented environments or by rendering web sites in client honeypots. Both techniques bear a significant evaluation overhead, since the analysis can take up to tens of seconds or even minutes per sample.

In this paper, we introduce a novel, purely static analysis approach, the Delta-system, that (i) extracts change-related features between two versions of the same website, (ii) uses a machine-learning algorithm to derive a model of web site changes, (iii) detects if a change was malicious or benign, (iv) identifies the underlying infection vector campaign based on clustering, and (iv) generates an identifying signature.

We demonstrate the effectiveness of the Delta-system by evaluating it on a dataset of over 26 million pairs of web sites by running next to a web crawler for a period of four months. Over this time span, the Delta-system successfully identified previously unknown infection campaigns.  Including a campaign that targeted installations of the Discuz!X Internet forum software by injecting infection vectors into these forums and redirecting forum readers to an installation of the Cool Exploit Kit.},
  timestamp = {2013-11-04},
  kind      = {conference},
  slides    = {yes},
  paper     = {yes},
}

@InProceedings{Hao2015Drops_for,
  Paper       = {yes},
  author    = {Hao, Shuang and Borgolte, Kevin and Nikiforakis, Nick and Stringhini, Gianluca and Egele, Manuel and Eubanks, Michael and Krebs, Brian and Vigna, Giovanni},
  title     = {{Drops for Stuff: An Analysis of Reshipping Mule Scams}},
  booktitle = {{Proceedings of the 22nd ACM Conference on Computer and Communications Security}},
  year      = {2015},
  series    = {CCS},
  month     = nov,
  publisher = {ACM},
  abstract  = {Credit card fraud has seen rampant increase in the past years, as customers use credit cards and similar financial instruments frequently.  Both online and brick-and-mortar outfits repeatedly fall victim to cybercriminals who siphon off credit card information in bulk. Despite the many and creative ways that attackers use to steal and trade credit card information, the stolen information can rarely be used to withdraw money directly, due to protection mechanisms such as PINs and cash advance limits. As such, cybercriminals have had to devise more advanced monetization schemes to work around the current restrictions.

One monetization scheme that has been steadily gaining traction are reshipping scams. In such scams, cybercriminals purchase high-value or highly-demanded products from online merchants using stolen payment instruments, and then ship the items to a credulous citizen. This person, who has been recruited by the scammer under the guise of "work-from-home" opportunities, then forwards the received products to the cybercriminals, most of whom are located overseas. Once the goods reach the cybercriminals, they are then resold on the black market for an illicit profit. Due to the intricacies of this kind of scam, it is exceedingly difficult to trace, stop, and return shipments, which is why reshipping scams have become a common means for miscreants to turn stolen credit cards into cash.

In this paper, we report on the first large-scale analysis of reshipping scams, based on information that we obtained from multiple reshipping scam websites. We provide insights into the underground economy behind reshipping scams, such as the relationships among the various actors involved, the market size of this kind of scam, and the associated operational churn. We find that there exist prolific reshipping scam operations, with one having shipped nearly 6,000 packages in just 9 months of operation, exceeding 7.3 million US dollars in yearly revenue, contributing to an overall reshipping scam revenue of an estimated 1.8 billion US dollars per year. Finally, we propose possible approaches to intervene and disrupt reshipping scam services.},
  timestamp = {2015-10-12},
  kind      = {conference},
  paper     = {yes},
  slides    = {yes}
}

@InProceedings{Fiebig2017Something_From,
  Paper       = {yes},
  author    = {Fiebig, Tobias and Borgolte, Kevin and Hao, Shuang and Kruegel, Christopher and Vigna, Giovanni},
  title     = {{Something From Nothing (There): Collecting Global IPv6 Datasets From DNS}},
  booktitle = {{Proceedings of the 18th Passive and Active Measurement Conference}},
  year      = {2017},
  series    = {PAM},
  month     = mar,
  abstract  = {Current large-scale IPv6 studies mostly rely on non-public datasets, as most public datasets are domain specific. For instance, traceroute-based datasets are biased toward network equipment. In this paper, we present a new methodology to collect IPv6 address datasets that does not require access to restricted network vantage points.  We collect a new dataset spanning more than 5.8 million IPv6 addresses by exploiting  DNS' denial of existence semantics (NXDOMAIN). This paper documents our efforts in obtaining new datasets of allocated IPv6 addresses, so others can avoid the obstacles we encountered.
},
  timestamp = {2017-03-30},
  kind      = {conference},
  paper     = {yes},
}

@Article{Bianchi2017Cyber_Grand,
  author    = {Bianchi, Antonio and Borgolte, Kevin and Corbetta, Jacopo and Disperati, Francesco and Dutcher, Andrew and Grosen, John and Grosen, Paul and Machiry, Aravind and Salls, Christopher and Shoshitaishvili, Yan and Stephens, Nick and Vigna, Giovanni and Wang, Ruoyu},
  title     = {Cyber Grand Shellphish},
  journal   = {Phrack},
  year      = {2017},
  volume    = {15},
  number    = {70},
  month     = jan,
  note      = {(Authors listed alphabetically)},
  url       = {http://phrack.org/papers/cyber_grand_shellphish.html},
  abstract  = {Hacking is often considered more than a skill. In popular culture, hackers are seen as wizards of sorts, artists with powers to access the inaccessible, or perform acts that seem impossible. Hacking, like art, has great people, who are recognized for their skills, but whose abilities cannot be captured or reproduced. In fact, a single great hacker in a team is better than a hundred mediocre ones, similar to as none of the paintings from a hundred mediocre artists can match a painting from van Gogh.

Vulnerability analysis is the science of capturing and reproducing what some hackers do. Vulnerability analysis studies how one can reason, in a principled way, about finding and exploiting vulnerabilities in all types of software or hardware. By developing algorithms and tools to help humans identify flaws in software, researchers "codify" the knowledge that hackers use, in an organic way, to analyze systems and find their flaws. The resulting tools can then be used at scale, and composed to create new analysis systems.

This scientific process has generated a number of useful tools, such as static analysis tools, fuzzers, and symbolic execution frameworks. However, these tools codify only a subset of the skills of a hacker, and they are still used only to augment the abilities of humans.

One approach to push the codification of what human hackers do, is to take the hackers out of the equation. This is precisely what the DARPA Cyber Grand Challenge was set out to do.

The DARPA Cyber Grand Challenge (CGC) was designed as a Capture The Flag (CTF) competition among autonomous systems without any humans being involved. During the competition, Cyber Reasoning Systems (CRSs) would find vulnerabilities in binaries, exploit them, and generate patches to protect them from attacks, without any human involvement at all.

The separation between human and machine is key, as it forces the participants to codify, in algorithms, the techniques used for both attack and defense. Although the competition was only a first step toward capturing the art of hacking, it was an important one: for the first time, completely autonomous systems were hacking one another with code, and not human intuition, driving the discovery of flaws in complex software systems.

Shellphish is a team that was founded by Professor Giovanni Vigna at UC Santa Barbara in 2005 to participate in the DEF CON CTF with his graduate students. Since then, Shellphish has evolved to include dozens of individuals (graduate students - now professors elsewhere, undergraduate students, visitors, their friends, etc.) who are somewhat connected by the Security Lab at UC Santa Barbara, but who are now spread all across the world. Nonetheless, Shellphish has never lost its "hackademic" background and its interest in the science behind hacking. Participation in many CTF competitions sparked novel research ideas, which, in addition to publications, resulted in tools, which, in turn, were put to good use during CTF competitions.

Given the academic focus of Shellphish, it is no surprise that the DARPA Cyber Grand Challenge seemed like a great opportunity to put the research carried out at the UC Santa Barbara SecLab to work. Unfortunately, when the call for participation for the funded track came out, the lab was (as usual) busy with a great number of research projects and research endeavors, and there were simply no cycles left to dedicate to this effort.  However, when the call for the qualification round that was open to anybody who wanted to throw their hat in the ring was announced, a group of dedicated students from the SecLab decided to participate, entering the competition as team Shellphish.

With only a few weeks to spare, the Shellphish team put together a prototype of a system that automatically identifies crashes in binaries using a novel composition of fuzzing and symbolic execution.  Unsurprisingly, the system was largely unstable and crashed more than the binaries it was supposed to crash.  Yet, it performed well and Shellphish was one of the seven teams (out of more than a hundred participants) that qualified for the final event. Since Shellphish was not initially funded by DARPA through the funded track, it received a $750,000 award to fund the creation of the autonomous system that would participate in the final competition.

The following few months focused mostly on basic research, which resulted in a number of interesting scientific results in the field of binary analysis [Driller16, ArtOfWar16], and to the dramatic improvement of angr [angr], an open-source framework created at the UC Santa Barbara SecLab to support the analysis of binaries.

Eventually, the pressure to create a fully autonomous system increased to the point that academic research had to be traded for system-building.  During the several months preceding the final competition event, all the energy of the Shellphish team focused on creating a solid system that could be resilient to failure, perform at scale, and be able not only to crash binaries, but also to generate reliable exploits and patches.

After gruesome months of Sushi-fueled work that lead to severe Circadian rhythm sleep disorder [Inversion] in many of the team's members, the Mechanical Phish Cyber Reasoning System was born. Mechanical Phish is a highly-available, distributed system that can identify flaws in DECREE binaries, generate exploits (called Proofs Of Vulnerability, or POVs), and patched binaries, without human intervention. In a way, Mechanical Phish represents a codification of some of the hacking skills of Shellphish.

Mechanical Phish participated in the final event, held in Las Vegas on August 4th, in conjunction with DEF CON, and placed third, winning a $750,000 prize. As a team, we were ecstatic: our system performed more successful exploits than any other CRS, and it was exploited on fewer challenges than any other CRS. Of course, in typical Shellphish style, the game strategy is where we lost points, but the technical aspects of our CRS were some of the best.

We decided to make our system completely open-source (at the time of writing, Shellphish is the only team that decided to do so), so that others can build upon and improve what we put together.

The rest of this article describes the design of our system, how it performed, and the many lessons learned in designing, implementing, and deploying Mechanical Phish.},
  timestamp = {2017-01-27},
  kind      = {journal},
  text      = {yes},
}

@InProceedings{Cao2014Protecting_Web,
  Paper       = {yes},
  author    = {Cao, Yinzhi and Shoshitaishvili, Yan and Borgolte, Kevin and Kruegel, Christopher and Vigna, Giovanni and Chen, Yan},
  title     = {{Protecting Web Single Sign-on against Relying Party Impersonation Attacks through a Bi-directional Secure Channel with Authentication}},
  booktitle = {{Proceedings of the 17th International Symposium on Research in Attacks, Intrusions and Defense}},
  year      = {2014},
  series    = {RAID},
  month     = sep,
  publisher = {Springer},
  abstract  = {Web-based single sign-on describes a class of protocols where a user signs into a web site with the authentication provided as a service by a third party. In exchange for the increased complexity of the authentication procedure, SSO makes it convenient for users to authenticate themselves to many different web sites (relying parties), using just a single account at an identity provider such as Facebook or Google.

Single sign-on (SSO) protocols, however, are not immune to vulnerabilities.  Recent research introduced several attacks against existing SSO protocols, and further work showed that these problems are prevalent: 6.5\% of the investigated relying parties were vulnerable to impersonation attacks, which can lead to account compromises and privacy breaches.  Prior work used formal verification methods to identify vulnerabilities in SSO protocols or leveraged invariances of SSO interaction traces to identify logic flaws. No prior work, however, systematically studied the actual root cause of impersonation attacks against the relying party.

In this paper, we systematically examine existing SSO protocols and determine the root cause of the aforementioned vulnerabilities: the design of the communication channel between the relying party and the identity provider, which, depending on the protocol and implementation, suffers from being a one-way communication protocol, or from a lack of authentication. We (a) systematically study the weakness responsible for the vulnerabilities in existing protocols that allow impersonation attacks against the relying party, (b) introduce a dedicated, authenticated, bi-directional, secure channel that does not suffer from those shortcomings, (c) formally verify the authentication property of this channel using a well-known cryptographic protocol verifier (ProVerif), and (d) evaluate the practicality of a prototype implementation of our protocol.

Ultimately, to support a smooth and painless transition from existing SSO protocols, we introduce a proxy setup in which our channel can be used to secure existing SSO protocols from impersonation attacks. Furthermore, to demonstrate the flexibility of our approach, we design two different SSO protocols: an OAuth-like and an OpenID-like protocol.},
  timestamp = {2014-09-17},
  kind      = {conference},
  slides    = {yes},
  paper     = {yes},
  video_url = {https://www.youtube.com/watch?v=mvUo1CIqFD4},
}

@Article{Payer2015What_You,
  Paper       = {yes},
  author    = {Payer, Mathias and Huang, Ling and Gong, Neil Zhenqiang and Borgolte, Kevin and Frank, Mario},
  title     = {{What You Submit is Who You Are: A Multi-Modal Approach for Deanonymizing Scientific Publications}},
  journal   = {{IEEE Transactions on Information Forensics and Security}},
  year      = {2015},
  volume    = {10},
  number    = {1},
  abstract  = {{The peer-review system of most academic conferences relies on the anonymity of both the authors and the reviewers of submissions. In particular with respect to the authors, the anonymity requirement is heavily disputed and pros and cons are discussed exclusively on a qualitative level.

In this paper, we contribute a quantitative argument to this discussion by showing that it is possible for a machine to reveal the identity of authors of scientific publications with high accuracy. We attack the anonymity of authors using statistical analysis of multiple heterogeneous aspects of a paper, such as its citations, its writing style, and its content. We apply several multi-label, multi-class machine learning methods to model the patterns exhibited in each feature category for individual authors and combine them to a single ensemble classifier to deanonymize authors with high accuracy. To the best of our knowledge, this is the first approach that exploits multiple categories of discriminative features and uses multiple, partially complementing classifiers in a single, focused attack on the anonymity of the authors of an academic publication.

We evaluate our author identification framework, deAnon, based on a real-world data set of 3,894 papers. From these papers, we target 1,405 productive authors that each have at least 3 publications in our data set. Our approach returns a ranking of probable authors for anonymous papers, an ordering for guessing the authors of a paper. In our experiments, following this ranking, the first guess corresponds to one of the authors of a paper in 39.7\% of the cases, and at least one of the authors is among the top 10 guesses in 65.6\% of all cases. Thus, deAnon significantly outperforms current state-of-the-art techniques for automatic deanonymization.}},
  timestamp = {2015-01-01},
  paper     = {yes},
  kind      = {journal},
}

@InProceedings{Borgolte2015Meerkat_Detecting,
  author    = {Borgolte, Kevin and Kruegel, Christopher and Vigna, Giovanni},
  title     = {{Meerkat: Detecting Website Defacements through Image-based Object Recognition}},
  booktitle = {{Proceedings of the 24th USENIX Security Symposium}},
  year      = {2015},
  series    = {USENIX Security},
  month     = aug,
  publisher = {USENIX},
  abstract  = {Website defacements and website vandalism can inflict significant harm on the website owner through the loss of sales, the loss in reputation, or because of legal ramifications.

Prior work on website defacements detection focused on detecting unauthorized changes to the web server, e.g., via host-based intrusion detection systems or file-based integrity checks. However, most prior approaches lack the capabilities to detect the most prevailing defacement techniques used today: code and/or data injection attacks, and DNS hijacking. This is because these attacks do not actually modify the code or configuration of the website, but instead they introduce new content or redirect the user to a different website.

In this paper, we approach the problem of defacement detection from a different angle: we use computer vision techniques to recognize if a website was defaced, similarly to how a human analyst decides if a website was defaced when viewing it in a web browser. We introduce MEERKAT, a defacement detection system that requires no prior knowledge about the websites content or its structure, but only its URL. Upon detection of a defacement, the system notifies the website operator that his website is defaced, who can then take appropriate action. To detect defacements, MEERKAT automatically learns high-level features from screenshots of defaced websites by combining recent advances in machine learning, like stacked autoencoders and deep neural networks, with techniques from computer vision. These features are then used to create models that allow for the detection of newly-defaced websites.

We show the practicality of MEERKAT on the largest website defacement dataset to date, comprising of 10,053,772 defacements observed between January 1998 and May 2014, and 2,554,905 legitimate websites. Overall, MEERKAT achieves true positive rates between 97.422\% and 98.816\%, false positive rates between 0.547\% and 1.528\%, and Bayesian detection rates (the likelihood that if we detect a website as defaced, it actually is defaced; P(true positive|positive)) between 98.583\% and 99.845\%, thus significantly outperforming existing approaches.},
  timestamp = {2015-08-13},
  paper     = {yes},
  slides    = {yes},
  kind      = {conference},
  aliases   = {usesec2015-meerkat}
}

@InProceedings{Borgolte2014Relevant_Change,
  author    = {Borgolte, Kevin and Kruegel, Christopher and Vigna, Giovanni},
  title     = {{Relevant Change Detection: A Framework for the Precise Extraction of Modified and Novel Web-based Content as a Filtering Technique for Analysis Engines}},
  booktitle = {{Proceedings of the 23rd International World Wide Web Conference Companion}},
  year      = {2014},
  series    = {WWW},
  month     = apr,
  publisher = {IW3C2},
  note      = {Developers Track},
  abstract  = {Tracking the evolution of websites has become fundamental to the understanding of todays Internet. The automatic reasoning of how and why websites change has become essential to developers and businesses alike, in particular because the manual reasoning has become impractical due to the sheer number of modifications that websites undergo during their operational lifetime, including but not limited to rotating advertisements, personalized content, insertion of new content, or removal of old content.

Prior work in the area of change detection, such as XyDiff, X-Diff or AT&Ts internet difference engine, focused mainly on diffing XML-encoded literary documents or XML-encoded databases. Only some previous work investigated the differences that must be taken into account to accurately extract the difference between HTML documents for which the markup language does not necessarily describe the content but is used to describe how the content is displayed instead.  Additionally, prior work identifies all changes to a website, even those that might not be relevant to the overall analysis goal, in turn, they unnecessarily burden the analysis engine with additional workload.

In this paper, we introduce a novel analysis framework, the Delta framework, that works by (i) extracting the modifications between two versions of the same website using a fuzzy tree difference algorithm, and (ii) using a machine-learning algorithm to derive a model of relevant website changes that can be used to cluster similar modifications to reduce the overall workload imposed on the analysis engine. Based on this model for example, the tracked content changes can be used to identify ongoing or even inactive web-based malware campaigns, or to automatically learn semantic translations of sentences or paragraphs by analyzing websites that are available in multiple languages.

In prior work, we showed the effectiveness of the Delta framework by applying it to the detection and automatic identification of web-based malware campaigns on a data set of over 26 million pairs of websites that were crawled over a time span of four months. During this time, the system based on our framework successfully identified previously unknown web-based malware campaigns, such as a targeted campaign infecting installations of the Discuz!X Internet forum software.},
  timestamp = {2014-04-09},
  paper     = {yes},
  kind      = {conference},
}

@InProceedings{Borgolte2018Cloud_Strife,
  Paper       = {yes},
  author    = {Borgolte, Kevin and Fiebig, Tobias and Hao, Shuang and Kruegel, Christopher and Vigna, Giovanni},
  title     = {{Cloud Strife: Mitigating the Security Risks of Domain-Validated Certificates}},
  booktitle = {{Proceedings of the 25th Network and Distributed Systems Security Symposium}},
  year      = {2018},
  series    = {NDSS},
  month     = feb,
  publisher = {ISOC},
  kind      = {conference},
  timestamp = {2018-02-18},
  abstract  = {Infrastructure-as-a-Service (IaaS), and more generally the "cloud," like Amazon Web Services (AWS) or Microsoft Azure, have changed the landscape of system operations on the Internet. Their elasticity allows operators to rapidly allocate and use resources as needed, from virtual machines, to storage, to bandwidth, and even to IP addresses, which is what made them popular and spurred innovation.

In this paper, we show that the dynamic component paired with recent developments in trust-based ecosystems (e.g., SSL certificates) creates so far unknown attack vectors. Specifically, we discover a substantial number of stale DNS records that point to available IP addresses in clouds, yet, are still actively attempted to be accessed. Often, these records belong to discontinued services that were previously hosted in the cloud. We demonstrate that it is practical, and time and cost efficient for attackers to allocate IP addresses to which stale DNS records point. Considering the ubiquity of domain validation in trust ecosystems, like SSL certificates, an attacker can impersonate the service using a valid certificate trusted by all major operating systems and browsers. The attacker can then also exploit residual trust in the domain name for phishing, receiving and sending emails, or possibly distribute code to clients that load remote code from the domain (e.g., loading of native code by mobile apps, or JavaScript libraries by websites).

Even worse, an aggressive attacker could execute the attack in less than 70 seconds, well below common time-to-live (TTL) for DNS records. In turn, it means an attacker could exploit normal service migrations in the cloud to obtain a valid SSL certificate for domains owned and managed by others, and, worse, that she might not actually be bound by DNS records being (temporarily) stale, but that she can exploit caching instead.

We introduce a new authentication method for trust-based domain validation that mitigates staleness issues without incurring additional certificate requester effort by incorporating existing trust of a name into the validation process. Furthermore, we provide recommendations for domain name owners and cloud operators to reduce their and their clients exposure to DNS staleness issues and the resulting domain takeover attacks.},
  paper = {yes},
  video_url = {https://www.youtube.com/watch?v=GTvDBuKGwag},
  aliases = {ndss2018-cloudstrife}
}

@InProceedings{Fiebig2018In_rDNS,
  Paper       = {yes},
  author    = {Fiebig, Tobias and Borgolte, Kevin and Hao, Shuang and Kruegel, Christopher and Vigna, Giovanni and Feldmann, Anja},
  title     = {{In rDNS We Trust: Revisiting a Common Data-Source's Reliability}},
  booktitle = {{Proceedings of the 19th Passive and Active Measurement Conference}},
  year      = {2018},
  series    = {PAM},
  month     = mar,
  kind      = {conference},
  timestamp = {2018-03-27},
  abstract = {Reverse DNS (rDNS) is regularly used as a data source in Internet measurement research.
  However, existing work is polarized on its reliability, and new techniques to collect active IPv6 datasets have not yet been sufficiently evaluated.
  In this paper, we investigate active and passive data collection and practical use aspects of rDNS datasets.
  We observe that the share of non-authoritatively answerable IPv4 rDNS queries reduced since earlier studies and IPv6 rDNS has less non-authoritatively answerable queries than IPv4 rDNS.
  Furthermore, we compare passively collected datasets with actively collected ones, and we show that they enable observing the same effects in rDNS data.
  While highlighting opportunities for future research, we find no immediate challenges to the use of rDNS as active and passive data-source for Internet measurement research.},
  paper = {yes}
}

@InProceedings{Borgolte2018Enumerating_Active,
  Paper       = {yes},
  author    = {Borgolte, Kevin and Hao, Shuang and Fiebig, Tobias and Vigna, Giovanni},
  title     = {{Enumerating Active IPv6 Hosts for Large-scale Security Scans via DNSSEC-signed Reverse Zones}},
  year      = {2018},
  series    = {S\&P},
  month     = may,
  booktitle = {{Proceedings of the 39th IEEE Symposium on Security \& Privacy}},
  kind      = {conference},
  timestamp = {2018-05-21},
  abstract  = {Security research has made extensive use of exhaustive Internet-wide scans over the recent years, as they can provide significant insights into the overall state of security of the Internet, and ZMap made scanning the entire IPv4 address space practical.
However, the IPv4 address space is exhausted, and a switch to IPv6, the only accepted long-term solution, is inevitable.
In turn, to better understand the security of devices connected to the Internet, including in particular Internet of Things devices, it is imperative to include IPv6 addresses in security evaluations and scans.
Unfortunately, it is practically infeasible to iterate through the entire IPv6 address space, as it is 2^96^ times larger than the IPv4 address space.
Therefore, enumeration of active hosts prior to scanning is necessary.
Without it, we will be unable to investigate the overall security of Internet-connected devices in the future.

In this paper, we introduce a novel technique to enumerate an active part of the IPv6 address space by walking DNSSEC-signed IPv6 reverse zones.
Subsequently, by scanning the enumerated addresses, we uncover significant security problems: the exposure of sensitive data, and incorrectly controlled access to hosts, such as access to routing infrastructure via administrative interfaces, all of which were accessible via IPv6.
Furthermore, from our analysis of the differences between accessing dual-stack hosts via IPv6 and IPv4, we hypothesize that the root cause is that machines automatically and by default take on globally routable IPv6 addresses.
This is a practice that the affected system administrators appear unaware of, as the respective services are almost always properly protected from unauthorized access via IPv4.

Our findings indicate (i) that enumerating active IPv6 hosts is practical without a preferential network position contrary to common belief, (ii) that the security of active IPv6 hosts is currently still lagging behind the security state of IPv4 hosts, and (iii) that unintended IPv6 connectivity is a major security issue for unaware system administrators.},
  paper     = {yes},
  video_url = {https://www.youtube.com/watch?v=YpaaZla7hV8}
}

@Article{Shoshitaishvili2018Mechanical_Phish,
  author    = {Shoshitaishvili, Yan and Bianchi, Antonio and Borgolte, Kevin and Cama, Amat and Corbetta, Jacopo and Disperati, Francesco and Dutcher, Andrew and Grosen, John and Grosen, Paul and Machiry, Aravind and Salls, Christopher and Stephens, Nick and Wang, Ruoyu and Vigna, Giovanni},
  title     = {{Mechanical Phish: Resilient Autonomous Hacking}},
  journal   = {{IEEE Security \& Privacy - Special Issue on Hacking without Humans}},
  kind      = {magazine},
  publishnote = {Volume 16, Issue 2},
  volume    = 16,
  issue     = 2,
  month     = mar,
  year      = {2018},
  timestamp = {2018-03-30},
  url       = {https://ieeexplore.ieee.org/document/8328966/}
}

@InProceedings{Meng2018Rampart_Protecting,
  Paper       = {yes},
  author    = {Meng, Wei and Qian, Chenxiong and Hao, Shuang and Borgolte, Kevin and Vigna, Giovanni and Kruegel, Christopher and Lee, Wenke},
  title     = {{Rampart: Protecting Web Applications from CPU-Exhaustion Denial-of-Service Attacks}},
  booktitle = {{Proceedings of the 27th USENIX Security Symposium}},
  year      = {2018},
  series    = {USENIX Security},
  month     = aug,
  aliases   = {usesec2018-rampart},
  abstract  = {Denial-of-Service (DoS) attacks pose a severe threat to the availability of web applications. Traditionally, attackers have employed botnets or amplification techniques to send a significant amount of requests to exhaust a target web servers resources, and, consequently, prevent it from responding to legitimate requests. However, more recently, highly sophisticated DoS attacks have emerged, in which a single, carefully crafted request results in significant resource consumption and ties up a web applications back-end components for a non-negligible amount of time. Unfortunately, these attacks require only few requests to overwhelm an application, which makes them difficult to detect by state-of-the-art detection systems.

In this paper, we present Rampart, which is a defense that protects web applications from sophisticated CPU-exhaustion DoS attacks. Rampart detects and stops sophisticated CPU-exhaustion DoS attacks using statistical methods and function-level program profiling. Furthermore, it synthesizes and deploys filters to block subsequent attacks, and it adaptively updates them to minimize any potentially negative impact on legitimate users.

We implemented Rampart as an extension to the PHP Zend engine. Rampart has negligible performance overhead and it can be deployed for any PHP application without having to modify the applications source code. To evaluate Ramparts effectiveness and efficiency, we demonstrate that it protects two of the most popular web applications, WordPress and Drupal, from real-world and synthetic CPU-exhaustion DoS attacks, and we also show that Rampart preserves web server performance with low false positive rate and low false negative rate.},
  kind      = {conference},
  timestamp = {2018-08-15},
  paper     = {yes}
}

@InProceedings{Bianchi2012Blacksheep_Detecting,
  title     = {Blacksheep: {Detecting} {Compromised} {Hosts} in {Homogeneous} {Crowds}},
  author    = {Bianchi, Antonio and Shoshitaishvili, Yan and Kruegel, Christopher and Vigna, Giovanni},
  booktitle = {{Proceedings of the 19th ACM Conference on Computer and Communications Security}},
  series    = {CCS},
  year      = {2012},
  month     = oct,
  publisher = {ACM},
  kind      = {conference},
  timestamp = {2012-10-16},
  Paper     = {yes},
}

@InProceedings{Andronio2015HelDroid_Dissecting,
  Paper     = {yes},
  Title      = {{HelDroid}: {Dissecting} and {Detecting} {Mobile} {Ransomware}},
  Paper      = {yes},
  Author     = {Andronio, Nicol and Zanero, Stefano and Maggi, Federico},
  Booktitle  = {Proceedings of the 18th international conference on {Research} in {Attacks}, {Intrusions}, and {Defenses}},
  Year       = {2015},
  Month      = nov,
  doi        = {10.1007/978-3-319-26362-5_18},
  Pages      = {382--404},
  Publisher  = {Springer International Publishing},
  Series     = {Lecture {Notes} in {Computer} {Science}},
  Abstract   = {In ransomware attacks, the actual target is the human, as opposed to the classic attacks that abuse the infected devices (e.g., botnet renting, information stealing). Mobile devices are by no means immune to ransomware attacks. However, there is little research work on this matter and only traditional protections are available. Even state-of-the-art mobile malware detection approaches are ineffective against ransomware apps because of the subtle attack scheme. As a consequence, the ample attack surface formed by the billion mobile devices is left unprotected. First, in this work we summarize the results of our analysis of the existing mobile ransomware families, describing their common characteristics. Second, we present HelDroid, a fast, efficient and fully automated approach that recognizes known and unknown scareware and ransomware samples from goodware. Our approach is based on detecting the building blocks that are typically needed to implement a mobile ransomware application. Specifically, HelDroid detects, in a generic way, if an app is attempting to lock or encrypt the device without the users consent, and if ransom requests are displayed on the screen. Our technique works without requiring that a sample of a certain family is available beforehand. We implemented HelDroid and tested it on real-world Android ransomware samples. On a large dataset comprising hundreds of thousands of APKs including goodware, malware, scareware, and ransomware, HelDroid exhibited nearly zero false positives and the capability of recognizing unknown ransomware samples.},
  Copyright  = {2015 Springer International Publishing Switzerland},
  ISBN       = {978-3-319-26361-8 978-3-319-26362-5},
  Language   = {en},
  Url        = {http://link.springer.com/chapter/10.1007/978-3-319-26362-5_18},
  Timestamp  = {2015-10-30},
  Kind       = {conference},
  Paper      = {yes}
}

@InProceedings{Antonini2015A_Practical,
  Title     = {A {Practical} {Attack} {Against} a {KNX}-based {Building} {Automation} {System}},
  Author    = {Antonini, Alessio and Maggi, Federico and Zanero, Stefano},
  Booktitle = {Proceedings of the 2nd {International} {Symposium} on {ICS} \& {SCADA} {Cyber} {Security} {Research} 2014},
  Year      = {2014},
  Address   = {UK},
  Month     = sep,
  Pages     = {53--60},
  Publisher = {BCS},
  Series    = {{ICS}-{CSR} 2014},
  Abstract  = {Building automation systems rely heavily on general-purpose computers and communication protocols, which are often affected by security vulnerabilities. In this paper, we first analyze the attack surface of a real building automation system - based on the widely used KNX protocol-connected to a general-purpose IP network. To this end, we analyze the vulnerabilities of KNX-based networks highlighted by previous research work, which, however, did not corroborate their findings with experimental results. To verify the practical exploitability of these vulnerabilities and their potential impact, we implement a full-fledged testbed infrastructure that reproduces the typical deployment of a building automation system. On this testbed, we show the feasibility of a practical attack that leverages and combines the aforementioned vulnerabilities. We show the ease of reverse engineering the vendor-specific components of the KNX protocol. Our attack leverages the IP-to-KNX connectivity to send arbitrary commands which are executed by the actuators. We conclude that the vulnerabilities highlighted by previous work are effectively exploitable in practice, with severe results. Although we use KNX as a target, our work can be generalized to other communication protocols, often characterized by similar issues. Finally, we analyze the countermeasures proposed in previous literature and reveal the limitations that prevent their adoption in practice. We suggest a practical stopgap measure to protect real KNX-based BASs from our attack.},
  ISBN      = {978-1-78017-286-6},
  doi       = {10.14236/ewic/ics-csr2014.7},
  Kind      = {conference},
  Timestamp = {2015-08-23}
}

@Article{rnes2016Using_a,
  Title     = {Using a virtual security testbed for digital forensic reconstruction},
  Paper     = {yes},
  Author    = {rnes, Andr and Haas, Paul and Vigna, Giovanni and Kemmerer, Richard A.},
  Journal   = {Journal in Computer Virology},
  Year      = {2006},
  Month     = dec,
  Number    = {4},
  Pages     = {275--289},
  Volume    = {2},
  Abstract  = {This paper presents ViSe, a virtual security testbed, and demonstrates how it can be used to efficiently study computer attacks and suspect tools as part of a computer crime reconstruction. Based on a hypothesis of the security incident in question, ViSe is configured with the appropriate operating systems, services, and exploits. Attacks are formulated as event chains and replayed on the testbed. The effects of each event are analyzed in order to support or refute the hypothesis. The purpose of the approach is to facilitate reconstruction experiments in digital forensics. Two examples are given to demonstrate the approach; one overview example based on the Trojan defense and one detailed example of a multi-step attack. Although a reconstruction can neither prove a hypothesis with absolute certainty nor exclude the correctness of other hypotheses, a standardized environment, such as ViSe, combined with event reconstruction and testing, can lend credibility to an investigation and can be a great asset in court.},
  ISSN      = {1772-9890, 1772-9904},
  Language  = {en},
  Url       = {http://link.springer.com/article/10.1007/s11416-006-0033-x},
  Kind      = {journal},
  Timestamp = {2016-01-26}
}

@InProceedings{Arnes2016Using_Hidden,
  Title     = {Using {Hidden} {Markov} {Models} to {Evaluate} the {Risks} of {Intrusions}: {System} {Architecture} and {Model} {Validation}},
  Author    = {Arnes, Andr and Valeur, Fredrik and Vigna, Giovanni and Kemmerer, Richard A.},
  Booktitle = {Proceedings of the 9th Symposium on Recent {Advances} in {Intrusion} {Detection}},
  Year      = {2006},
  Pages     = {145--164},
  Publisher = {Springer},
  Url       = {http://link.springer.com/chapter/10.1007/11856214_8},
  Kind      = {conference},
  Timestamp = {2016-01-26}
}

@InProceedings{Balduzzi2016A_solution,
  Title     = {A solution for the automated detection of clickjacking attacks},
  Paper     = {yes},
  Author    = {Balduzzi, Marco and Egele, Manuel and Kirda, Engin and Balzarotti, Davide and Kruegel, Christopher},
  Booktitle = {Proceedings of the 5th {ACM} {Symposium} on {Information}, {Computer} and {Communications} {Security}},
  Year      = {2010},
  Pages     = {135--144},
  Publisher = {ACM},
  Url       = {http://dl.acm.org/citation.cfm?id=1755706},
  Kind      = {conference},
  Timestamp = {2016-01-26}
}

@InProceedings{Balduzzi2010Abusing_Social,
  Paper     = {yes},
  Title     = {Abusing {Social} {Networks} for {Automated} {User} {Profiling}},
  Author    = {Balduzzi, Marco and Platzer, Christian and Holz, Thorsten and Kirda, Engin and Balzarotti, Davide and Kruegel, Christopher},
  Booktitle = {Proceeding of the 13th Symposium on Recent Advances in Intrusion Detection},
  Year      = {2010},
  doi       = {10.1007/978-3-642-15512-3_2},
  Pages     = {422--441},
  Kind      = {conference},
  Timestamp = {2010-09-15}
}

@Article{Balzarotti2010An_Experience,
  Title     = {An {Experience} in {Testing} the {Security} of {Real}-world {Electronic} {Voting} {Systems}},
  Author    = {Balzarotti, Davide and Banks, Greg and Cova, Marco and Felmetsger, Viktoria and Kemmerer, Richard and Robertson, William and Valeur, Fredrik and Vigna, Giovanni},
  Journal   = {IEEE Transactions on Software Engineering},
  Year      = {2010},
  Month     = aug,
  Kind      = {journal},
  Timestamp = {2010-08-01}
}

@InProceedings{Balzarotti2008Are_Your,
  Title     = {Are {Your} {Votes} {Really} {Counted}? {Testing} the {Security} of {Real}-world {Electronic} {Voting} {Systems}},
  Author    = {Balzarotti, Davide and Banks, Greg and Cova, Marco and Felmetsger, Viktoria and Kemmerer, Richard and Robertson, William and Valeur, Fredrik and Vigna, Giovanni},
  Booktitle = {Proceedings of the 17th {International} {Symposium} on {Software} {Testing} and {Analysis} ({ISSTA})},
  Year      = {2008},
  Address   = {Seattle, WA},
  Month     = jul,
  Kind      = {conference},
  Timestamp = {2008-08-20}
}

@InProceedings{Balzarotti2008Saner_Composing,
  Title     = {Saner: {Composing} {Static} and {Dynamic} {Analysis} to {Validate} {Sanitization} in {Web} {Applications}},
  Author    = {Balzarotti, Davide and Cova, Marco and Felmetsger, Vika and Jovanovic, Nenad and Kirda, Engin and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the 29th {IEEE} {Symposium} on {Security} and {Privacy}},
  Year      = {2008},
  Address   = {Oakland, CA},
  Month     = may,
  Kind      = {conference},
  Timestamp = {2008-05-18}
}

@InProceedings{Balzarotti2007Multi-Module_Vulnerability,
  Title     = {Multi-{Module} {Vulnerability} {Analysis} of {Web}-based {Applications}},
  Author    = {Balzarotti, Davide and Cova, Marco and Felmetsger, Viktoria and Vigna, Giovanni},
  Booktitle = {Proceedings of the 14th {ACM} {Conference} on {Computer} and {Communications} {Security} ({CCS})},
  Year      = {2007},
  Address   = {Alexandria, VA},
  Month     = oct,
  Pages     = {25--35},
  Kind      = {conference},
  Timestamp = {2007-10-08}
}

@InProceedings{Balzarotti2010Efficient_Detection,
  Title     = {Efficient {Detection} of {Split} {Personalities} in {Malware}},
  Author    = {Balzarotti, Davide and Cova, Marco and Karlberger, Christoph and Kruegel, Christopher and Kirda, Engin and Vigna, Giovanni},
  Booktitle = {Proceedings of the 17th Symposium on {Network} and {Distributed} {System} {Security} {Symposium} ({NDSS})},
  Year      = {2010},
  Address   = {San Diego, CA},
  Month     = feb,
  Kind      = {conference},
  Timestamp = {2010-02-28}
}

@InProceedings{Balzarotti2008ClearShot_Eavesdropping,
  Title     = {{ClearShot}: {Eavesdropping} on {Keyboard} {Input} from {Video}},
  Author    = {Balzarotti, Davide and Cova, Marco and Vigna, Giovanni},
  Booktitle = {Proceedings of the 29th {IEEE} {Symposium} on {Security} and {Privacy}},
  Year      = {2008},
  Address   = {Oakland, CA},
  Month     = may,
  Kind      = {conference},
  Timestamp = {2008-05-18}
}

@InProceedings{Banks2015MISHIMA_Multilateration,
  Title      = {{MISHIMA}: {Multilateration} of {Internet} {Hosts} {Hidden} {Using} {Malicious} {Fast}-{Flux} {Agents} ({Short} {Paper})},
  Paper      = {yes},
  Author     = {Banks, Greg and Fattori, Aristide and Kemmerer, Richard and Kruegel, Christopher and Vigna, Giovanni},
  booktitle  = {{Proceeding of the 8th Symposium on Detection of Intrusions and Malware, and Vulnerability Assessment}},
  Year       = {2011},
  Month      = jul,
  Pages      = {184--193},
  Publisher  = {Springer Berlin Heidelberg},
  ISBN       = {978-3-642-22423-2 978-3-642-22424-9},
  Language   = {en},
  Url        = {http://link.springer.com/chapter/10.1007/978-3-642-22424-9_11},
  Kind       = {conference},
  Timestamp  = {2015-12-11}
}

@InProceedings{Bayer2010Improving_the,
  Paper     = {yes},
  Title     = {Improving the efficiency of dynamic malware analysis},
  Author    = {Bayer, Ulrich and Kirda, Engin and Kruegel, Christopher},
  Booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing {SAC}},
  Year      = {2010},
  doi       = {10.1145/1774088.1774484},
  Pages     = {1871--1878},
  Kind      = {conference},
  Timestamp = {2010-03-22}
}

@InProceedings{Becker2016International_Comparison,
  Title     = {International {Comparison} of {Bank} {Fraud} {Reimbursement}: {Customer} {Perceptions} and {Contractual} {Terms}},
  Author    = {Becker, Ingolf and Hutchings, Alice and Abu-Salma, Ruba and Anderson, Ross and Bohm, Nicholas and Murdoch, Steven and Sasse, Angela and Stringhini, Gianluca},
  Booktitle = {Workshop on the {Economics} of {Information} {Security} ({WEIS})},
  Year      = {2016},
  Address   = {Berkeley},
  Month     = jun,
  Abstract  = {We set out to investigate how customers comprehend bank terms and conditions (T\&Cs). If T\&Cs are incomprehensible, then it is unreasonable to expect customers to comply with them. An expert analysis of 30 bank contracts across 25 countries found that in most cases the contract terms were too vague to be understood; in some cases they differ by product type, and advice can even be contradictory. While many banks allow customers to write PINs down as long as they are disguised and not kept with the card, 20\% of banks do not allow PINs to be written down at all, and a handful do not allow PINs to be shared between accounts. We test our findings on 151 participants in Germany, the US and UK. They mostly agree: only 35\% fully understand the T\&Cs, and 28\% find that sections are unclear. There are strong regional variations: Germans find their T\&Cs particularly hard to understand, but Americans assume harsher T\&Cs than they actually are, and tend to be reassured when they actually read them.},
  Url       = {http://www0.cs.ucl.ac.uk/staff/G.Stringhini/papers/bank-weis2016.pdf},
  Kind      = {jornal},
  Timestamp = {2016-06-01}
}

@InProceedings{Bianchi2015What_the,
  Title     = {What the {App} is {That}? {Deception} and {Countermeasures} in the {Android} {User} {Interface}},
  Author    = {Bianchi, Antonio and Corbetta, Jacopo and Invernizzi, Luca and Fratantonio, Yanick and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the 36th {IEEE} {Symposium} on {Security} and {Privacy}},
  Year      = {2015},
  Publisher = {IEEE},
  Series    = {{SSP} 39;15},
  Kind      = {conference},
  Timestamp = {2015-05-21}
}

@InProceedings{Bianchi2015NJAS_Sandboxing,
  Title     = {{NJAS}: {Sandboxing} {Unmodified} {Applications} in {Non}-rooted {Devices} {Running} {Stock} {Android}},
  Author    = {Bianchi, Antonio and Fratantonio, Yanick and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the 5th {Annual} {ACM} {CCS} {Workshop} on {Security} and {Privacy} in {Smartphones} and {Mobile} {Devices}},
  Year      = {2015},
  Address   = {New York, NY, USA},
  Pages     = {27--38},
  Publisher = {ACM},
  Series    = {{SPSM} '15},
  Abstract  = {Malware poses a serious threat to the Android ecosystem. Moreover, even benign applications can sometimes constitute security and privacy risks to their users, as they might contain vulnerabilities, or they might perform unwanted actions. Previous research has shown that the current Android security model is not sufficient to protect against these threats, and several solutions have been proposed to enable the specification and enforcing of finer-grained security policies. Unfortunately, many existing solutions suffer from several limitations: they require modifications to the Android framework, root access to the device, to create a modified version of an existing app that cannot be installed without enabling unsafe options, or they cannot completely sandbox native code components. In this work, we propose a novel approach that aims to sandbox arbitrary Android applications. Our solution, called NJAS, works by executing an Android application within the context of another one, and it achieves sandboxing by means of system call interposition. In this paper, we show that our solution overcomes major limitations that affect existing solutions. In fact, it does not require any modification to the framework, does not require root access to the device, and does not require the user to enable unsafe options. Moreover, the core sandboxing mechanism cannot be evaded by using native code components.},
  ISBN      = {978-1-4503-3819-6},
  doi       = {10.1145/2808117.2808122},
  Kind      = {workshop},
  Timestamp = {2015-12-11}
}

@InProceedings{Bonetti2014A_Comprehensive,
  Title     = {A {Comprehensive} {Black}-box {Methodology} for {Testing} the {Forensic} {Characteristics} of {Solid}-state {Drives}},
  Paper     = {yes},
  Author    = {Bonetti, Gabriele and Viglione, Marco and Frossi, Alessandro and Maggi, Federico and Zanero, Stefano},
  Booktitle = {Proceedings of the 29th {Annual} {Computer} {Security} {Applications} {Conference}},
  Year      = {2013},
  Address   = {New York, NY, USA},
  Month     = dec,
  Pages     = {269--278},
  Publisher = {ACM},
  Series    = {{ACSAC} '13},
  Abstract  = {Solid-state drives (SSDs) are inherently different from traditional drives, as they incorporate data-optimization mechanisms to overcome their limitations (such as a limited number of program-erase cycles, or the need of blanking a block before writing). The most common optimizations are wear leveling, trimming, compression, and garbage collection, which operate transparently to the host OS and, in certain cases, even when the disks are disconnected from a computer (but still powered up). In simple words, SSD controllers are designed to hide these internals completely, rendering them inaccessible if not through direct acquisition of the memory cells. These optimizations have a significant impact on the forensic analysis of SSDs. The main cause is that memory cells could be pre-emptively blanked, whereas a traditional drive sector would need to be explicitly rewritten to physically wipe off the data. Unfortunately, the existing literature on this subject is sparse and the conclusions are seemingly contradictory. In this paper we propose a generic, practical, test-driven methodology that guides researchers and forensics analysts through a series of steps that assess the "forensic friendliness" of a SSD. Given a drive of the same brand and model of the one under analysis, our methodology produces a decision that helps an analyst to determine whether or not an expensive direct acquisition of the memory cells is worth the effort, because the extreme optimizations may have rendered the data unreadable or useless. We apply our methodology to three SSDs produced by top vendors (Samsung, Corsair, and Crucial), and provide a detailed description of how each step should be conducted.},
  ISBN      = {978-1-4503-2015-3},
  doi       = {10.1145/2523649.2523660},
  Kind      = {conference},
  Timestamp = {2014-06-29}
}

@InProceedings{Canali2011Prophiler_A,
  Paper     = {yes},
  Title     = {Prophiler: {A} {Fast} {Filter} for the {Large}-{Scale} {Detection} of {Malicious} {Web} {Pages}},
  Author    = {Canali, Davide and Cova, Marco and Christopher Kruegel and Vigna, Giovanni},
  Booktitle = {Proceedings of the 20th {World} {Wide} {Web} {Conference} ({WWW})},
  Year      = 2011,
  Address   = {Hiderabad, India},
  Month     = mar,
  Kind      = {conference},
  Timestamp = {2011-03-01}
}

@InProceedings{Canali2016A_quantitative,
  Title     = {A quantitative study of accuracy in system call-based malware detection},
  Author    = {Canali, Davide and Lanzi, Andrea and Balzarotti, Davide and Kruegel, Christopher and Christodorescu, Mihai and Kirda, Engin},
  Booktitle = {Proceedings of the 21st {International} {Symposium} on {Software} {Testing} and {Analysis}},
  Year      = {2012},
  Address   = {Minneapolis, UNITED STATES},
  Pages     = {122--132},
  Publisher = {ACM},
  Url       = {http://dl.acm.org/citation.cfm?id=2336768},
  Kind      = {conference},
  Timestamp = {2016-01-26}
}

@InProceedings{Cao2015EdgeMiner_Automatically,
  Title     = {{EdgeMiner}: {Automatically} {Detecting} {Implicit} {Control} {Flow} {Transitions} through the {Android} {Framework}},
  Paper     = {yes},
  Author    = {Cao, Yinzhi and Fratantonio, Yanick and Bianchi, Antonio and Egele, Manuel and Kruegel, Christopher and Vigna, Giovanni and Chen, Yan},
  Booktitle = {Proceedings of the 22nd Symposium on {Network} and {Distributed} {System} {Security}},
  Year      = {2015},
  Address   = {San Diego, CA},
  Month     = feb,
  Kind      = {conference},
  Timestamp = {2015-02-08}
}

@InProceedings{Carminati2015BankSealer_An,
  Paper     = {yes},
  Title      = {{BankSealer}: {An} {Online} {Banking} {Fraud} {Analysis} and {Decision} {Support} {System}},
  Paper      = {yes},
  Author     = {Carminati, Michele and Caron, Roberto and Maggi, Federico and Epifani, Ilenia and Zanero, Stefano},
  Booktitle  = {Proceedings of the 29th Internation Conference on {Systems} {Security} and {Privacy} {Protection}},
  Year       = {2014},
  Month      = jun,
  Pages      = {380--394},
  Publisher  = {Springer Berlin Heidelberg},
  Series     = {{IFIP} {Advances} in {Information} and {Communication} {Technology}},
  Abstract   = {We propose a semi-supervised online banking fraud analysis and decision support approach. During a training phase, it builds a profile for each customer based on past transactions. At runtime, it supports the analyst by ranking unforeseen transactions that deviate from the learned profiles. It uses methods whose output has a immediate statistical meaning that provide the analyst with an easy-to-understand model of each customers spending habits. First, we quantify the anomaly of each transaction with respect to the customer historical profile. Second, we find global clusters of customers with similar spending habits. Third, we use a temporal threshold system that measures the anomaly of the current spending pattern of each customer, with respect to his or her past spending behavior. As a result, we mitigate the undertraining due to the lack of historical data for building of well-trained profiles (of fresh users), and the users that change their (spending) habits over time. Our evaluation on real-world data shows that our approach correctly ranks complex frauds as top priority.},
  Copyright  = {2014 IFIP International Federation for Information Processing},
  ISBN       = {978-3-642-55414-8 978-3-642-55415-5},
  Language   = {en},
  Url        = {http://link.springer.com/chapter/10.1007/978-3-642-55415-5_32},
  Kind       = {conference},
  Timestamp  = {2015-08-23}
}

@Article{Carminati2015BankSealer_A,
  Paper     = {yes},
  Title    = {{BankSealer}: {A} decision support system for online banking fraud analysis and investigation},
  Paper    = {yes},
  Author   = {Carminati, Michele and Caron, Roberto and Maggi, Federico and Epifani, Ilenia and Zanero, Stefano},
  Journal  = {Computers \& Security},
  Year     = {2015},
  Month    = apr,
  Abstract = {The significant growth of online banking frauds, fueled by the underground economy of malware, raised the need for effective fraud analysis systems. Unfortunately, almost all of the existing approaches adopt black box models and mechanisms that do not give any justifications to analysts. Also, the development of such methods is stifled by limited Internet banking data availability for the scientific community. In this paper we describe BankSealer, a decision support system for online banking fraud analysis and investigation. During a training phase, BankSealer builds easy-to-understand models for each customer's spending habits, based on past transactions. First, it quantifies the anomaly of each transaction with respect to the customer historical profile. Second, it finds global clusters of customers with similar spending habits. Third, it uses a temporal threshold system that measures the anomaly of the current spending pattern of each customer, with respect to his or her past spending behavior. With this threefold profiling approach, it mitigates the under-training due to the lack of historical data for building well-trained profiles, and the evolution of users' spending habits over time. At runtime, BankSealer supports analysts by ranking new transactions that deviate from the learned profiles, with an output that has an easily understandable, immediate statistical meaning.

  Our evaluation on real data, based on fraud scenarios built in collaboration with domain experts that replicate typical, real-world attacks (e.g., credential stealing, banking trojan activity, and frauds repeated over time), shows that our approach correctly ranks complex frauds. In particular, we measure the effectiveness, the computational resource requirements and the capabilities of BankSealer to mitigate the problem of users that performed a low number of transactions. Our system ranks frauds and anomalies with up to 98\% detection rate and with a maximum daily computation time of 4min. Given the good results, a leading Italian bank deployed a version of BankSealer in their environment to analyze frauds.},
  ISSN       = {0167-4048},
  Url        = {http://www.sciencedirect.com/science/article/pii/S0167404815000437},
  Kind       = {journal},
  Timestamp  = {2015-05-23}
}

@InProceedings{Carter2016CuriousDroid_Automated,
  Paper     = {yes},
  Title     = {{CuriousDroid}: {Automated} {User} {Interface} {Interaction} for {Android} {Application} {Analysis} {Sandboxes}},
  Author    = {Carter, Patrick and Mulliner, Collin and Lindorfer, Martina and Robertson, William and Kirda, Engin},
  Booktitle = {Proceedings of the {International} {Conference} on {Financial} {Cryptography} and {Data} {Security} ({FC})},
  Year      = {2016},
  Address   = {Christ Church, Barbados},
  Month     = feb,
  Abstract  = {Mobile computing has experienced enormous growth in market share and computational power in recent years. As a result, mobile malware is becoming more sophisticated and more prevalent, leading to research into dynamic sandboxes as a widespread approach for detecting malicious applications. However, the event-driven nature of Android applications renders critical the capability to automatically generate deterministic and intelligent user interactions to drive analysis subjects and improve code coverage. In this paper, we present CuriousDroid, an automated system for exercising Android application user interfaces in an intelligent, user-like manner. CuriousDroid operates by decomposing application user interfaces on-the-fly and creating a context-based model for interactions that is tailored to the current user layout. We integrated CuriousDroid with Andrubis, a well-known Android sandbox, and conducted a large-scale evaluation of 38,872 applications taken from different data sets. Our evaluation demonstrates significant improvements in both end-to-end sample classification as well as increases in the raw number of elicited behaviors at runtime.},
  Kind      = {conference},
  Timestamp = {2016-02-01}
}

@InProceedings{Carzaniga2007Is_Code,
  Title     = {Is {Code} {Still} {Moving} {Around}? {Looking} {Back} at a {Decade} of {Code} {Mobility}},
  Author    = {Carzaniga, Antonio and Picco, Gian Pietro and Vigna, Giovanni},
  Booktitle = {Proceedings of the 29th {International} {Conference} on {Software} {Engineering} ({ICSE})},
  Year      = {2007},
  Month     = may,
  Pages     = {9--20},
  Kind      = {conference},
  Timestamp = {2007-05-19}
}

@InProceedings{Cavedon2010Are_BGP,
  Title     = {Are {BGP} {Routers} {Open} {To} {Attack}? {An} {Experiment}},
  Author    = {Cavedon, Ludovico and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the {iNetSec} {Conference}},
  Year      = {2010},
  Address   = {Sophia, Bulgaria},
  Month     = mar,
  Kind      = {conference},
  Timestamp = {2010-03-05}
}

@InProceedings{Chatzakou2017Hate_is,
  Title       = {Hate is not binary: {Studying} abusive behavior of \#{GamerGate} on {Twitter}},
  Author      = {Chatzakou, Despoina and Kourtellis, Nicolas and Blackburn, Jeremy and De Cristofaro, Emiliano and Stringhini, Gianluca and Vakali, Athena},
  Booktitle   = {Proceedings of the 2017 {ACM} {Conference} on {Hypertext} and {Social} {Media} ({HyperText})},
  Year        = {2017},
  Address     = {Prague, Czech Republic},
  Month       = jul,
  Publisher   = {ACM},
  Abstract    = {Over the past few years, online bullying and aggression have become increasingly prominent, and manifested in many di erent forms on social media. However, there is little work analyzing the characteristics of abusive users and what distinguishes them from typical social media users. In this paper, we start addressing this gap by analyzing tweets containing a great large amount of abusiveness. We focus on a Twitter dataset revolving around the Gamergate controversy, which led to many incidents of cyberbullying and cyberaggression on various gaming and social media platforms. We study the properties of the users tweeting about Gamergate, the content they post, and the di erences in their behavior compared to typical Twitter users. We nd that while their tweets are often seemingly about aggressive and hateful subjects, Gamergaters do not exhibit common expressions of online anger, and in fact primarily di er from typical users in that their tweets are less joyful. They are also more engaged than typical Twitter users, which is an indication as to how and why this controversy is still ongoing. Surprisingly, we nd that Gamergaters are less likely to be suspended by Twitter, thus we analyze their properties to identify di erences from typical users and what may have led to their suspension. We perform an unsupervised machine learning analysis to detect clusters of users who, though currently active, could be considered for suspension since they exhibit similar behaviors with suspended users. Finally, we con rm the usefulness of our analyzed features by emulating the Twitter suspension mechanism with a supervised learning method, achieving very good precision and recall.},
  Kind          = {conference},
  Timestamp     = {2017-07-04}
}

@InProceedings{Chatzakou2017Mean_Birds,
  Paper     = {yes},
  Title     = {Mean {Birds}: {Detecting} {Aggression} and {Bullying} on {Twitter}},
  Paper     = {yes},
  Author    = {Chatzakou, Despoina and Kourtellis, Nicolas and Blackburn, Jeremy and De Cristofaro, Emiliano and Stringhini, Gianluca and Vakali, Athena},
  Booktitle = {Proceedings of the 2017 {International} {ACM} {Web} {Science} {Conference} ({WebSci})},
  Year      = {2017},
  Address   = {Troy, NY},
  Month     = jun,
  Publisher = {ACM},
  Abstract  = {In recent years, bullying and aggression against social media users have grown signi cantly, causing serious consequences to victims of all demographics. Nowadays, cyberbullying a ects more than half of young social media users worldwide, su ering from prolonged and/or coordinated digital harassment. Also, tools and technologies geared to understand and mitigate it are scarce and mostly ine ective. In this paper, we present a principled and scalable approach to detect bullying and aggressive behavior on Twitter. We propose a robust methodology for extracting text, user, and network-based attributes, studying the properties of bullies and aggressors, and what features distinguish them from regular users. We nd that bullies post less, participate in fewer online communities, and are less popular than normal users. Aggressors are relatively popular and tend to include more negativity in their posts. We evaluate our methodology using a corpus of 1.6M tweets posted over 3 months, and show that machine learning classification algorithms can accurately detect users exhibiting bullying and aggressive behavior, with over 90\% AUC.},
  Kind        = {conference},
  Timestamp   = {2017-06-25}
}

@InProceedings{Chen2016Towards_Fully,
  Paper     = {yes},
  Title            = {Towards {Fully} {Automated} {Dynamic} {Analysis} for {Embedded} {Firmware}},
  Author           = {Chen, Daming and Egele, Manuel and Woo, Maverick and Brumley, David},
  Booktitle        = {Proceedings of the 23rd Symposium on {Network} and {Distributed} {System} {Security}},
  Year             = {2016},
  Address          = {San Diego, CA},
  Month            = feb,
  Kind             = {conference},
  Timestamp        = {2016-02-21}
}

@InProceedings{Childers2010Organizing_large,
  Title     = {Organizing large scale hacking competitions},
  Author    = {Childers, Nicholas and Boe, Bryce and Cavallaro, Lorenzo and Cavedon, Ludovico and Cova, Marco and Egele, Manuel and Vigna, Giovanni},
  Booktitle = {Proceedings of the 7th {International} {Conference} on {Detection} of {Intrusions} and {Malware} \& {Vulnerability} {Assessment}},
  Year      = {2010},
  Address   = {Bonn, Germany},
  Month     = jul,
  ISBN      = {3-642-14214-1 978-3-642-14214-7},
  Url       = {http://portal.acm.org/citation.cfm?id=1884848.1884859},
  Kind      = {conference},
  Timestamp = {2010-07-08}
}

@InProceedings{Cipriano2016Nexat_A,
  Title      = {Nexat: {A} history-based approach to predict attacker actions},
  Paper      = {yes},
  Author     = {Cipriano, Casey and Zand, Ali and Houmansadr, Amir and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle  = {Proceedings of the 27th {Annual} {Computer} {Security} {Applications} {Conference}},
  Year       = {2011},
  Address    = {Orlando, FL},
  Pages      = {383--392},
  Publisher  = {ACM},
  Kind       = {conference},
  Timestamp  = {2016-01-26}
}

@InProceedings{Coletta2016DroydSeuss_A,
  Paper     = {yes},
  Title     = {{DroydSeuss}: {A} {Mobile} {Banking} {Trojan} {Tracker} - {Short} {Paper}},
  Paper     = {yes},
  Author    = {Coletta, Alberto and Van Der Veen, Victor and Maggi, Federico},
  Booktitle = {Financial {Cryptography} and {Data} {Security}},
  Year      = {2016},
  Month     = feb,
  Publisher = {Springer Berlin Heidelberg},
  Series    = {Lecture {Notes} in {Computer} {Science} ({LNCS})},
  Abstract  = {After analyzing several Android mobile banking trojans, we observed the presence of repetitive artifacts that describe valuable information about the distribution of this class of malicious apps. Motivated by the high threat level posed by mobile banking trojans and by the lack of publicly available analysis and intelligence tools, we automated the extraction of such artifacts and created a malware tracker named DroydSeuss. DroydSeuss first processes applications both statically and dynamically, extracting relevant strings that contain traces of communication endpoints. Second, it prioritizes the extracted strings based on the APIs that manipulate them. Finally, DroydSeuss correlates the endpoints with descriptive metadata from the samples, providing aggregated statistics, raw data, and cross-sample information that allow researchers to pinpoint relevant groups of applications. We connected DroydSeuss to the VirusTotal daily feed, consuming Android samples that perform banking-trojan activity. We manually analyzed its output and found supporting evidence to confirm its correctness. Remarkably, the most frequent itemset unveiled a campaign currently spreading against Chinese and Korean bank customers.
  Although motivated by mobile banking trojans, DroydSeuss can be used to analyze the communication behavior of any suspicious application.},
  Kind      = {conference},
  Timestamp = {2016-02-01}
}

@InProceedings{Comparetti2010Identifying_Dormant,
  Paper     = {yes},
  Title     = {Identifying {Dormant} {Functionality} in {Malware} {Programs}},
  Author    = {Comparetti, Paolo Milani and Salvaneschi, Guido and Kirda, Engin and Kolbitsch, Clemens and Kruegel, Christopher and Zanero, Stefano},
  Booktitle = {Proceedings of the 31st {IEEE} {Symposium} on {Security} and {Privacy}},
  Year      = {2010},
  doi       = {10.1109/SP.2010.12},
  Pages     = {61--76},
  Kind      = {conference},
  Timestamp = {2010-05-16}
}

@InProceedings{Continella2017Obfuscation-Resilient_Privacy,
  Title     = {Obfuscation-{Resilient} {Privacy} {Leak} {Detection} for {Mobile} {Apps} {Through} {Differential} {Analysis}},
  Paper     = {yes},
  Author    = {Continella, Andrea and Fratantonio, Yanick and Lindorfer, Martina and Puccetti, Alessandro and Zand, Ali and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the 24th Symposium on {Network} and {Distributed} {System} {Security} ({NDSS})},
  Year      = {2017},
  Address   = {San Diego},
  Month     = feb,
  Abstract  = {Mobile apps are notorious for collecting a wealth of private information from users. Despite significant effort from the research community in developing privacy leak detection tools based on data flow tracking inside the app or through network traffic analysis, it is still unclear whether apps and ad libraries can hide the fact that they are leaking private information. In fact, all existing analysis tools have limitations: data flow tracking suffers from imprecisions that cause false positives, as well as false negatives when the data flow from a source of private information to a network sink is interrupted; on the other hand, network traffic analysis cannot handle encryption or custom encoding.
  We propose a new approach to privacy leak detection that is not affected by such limitations, and it is also resilient to obfuscation techniques, such as encoding, formatting, encryption, or any other kind of transformation performed on private information before it is leaked. Our work is based on blackbox differential analysis, and it works in two steps: first, it establishes a baseline of the network behavior of an app; then, it modifies sources of private information, such as the device ID and location, and detects leaks by observing deviations in the resulting network traffic. The basic concept of black-box differential analysis is not novel, but, unfortunately, it is not practical enough to precisely analyze modern mobile apps. In fact, their network traffic contains many sources of non-determinism, such as random identifiers, timestamps, and server-assigned session identifiers, which, when not handled properly, cause too much noise to correlate output changes with input changes. 
  The main contribution of this work is to make black-box differential analysis practical when applied to modern Android apps. In particular, we show that the network-based non-determinism can often be explained and eliminated, and it is thus possible to reliably use variations in the network traffic as a strong signal to detect privacy leaks. We implemented this approach in a tool, called Agrigento, and we evaluated it on more than one thousand Android apps. Our evaluation shows that our approach works well in practice and outperforms current state-of-the-art techniques. We conclude our study by discussing several case studies that show how popular apps and ad libraries currently exfiltrate data by using complex combinations of encoding and encryption mechanisms that other approaches fail to detect. Our results show that these apps and libraries seem to deliberately hide their data leaks from current approaches and clearly demonstrate the need for an obfuscation-resilient approach such as ours.},
  Kind      = {conference},
  Timestamp = {2017-02-26}
}

@InProceedings{Corbetta2015Eyes_of,
  Paper     = {yes},
  Title      = {Eyes of a {Human}, {Eyes} of a {Program}: {Leveraging} {Different} {Views} of the {Web} for {Analysis} and {Detection}},
  Author     = {Corbetta, Jacopo and Invernizzi, Luca and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle  = {Proceedings of the 17th Symposium on Research in {Attacks}, {Intrusions} and {Defenses}},
  Year       = {2014},
  Month      = sep,
  doi        = {10.1007/978-3-319-11379-1_7},
  Pages      = {130--149},
  Publisher  = {Springer International Publishing},
  Series     = {Lecture {Notes} in {Computer} {Science}},
  Abstract   = {With JavaScript and images at their disposal, web authors can create content that is immediately understandable to a person, but is beyond the direct analysis capability of computer programs, including security tools. Conversely, information can be deceiving for humans even if unable to fool a program. In this paper, we explore the discrepancies between user perception and program perception, using content obfuscation and counterfeit seal images as two simple but representative case studies. In a dataset of 149,700 pages we found that benign pages rarely engage in these practices, while uncovering hundreds of malicious pages that would be missed by traditional malware detectors. We envision that this type of heuristics could be a valuable addition to existing detection systems. To show this, we have implemented a proof-of-concept detector that, based solely on a similarity score computed on our metrics, can already achieve a high precision (95\%) and a good recall (73\%).},
  Copyright  = {2014 Springer International Publishing Switzerland},
  ISBN       = {978-3-319-11378-4 978-3-319-11379-1},
  Language   = {en},
  Url        = {http://link.springer.com/chapter/10.1007/978-3-319-11379-1_7},
  Kind       = {conference},
  Timestamp  = {2015-12-11}
}

@InProceedings{Cova2007Swaddler_An,
  Title     = {Swaddler: {An} {Approach} for the {Anomaly}-based {Detection} of {State} {Violations} in {Web} {Applications}},
  Author    = {Cova, Marco and Balzarotti, Davide and Felmetsger, Viktoria and Vigna, Giovanni},
  Booktitle = {Proceedings of the 10th {International} {Symposium} on {Recent} {Advances} in {Intrusion} {Detection} ({RAID})},
  Year      = {2007},
  Address   = {Gold Coast, Australia},
  Month     = sep,
  Pages     = {63--86},
  Kind      = {conference},
  Timestamp = {2007-09-01}
}

@InProceedings{Cova2006Static_Detection,
  Title     = {Static {Detection} of {Vulnerabilities} in x86 {Executables}},
  Author    = {Cova, Marco and Felmetsger, Viktoria and Banks, Greg and Vigna, Giovanni},
  Booktitle = {Proceedings of the 22nd Symposium on {Computer} {Security} {Applications} {Conference} ({ACSAC})},
  Year      = {2006},
  Address   = {Miami, FL},
  Month     = dec,
  Kind      = {conference},
  Timestamp = {2006-12-01}
}

@InBook{Cova2007Vulnerability_Analysis,
  Title     = {Vulnerability {Analysis} of {Web} {Applications}},
  Author    = {Cova, Marco and Felmetsger, Viktoria and Vigna, Giovanni},
  Booktitle = {Testing and {Analysis} of {Web} {Services}},
  Publisher = {Springer},
  Year      = {2007},
  Kind      = {chapter},
  Timestamp = {2007-01-01}
}

@InProceedings{Cova2010Detection_and,
  Title     = {Detection and {Analysis} of {Drive}-by-{Download} {Attacks} and {Malicious} {JavaScript} {Code}},
  Author    = {Cova, Marco and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the 19th International Conference on {World} {Wide} {Web} ({WWW})},
  Year      = {2010},
  Address   = {Raleigh, NC},
  Month     = apr,
  Kind      = {conference},
  Timestamp = {2010-04-26}
}

@InProceedings{Cova2008There_is,
  Title     = {{There is No Free Phish: An Analysis of Free and Live Phishing Kits}},
  Author    = {Cova, Marco and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the 2nd {USENIX} {Workshop} {On} {Offensive} {Technologies} ({WOOT})},
  Year      = {2008},
  Address   = {San Jose, CA},
  Month     = aug,
  Kind      = {workshop},
  Timestamp = {2008-08-01}
}

@InProceedings{Criscione2014Zarathustra_Extracting,
  Title     = {Zarathustra: {Extracting} {WebInject} {Signatures} from {Banking} {Trojans}},
  Paper     = {yes},
  Author    = {Criscione, Claudio and Bosatelli, Fabio and Zanero, Stefano and Maggi, Federico},
  Booktitle = {Proceedings of the 12th {Annual} {International} {Conference} on {Privacy}, {Security} and {Trust} ({PST})},
  Year      = {2014},
  Address   = {Toronto, Canada},
  Month     = jul,
  Pages     = {139--148},
  Publisher = {IEEE Computer Society},
  Abstract  = {Modern trojans are equipped with a functionality, called WebInject, that can be used to silently modify a web page on the infected end host. Given its flexibility, WebInject-based malware is becoming a popular information-stealing mechanism. In addition, the structured and well-organized malware-as-a-service model makes revenue out of customization kits, which in turns leads to high volumes of binary variants. Analysis approaches based on memory carving to extract the decrypted webinject.txt and config.bin files at runtime make the strong assumption that the malware will never change the way such files are handled internally, and therefore are not future proof by design. In addition, developers of sensitive web applications (e.g., online banking) have no tools that they can possibly use to even mitigate the effect of WebInjects.},
  ISBN      = {978-1-4799-3502-4},
  Kind      = {conference},
  Timestamp = {2014-07-01}
}

@InProceedings{Criscione2009Integrated_Detection,
  Paper     = {yes},
  Title     = {Integrated {Detection} of {Attacks} {Against} {Browsers}, {Web} {Applications} and {Databases}},
  Author    = {Criscione, Claudio and Maggi, Federico and Salvaneschi, Guido and Zanero, Stefano},
  Booktitle = {Proceedings of the 3rd {European} {Conference} on {Network} {Defense}},
  Year      = {2009},
  Month     = nov,
  Publisher = {IEEE Computer Society},
  Abstract  = {Anomaly-based techniques were exploited successfully to implement protection mechanisms for various systems. Recently, these approaches have been ported to the web domain under the name of web application anomaly detectors (or firewalls) with promising results. In particular, those capable of automatically building specifications, or models, of the protected application by observing its traffic (e.g., network packets, system calls, or HTTP requests and responses) are particularly interesting, since they can be deployed with little effort. Typically, the detection accuracy of these systems is significantly influenced by the model building phase (often called training), which clearly depends upon the quality of the observed traffic, which should resemble the normal activity of the protected application and must be also free from attacks. Otherwise, detection may result in significant amounts of false positives (i.e., benign events flagged as anomalous) and negatives (i.e., undetected threats). In this work we describe Masibty, a web application anomaly detector that have some interesting properties. First, it requires the training data not to be attack-free. Secondly, not only it protects the monitored application, it also detects and blocks malicious client-side threats before they are sent to the browser. Third, Masibty intercepts the queries before they are sent to the database, correlates them with the corresponding HTTP requests and blocks those deemed anomalous. Both the accuracy and the performance have been evaluated on real-world web applications with interesting results. The system is almost not influenced by the presence of attacks in the training data and shows only a negligible amount of false positives, although this is paid in terms of a slight performance overhead.},
  ISBN      = {978-0-7695-3983-6},
  Kind      = {conference},
  Timestamp = {2009-11-01}
}

@Article{Dardanelli2013A_Security,
  Title                    = {A {Security} {Layer} for {Smartphone}-to-{Vehicle} {Communication} over {Bluetooth}},
  Paper                      = {yes},
  Author                   = {Dardanelli, Andrea and Maggi, Federico and Tanelli, Mara and Zanero, Stefano and Savaresi, Sergio M and Kochanek, Roman and Holz, Thorsten},
  Journal                  = {Embedded Systems Letters},
  Year                     = {2013},

  Month                    = jun,
  Number                   = {3},
  Pages                    = {34--37},
  Volume                   = {5},

  Abstract                 = {Modern vehicles are increasingly being interconnected with computer systems, which collect information both from vehicular sources and Internet services. Unfortunately, this creates a non negligible attack surface, which extends when vehicles are partly operated via smartphones. In this letter, a hierarchically distributed control system architecture which integrates a smartphone with classical embedded systems is presented, and an ad-hoc, end-to-end security layer is designed to demonstrate how a smartphone can interact securely with a modern vehicle without requiring modifications to the existing in-vehicle network. Experimental results demonstrate the effectiveness of the approach.},
  ISSN                     = {1943-0663},
  Kind = {journal},
  Timestamp = {2013-06-01}
}

@InProceedings{Davi2012MoCFI_A,
  Paper     = {yes},
  Title     = {{MoCFI}: {A} {Framework} to {Mitigate} {Control}-{Flow} {Attacks} on {Smartphones}},
  Paper     = {yes},
  Author    = {Davi, Lucas and Dmitrienko, Alexandra and Egele, Manuel and Fischer, Thomas and Holz, Thorsten and Hund, Ralf and Nrnberger, Stefan and Sadeghi, Ahmad-Reza},
  Booktitle = {Proceedings of the 19th Symposium on {Network} and {Distributed} {System} {Security} {Symposium}},
  Year      = {2012},
  Address   = {San Diego, CA},
  Month     = feb,
  Kind      = {conference},
  Timestamp = {2012-02-05}
}

@InProceedings{Davi2011CFI_Goes,
  Paper     = {yes},
  Title     = {{CFI} {Goes} {Mobile}: {Control}-{Flow} {Integrity} for {Smartphones}},
  Author    = {Davi, Lucas and Dmitrienko, Alexandra and Egele, Manuel and Fischer, Thomas and Hund, Ralf and Nrnberger, Stefan and Sadeghi, Ahmad-Reza and Holz, Thorsten},
  Booktitle = {International {Workshop} on {Trustworthy} {Embedded} {Devices}},
  Year      = {2011},
  Address   = {Leuven, Belgium},
  Month     = sep,
  Kind      = {workshop},
  Timestamp = {2011-09-01}
}

@InProceedings{Doup2010Why_Johnny,
  Title     = {Why {Johnny} {Can}t {Pentest}: {An} {Analysis} of {Black}-box {Web} {Vulnerability} {Scanners}},
  Author    = {Doup, Adam and Cova, Marco and Vigna, Giovanni},
  Booktitle = {Proceedings of the 7th {Conference} on {Detection} of {Intrusions} and {Malware} and {Vulnerability} {Assessment} ({DIMVA})},
  Year      = {2010},
  Address   = {Bonn, Germany},
  Month     = jul,
  Kind      = {conference},
  Timestamp = {2010-07-08}
}

@InProceedings{Doup2016Fear_the,
  Title      = {Fear the {EAR}: discovering and mitigating execution after redirect vulnerabilities},
  Booktitle  = {Proceedings of the 18th ACM Conference on Computer and Communications Security},
  Author     = {Doup, Adam and Boe, Bryce and Kruegel, Christopher and Vigna, Giovanni},
  Year       = {2011},
  Month      = oct,
  Pages      = {251--262},
  Publisher  = {ACM},
  ISBN       = {978-1-4503-0948-6},
  Url        = {http://dl.acm.org/citation.cfm?id=2046707.2046736},
  Kind       = {conference},
  Timestamp  = {2016-01-26}
}

@InProceedings{Doup2012Enemy_of,
  Title     = {Enemy of the {State}: {A} {State}-{Aware} {Black}-{Box} {Vulnerability} {Scanner}},
  Author    = {Doup, Adam and Cavedon, Ludovico and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the 21st Symposium on {USENIX} {Security}},
  Year      = {2012},
  Address   = {Bellevue, WA},
  Month     = aug,
  Kind      = {conference},
  Timestamp = {2012-08-08}
}

@InProceedings{Doup2016deDacota_toward,
  Title      = {{deDacota}: toward preventing server-side {XSS} via automatic code and data separation},
  Paper      = {yes},
  Author     = {Doup, Adam and Cui, Weidong and Jakubowski, Mariusz H. and Peinado, Marcus and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle  = {Proceedings of the 20th {ACM} {Conference} on {Computer} and {Communications} {Security} ({CCS})},
  Year       = {2013},
  Address    = {Berlin, Germany},
  Pages      = {1205--1216},
  Publisher  = {ACM Press},
  ISBN       = {978-1-4503-2477-9},
  Language   = {en},
  Url        = {http://dl.acm.org/citation.cfm?doid=2508859.2516708},
  Kind       = {conference},
  Timestamp  = {2016-01-26}
}

@InProceedings{Doup2011Hit_Em,
  Paper     = {yes},
  Title     = {Hit '{Em} {Where} {It} {Hurts}: {A} {Live} {Security} {Exercise} on {Cyber} {Situational} {Awareness}},
  Author    = {Doup, Adam and Egele, Manuel and Caillat, Benjamin and Stringhini, Gianluca and Yakin, Gorkem and Zand, Ali and Cavedon, Ludovico and Vigna, Giovanni},
  Booktitle = {Proceedings of the 27th {Annual} {Computer} {Security} {Applications} {Conference}},
  Year      = {2011},
  Address   = {New York, NY, USA},
  Pages     = {51--61},
  Publisher = {ACM},
  Series    = {{ACSAC} '11},
  ISBN      = {978-1-4503-0672-0},
  doi       = {10.1145/2076732.2076740},
  Kind      = {conference},
  Timestamp = {2011-12-05}
}

@InProceedings{Doup2013Writing_Groups,
  Title     = {Writing {Groups} in {Computer} {Science} {Research} {Labs}},
  Paper     = {yes},
  Author    = {Doup, Adam and Kayfetz, Janet L.},
  Booktitle = {Proceedings of the 43rd Annual {Frontiers} in {Education} {Conference} ({FIE})},
  Year      = {2013},
  Address   = {Oklahoma City, OK},
  Month     = oct,
  Kind      = {conference},
  Timestamp = {2013-10-23}
}

@Article{Eckmann2002STATL_An,
  Paper     = {yes},
  Title     = {{STATL}: {An} {Attack} {Language} for {State}-based {Intrusion} {Detection}},
  Author    = {Eckmann, Steven T. and Vigna, Giovanni and Kemmerer, Richard A.},
  Journal   = {Journal of Computer Security},
  Year      = {2002},
  Number    = {1/2},
  Pages     = {71--104},
  Volume    = {10},
  Kind      = {journal},
  Timestamp = {2002-01-01}
}

@MastersThesis{Egele2006Behavior-Based_Spyware,
  Title     = {Behavior-{Based} {Spyware} {Detection} {Using} {Dynamic} {Taint} {Analysis}},
  Author    = {Egele, Manuel},
  School    = {Vienna University of Technology},
  Year      = {2006},
  Address   = {Austria},
  Kind      = {thesis},
  Timestamp = {2006-01-01}
}

@InProceedings{Egele2010CAPTCHA_smuggling,
  Title     = {{CAPTCHA} smuggling: {Hijacking} web browsing sessions to create {CAPTCHA} farms},
  Author    = {Egele, Manuel and Bilge, Leyla and Kirda, Engin and Kruegel, Christopher},
  Booktitle = {Proceedings of 25th International Symposium on {Applied} {Computing}},
  Year      = {2010},
  Address   = {Sierre, Switzerland},
  Month     = mar,
  ISBN      = {978-1-60558-639-7},
  Kind      = {conference},
  Timestamp = {2010-03-22}
}

@InProceedings{Egele2015An_Empirical,
  Title     = {An {Empirical} {Study} of {Cryptographic} {Misuse} in {Android} {Applications}},
  Paper     = {yes},
  Author    = {Egele, Manuel and Brumley, David and Fratantonio, Yanick and Kruegel, Christopher},
  Booktitle = {Proceedings of the 2013 {ACM} {SIGSAC} {Conference} on {Computer} \& {Communications} {Security}},
  Year      = {2013},
  Address   = {New York, NY, USA},
  Pages     = {73--84},
  Publisher = {ACM},
  Series    = {{CCS} '13},
  Abstract  = {Developers use cryptographic APIs in Android with the intent of securing data such as passwords and personal information on mobile devices. In this paper, we ask whether developers use the cryptographic APIs in a fashion that provides typical cryptographic notions of security, e.g., IND-CPA security. We develop program analysis techniques to automatically check programs on the Google Play marketplace, and find that 10.327 out of 11,748 applications that use cryptographic APIs -- 88\% overall -- make at least one mistake. These numbers show that applications do not use cryptographic APIs in a fashion that maximizes overall security. We then suggest specific remediations based on our analysis towards improving overall cryptographic security in Android applications.},
  ISBN      = {978-1-4503-2477-9},
  doi       = {10.1145/2508859.2516693},
  Kind      = {conference},
  Timestamp = {2015-12-11}
}

@InProceedings{Egele2009Mitigating_Drive-by,
  Paper     = {yes},
  Title     = {Mitigating {Drive}-by {Download} {Attacks}: {Challenges} and {Open} {Problems}},
  Author    = {Egele, Manuel and Kirda, Engin and Kruegel, Christopher},
  Booktitle = {{iNetSec} {Open} {Research} {Problems} in {Network} {Security}},
  Year      = {2009},
  Address   = {Zurich, Switzerland},
  Month     = apr,
  Kind      = {workshop},
  Timestamp = {2009-04-05}
}

@Article{Egele2011Removing_web,
  Title     = {Removing web spam links from search engine results},
  Author    = {Egele, Manuel and Kolbitsch, Clemens and Platzer, Christian},
  Journal   = {Journal in Computer Virology},
  Year      = {2011},
  Month     = feb,
  Number    = {1},
  Pages     = {51--62},
  Volume    = {7},
  ISSN      = {1772-9890},
  doi       = {10.1007/s11416-009-0132-6},
  Kind      = {journal},
  Timestamp = {2011-02-01}
}

@InProceedings{Egele2009Removing_web,
  Title     = {Removing web spam links from search engine results},
  Author    = {Egele, Manuel and Kruegel, Christopher and Kirda, Engin},
  Booktitle = {European {Institute} for {Computer} {Antivirus} {Research} {Conference}},
  Year      = {2009},
  Journal   = {Journal in Computer Virology},
  Address   = {Berlin, Germany},
  Month     = may,
  Kind      = {journal},
  Timestamp = {2009-05-01}
}

@InProceedings{Egele2011PiOS_Detecting,
  Title     = {{PiOS}: {Detecting} {Privacy} {Leaks} in {iOS} {Applications}},
  Author    = {Egele, Manuel and Kruegel, Christopher and Kirda, Engin and Vigna, Giovanni},
  Booktitle = {Proceedings of the 18th Symposium on {Network} and {Distributed} {System} {Security} ({NDSS})},
  Year      = {2011},
  Address   = {San Diego, CA},
  Month     = feb,
  Kind      = {conference},
  Timestamp = {2011-02-06}
}

@InProceedings{Egele2007Dynamic_Spyware,
  Title     = {Dynamic {Spyware} {Analysis}},
  Author    = {Egele, Manuel and Kruegel, Christopher and Kirda, Engin and Yin, Heng and Song, Dawn Xiaodong},
  Booktitle = {Proceedings of the 16th {USENIX} {Annual} {Technical} {Conference}},
  Year      = {2007},
  Address   = {Santa Clara, CA},
  Month     = jun,
  Kind      = {conference},
  Timestamp = {2007-06-17}
}

@Article{Egele2012PoX_Protecting,
  Title     = {{PoX}: {Protecting} {Users} from {Malicious} {Facebook} {Applications}},
  Author    = {Egele, Manuel and Moser, Andreas and Kruegel, Christopher and Kirda, Engin},
  Journal   = {Computer Communications},
  Year      = {2012},
  Month     = jul,
  Number    = {12},
  Pages     = {1507--1515},
  Volume    = {35},
  ISSN      = {0140-3664},
  Url       = {http://www.sciencedirect.com/science/article/pii/S0140366412001417},
  Kind      = {journal},
  Timestamp = {2012-06-01}
}

@InProceedings{Egele2011PoX_Protecting,
  Title     = {{PoX}: {Protecting} {Users} from {Malicious} {Facebook} {Applications}},
  Author    = {Egele, Manuel and Moser, Andreas and Kruegel, Christopher and Kirda, Engin},
  Booktitle = {{IEEE} {International} {Workshop} on {SEcurity} and {SOCial} {Networking}},
  Year      = {2011},
  Address   = {Seattle, WA},
  Month     = mar,
  Kind      = {workshop},
  Timestamp = {2011-03-01}
}

@Article{Egele2012A_Survey,
  Title     = {A {Survey} on {Automated} {Dynamic} {Malware} {Analysis} {Techniques} and {Tools}},
  Paper     = {yes},
  Author    = {Egele, Manuel and Scholte, Theodoor and Kirda, Engin and Kruegel, Christopher},
  Journal   = {ACM Computing Surveys},
  Year      = {2012},
  Month     = mar,
  Number    = {2},
  Pages     = {6:1--6:42},
  Volume    = {44},
  ISSN      = {0360-0300},
  doi       = {10.1145/2089125.2089126},
  Kind      = {journal},
  Timestamp = {2012-03-01}
}

@InProceedings{Egele2016COMPA_Detecting,
  Paper     = {yes},
  Title      = {{COMPA}: {Detecting} {Compromised} {Accounts} on {Social} {Networks}.},
  Paper      = {yes},
  Author     = {Egele, Manuel and Stringhini, Gianluca and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle  = {Proceedings of the 20th Symposium on {Network} and {Distributed} {System} {Security}},
  Year       = {2013},
  Address    = {San Diego, CA},
  Kind       = {conference},
  Timestamp  = {2016-01-26}
}

@InProceedings{Egele2006Using_Static,
  Title     = {Using {Static} {Program} {Analysis} to {Aid} {Intrusion} {Detection}},
  Author    = {Egele, Manuel and Szydlowski, Martin and Kirda, Engin and Kruegel, Christopher},
  Booktitle = {Proceedings of the 3rd {International} {Conference} on {Detection} of {Intrusions} and {Malware} \& {Vulnerability} {Assessment}},
  Year      = {2006},
  Address   = {Berlin, Germany},
  Month     = jul,
  doi       = {10.1007/11790754_2},
  Kind      = {conference},
  Timestamp = {2006-07-13}
}

@InProceedings{Egele2014Blanket_Execution,
  Title     = {Blanket {Execution}: {Dynamic} {Similarity} {Testing} for {Program} {Binaries} and {Components}},
  Paper     = {yes},
  Author    = {Egele, Manuel and Woo, Maverick and Chapman, Peter and Brumley, David},
  Booktitle = {Proceedings of the 23rd Symposium on {USENIX} {Security}},
  Year      = {2014},
  Address   = {San Diego, CA},
  Month     = aug,
  ISBN      = {978-1-931971-15-7},
  Kind      = {conference},
  Timestamp = {2014-08-20}
}

@InProceedings{Egele2009Defending_Browsers,
  Paper     = {yes},
  Title     = {Defending {Browsers} against {Drive}-by {Downloads}: {Mitigating} {Heap}-{Spraying} {Code} {Injection} {Attacks}},
  Author    = {Egele, Manuel and Wurzinger, Peter and Kruegel, Christopher and Kirda, Engin},
  Booktitle = {Proceedings of the 6th {International} {Conference} on {Detection} of {Intrusions} and {Malware} \& {Vulnerability} {Assessment}},
  Year      = {2009},
  Address   = {Milan, Italy},
  Month     = jul,
  doi       = {10.1007/978-3-642-02918-9_6},
  Kind      = {conference},
  Timestamp = {2009-07-13}
}

@InProceedings{Falsina2015Grab_Run,
  Title     = {Grab 'n {Run}: {Secure} and {Practical} {Dynamic} {Code} {Loading} for {Android} {Applications}},
  Author    = {Falsina, Luca and Fratantonio, Yanick and Zanero, Stefano and Kruegel, Christopher and Vigna, Giovanni and Maggi, Federico},
  Booktitle = {Proceedings of the 31st {Annual} {Computer} {Security} {Applications} {Conference}},
  Year      = {2015},
  Address   = {Los Angeles, USA},
  Month     = dec,
  Publisher = {ACM},
  Series    = {{ACSAC} '15},
  Volume    = {(to appear)},
  Abstract  = {Android introduced the dynamic code loading (DCL) mechanism to allow for code reuse, to achieve extensibility, to enable updating functionalities or to boost application start- up performance. In spite of its wide adoption by developers, implementing DCL in a secure way is challenging, leading to serious vulnerabilities such as remote code injection. Previous academic and community attempts at solving this problem are unfortunately either impractical or incomplete, or in some cases exhibit vulnerabilities. In this paper, we propose, design, implement and test Grab n Run, a novel code verification protocol and a series of supporting libraries, APIs, and components, that address the problem by abstracting away from the developer challenging implementation details. Grab n Run is designed to be practical: among its tools, it provides a drop-in library, which requires no modifications to the Android framework or the underlying Dalvik/ART runtime, is very similar to the native API, and most code can be automatically rewritten to use it. Grab n Run also contains an application rewriting tool, which allows easy porting of existing applications to use the secure API of its library. We evaluate Grab n Run library with a user study, obtaining impressive results in vulnerability reduction, ease of use and speed of development. We also show that the performance overhead introduced by our library is negligible. The library is released as free software.},
  Kind      = {conference},
  Timestamp = {2015-12-07}
}

@InProceedings{Federico2015How_the,
  Title     = {How the {ELF} {Ruined} {Christmas}},
  Author    = {Federico, Alessandro Di and Cama, Amat and Shoshitaishvili, Yan and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the Symposium on the 24th {USENIX} {Security}},
  Year      = {2015},
  Address   = {Washington, D.C.},
  Month     = aug,
  Pages     = {643--658},
  Publisher = {USENIX Association},
  ISBN      = {978-1-931971-23-2},
  Url       = {https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/di-frederico},
  Kind      = {conference},
  Timestamp = {2015-08-12}
}

@InProceedings{Felmetsger2010Toward_Automated,
  Title     = {Toward {Automated} {Detection} of {Logic} {Vulnerabilities} in {Web} {Applications}},
  Author    = {Felmetsger, Viktoria and Cavedon, Ludovico and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the 19th Symposium on {USENIX} {Security}},
  Year      = {2010},
  Address   = {Washington, DC},
  Month     = aug,
  Kind      = {conference},
  Timestamp = {2010-08-11}
}

@InProceedings{Felmetsger2005Exploiting_OS-level,
  Title     = {Exploiting {OS}-level {Mechanisms} to {Implement} {Mobile} {Code} {Security}},
  Author    = {Felmetsger, Viktoria and Vigna, Giovanni},
  Booktitle = {Proceedings of the 10th {IEEE} {International} {Conference} on {Engineering} of {Complex} {Computer} {Systems} ({ICECCS})},
  Year      = {2005},
  Address   = {Shanghai, China},
  Month     = jun,
  Kind      = {conference},
  Timestamp = {2005-06-16}
}

@InProceedings{Fischmeister2001Evaluating_the,
  Title     = {Evaluating the {Security} {Of} {Three} {Java}-{Based} {Mobile} {Agent} {Systems}},
  Author    = {Fischmeister, Sebastian and Vigna, Giovanni and Kemmerer, Richard A.},
  Booktitle = {Proceedings of the 5th {International} {Conference} on {Mobile} {Agents} ({MA} 39;01)},
  Year      = {2001},
  Address   = {Atlanta, GA},
  Month     = dec,
  Pages     = {31--41},
  Publisher = {Springer-Verlag},
  Volume    = {2240},
  Kind      = {conference},
  Timestamp = {2001-12-02}
}

@InProceedings{Ford2009Analyzing_and,
  Title     = {Analyzing and {Detecting} {Malicious} {Flash} {Advertisements}},
  Author    = {Ford, Sean and Cova, Marco and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the 25th {Annual} {Computer} {Security} {Applications} {Conference} ({ACSAC})},
  Year      = {2009},
  Address   = {Honolulu, HI},
  Month     = dec,
  Kind      = {conference},
  Timestamp = {2009-12-07}
}

@InProceedings{Foschini2008A_Parallel,
  Title     = {A {Parallel} {Architecture} for {Stateful}, {High}-{Speed} {Intrusion} {Detection}},
  Author    = {Foschini, Luca and Thapliyal, Ashish and Cavallaro, Lorenzo and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the {International} {Conference} on {Information} {Systems} {Security} ({ICISS})},
  Year      = {2008},
  Address   = {Hyderabad, India},
  Month     = dec,
  Pages     = {203--220},
  Publisher = {Springer},
  Kind      = {conference},
  Timestamp = {2008-12-14}
}

@InProceedings{Fratantonio2015On_the,
  Title     = {On the {Security} and {Engineering} {Implications} of {Finer}-{Grained} {Access} {Controls} for {Android} {Developers} and {Users}},
  Author    = {Fratantonio, Yanick and Bianchi, Antonio and Robertson, William and Egele, Manuel and Kruegel, Christopher and Kirda, Engin and Vigna, Giovanni},
  Booktitle = {Proceedings of the 12th Symposium on Detection of {Intrusions} and {Malware}, and {Vulnerability} {Assessment}},
  Year      = {2015},
  Month     = jul,
  Pages     = {282--303},
  Publisher = {Springer International Publishing},
  Abstract  = {One of the main security mechanisms in Android is the permission system. Previous research has pointed out that this system is too coarse-grained. Hence, several mechanisms have been proposed to address this issue. However, to date, the impact of changes in the current permission system on both end users and software developers has not been studied, and no significant work has been done to determine whether adopting a finer-grained permission system would be feasible in practice. In this work, we perform the first study to explore the practicality of the adoption of finer-grained system for the Internet permission. In particular, we have developed several analysis tools that we used to perform an empirical study on 1,227 real-world Android applications. The results of this study provide useful insights to answer the following three conceptual questions: (1) Is it practical to apply fine-grained access control mechanisms to real-world Android applications? (2) How can a system for fine-grained permission enforcement be integrated into the application development and distribution life-cycle with minimal additional required effort? (3) What are the incentives and practical benefits for both developers and end users to adopt a fine-grained permission model? Our preliminary results show that, in general, finer-grained permissions could be practical and desirable for Android applications. In addition, we show how the tools we have developed can be used to automatically generate and enforce security policies, and thus could be used to lower the burden of adoption of finer-grained permission systems.},
  Copyright = {2015 Springer International Publishing Switzerland},
  ISBN      = {978-3-319-20549-6 978-3-319-20550-2},
  Language  = {en},
  doi       = {10.1007/978-3-319-20550-2_15},
  Url       = {http://link.springer.com/chapter/10.1007/978-3-319-20550-2_15},
  Kind      = {conference},
  Timestamp = {2015-12-11}
}

@InProceedings{Fratantonio2016Shellzer_a,
  Title      = {Shellzer: a tool for the dynamic analysis of malicious shellcode},
  Paper      = {yes},
  Author     = {Fratantonio, Yanick and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle  = {Proceedings of the 14th {Symposium} on {Recent} {Advances} in {Intrusion} {Detection} ({RAID})},
  Year       = {2011},
  Address    = {S. Francisco, CA},
  Pages      = {61--80},
  Publisher  = {Springer},
  Kind       = {conference},
  Timestamp  = {2016-01-26}
}

@InProceedings{Fratantonio2015CLAPP_Characterizing,
  Paper     = {yes},
  Title      = {{CLAPP}: {Characterizing} {Loops} in {Android} {Applications}},
  Author     = {Fratantonio, Yanick and Machiry, Aravind and Bianchi, Antonio and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle  = {Proceedings of the 10th {Joint} {Meeting} on {Foundations} of {Software} {Engineering} {(ESEC/FSE)}},
  Year       = {2015},
  Address    = {New York, NY, USA},
  Pages      = {687--697},
  Publisher  = {ACM},
  Abstract   = {When performing program analysis, loops are one of the most important aspects that needs to be taken into account. In the past, many approaches have been proposed to analyze loops to perform different tasks, ranging from compiler optimizations to Worst-Case Execution Time (WCET) analysis. While these approaches are powerful, they focus on tackling very specific categories of loops and known loop patterns, such as the ones for which the number of iterations can be statically determined. In this work, we developed a static analysis framework to characterize and analyze generic loops, without relying on techniques based on pattern matching. For this work, we focus on the Android platform, and we implemented a prototype, called CLAPP, that we used to perform the first large-scale empirical study of the usage of loops in Android applications. In particular, we used our tool to analyze a total of 4,110,510 loops found in 11,823 Android applications. As part of our evaluation, we provide the detailed results of our empirical study, we show how our analysis was able to determine that the execution of 63.28\% of the loops is bounded, and we discuss several interesting insights related to the performance issues and security aspects associated with loops.},
  ISBN       = {978-1-4503-3675-8},
  doi        = {10.1145/2786805.2786873},
  Kind       = {conference},
  Timestamp  = {2015-12-11}
}

@InProceedings{Fratantonio2015CLAPP_Characterizing,
  Title     = {{CLAPP}: {Characterizing} {Loops} in {Android} {Applications} ({Invited} {Talk})},
  Author    = {Fratantonio, Yanick and Machiry, Aravind and Bianchi, Antonio and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the 3rd {International} {Workshop} on {Software} {Development} {Lifecycle} for {Mobile} {(DeMobile)}},
  Year      = {2015},
  Address   = {New York, NY, USA},
  Pages     = {33--34},
  Publisher = {ACM},
  ISBN      = {978-1-4503-3815-8},
  doi       = {10.1145/2804345.2804355},
  Kind      = {workshop},
  Timestamp = {2015-08-31}
}

@InProceedings{Frossi2009Selecting_and,
  Title     = {Selecting and {Improving} {System} {Call} {Models} for {Anomaly} {Detection}},
  Paper     = {yes},
  Author    = {Frossi, Alessandro and Maggi, Federico and Rizzo, GianLuigi and Zanero, Stefano},
  Booktitle = {Proceedings of the 6th {International} {Conference} on {Detection} of {Intrusions} and {Malware}, and {Vulnerability} {Assessment} ({DIMVA})},
  Year      = {2009},
  Month     = jul,
  Abstract  = {We propose a syscall-based anomaly detection system that incorporates both deterministic and stochastic models. We analyze in detail two alternative approaches for anomaly detection over system call sequences and arguments, and propose a number of modifications that significantly improve their performance. We begin by comparing them and analyzing their respective performance in terms of detection accuracy. Then, we outline their major shortcomings, and propose various changes in the models that can address them: we show how targeted modifications of their anomaly models, as opposed to the redesign of the global system, can noticeably improve the overall detection accuracy. Finally, the impact of these modifications are discussed by comparing the performance of the two original implementations with two modified versions complemented with our models.},
  Kind      = {conference},
  Timestamp = {2009-07-09}
}

@InCollection{Ghezzi1998Software_Engineering,
  Paper     = {yes},
  Title     = {Software {Engineering} {Issues} in {Network} {Computing}},
  Author    = {Ghezzi, Carlo and Vigna, Giovanni},
  Booktitle = {Requirements {Targeting} {Software} and {Systems} {Engineering}},
  Publisher = {Springer-Verlag},
  Year      = {1998},
  Month     = aug,
  Pages     = {101--123},
  Volume    = {1526},
  Kind      = {workshop},
  Timestamp = {1998-08-01}
}

@InProceedings{Gilbert2016Dymo_tracking,
  Title      = {Dymo: tracking dynamic code identity},
  Paper      = {yes},
  Author     = {Gilbert, Bob and Kemmerer, Richard and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle  = {Proceedings of the 11 Symposium on Recent {Advances} in {Intrusion} {Detection}},
  Year       = {2011},
  Address    = {Menlo Park, CA},
  Pages      = {21--40},
  Publisher  = {Springer},
  doi        = {10.1007/978-3-642-23644-0_2},
  Kind       = {conference},
  Timestamp  = {2016-01-26}
}

@InProceedings{Gundy2007Catch_Me,
  Paper     = {yes},
  Title     = {Catch {Me}, {If} {You} {Can}: {Evading} {Network} {Signatures} with {Web}-based {Polymorphic} {Worms}},
  Author    = {Gundy, Matthew Van and Balzarotti, Davide and Vigna, Giovanni},
  Booktitle = {Proceedings of the 1st {USENIX} {Workshop} on {Offensive} {Technologies} ({WOOT})},
  Year      = {2007},
  Address   = {Boston, MA},
  Month     = aug,
  Kind      = {workshop},
  Timestamp = {2007-08-06}
}

@InProceedings{Gundy2007Feature_Omission,
  Title     = {Feature {Omission} {Vulnerabilities}: {Thwarting} {Signature} {Generation} for {Polymorphic} {Worms}},
  Author    = {Gundy, Matthew Van and Chen, Hao and Su, Zhendong and Vigna, Giovanni},
  Booktitle = {Proceedings of the 23rd {Annual} {Computer} {Security} {Applications} {Conference} ({ACSAC})},
  Year      = {2007},
  Address   = {Miami, FL},
  Month     = dec,
  Pages     = {74--83},
  Kind      = {conference},
  Timestamp = {2007-12-01}
}

@InProceedings{Hallaraker2005Detecting_Malicious,
  Title     = {Detecting {Malicious} {JavaScript} {Code} in {Mozilla}},
  Author    = {Hallaraker, Oystein and Vigna, Giovanni},
  Booktitle = {Proceedings of the 8th {IEEE} {International} {Conference} on {Engineering} of {Complex} {Computer} {Systems} ({ICECCS})},
  Year      = {2005},
  Address   = {Shanghai, China},
  Month     = jun,
  Pages     = {85--94},
  Kind      = {conference},
  Timestamp = {2005-06-01}
}

@InProceedings{Haller2013Dowsing_for,
  Title     = {Dowsing for {Overflows}: {A} {Guided} {Fuzzer} to {Find} {Buffer} {Boundary} {Violations}},
  Author    = {Haller, Istvan and Slowinska, Asia and Neugschwandtner, Matthias and Bos, Herbert},
  Booktitle = {Proceedings of the 22nd Symposium on {USENIX} {Security}},
  Year      = {2013},
  Month     = aug,
  Abstract  = {Dowser is a guided fuzzer that combines taint tracking, program analysis and symbolic execution to find buffer overflow and underflow vulnerabilities buried deep in a programs logic. The key idea is that analysis of a program lets us pinpoint the right areas in the program code to probe and the appropriate inputs to do so.

  Intuitively, for typical buffer overflows, we need consider only the code that accesses an array in a loop, rather than all possible instructions in the program. After finding all such candidate sets of instructions, we rank them according to an estimation of how likely they are to contain interesting vulnerabilities. We then subject the most promising sets to further testing. Specifically, we first use taint analysis to determine which input bytes influence the array index and then execute the program symbolically, making only this set of inputs symbolic. By constantly steering the symbolic execution along branch outcomes most likely to lead to overflows, we were able to detect deep bugs in real programs (like the nginx webserver, the inspircd IRC server, and the ffmpeg videoplayer). Two of the bugs we found were previously undocumented buffer overflows in ffmpeg and the poppler PDF rendering library.},
  Kind      = {conference},
  Timestamp = {2013-08-13}
}

@InProceedings{Hine2017Kek,_Cucks,
  Title     = {Kek, {Cucks}, and {God} {Emperor} {Trump}: {A} {Measurement} {Study} of 4chan's {Politically} {Incorrect} {Forum} and its {Effects} on the {Web}},
  Author    = {Hine, Gabriel and Onaolapo, Jeremiah and De Cristofaro, Emiliano and Kourtellis, Nicolas and Leontiadis, Ilias and Samaras, Riginos and Stringhini, Gianluca and Blackburn, Jeremy},
  Booktitle = {Proceedings of the 11th International {Conference} on {Web} and {Social} {Media} ({ICWSM})},
  Year      = {2017},
  Month     = mar,
  Publisher = {AAAI},
  Abstract  = {The discussion-board site 4chan has been part of the Internets dark underbelly since its inception, and recent political events have put it increasingly in the spotlight. In particular, /pol/, the Politically Incorrect board, has been a central figure in the outlandish 2016 US election season, as it has often been linked to the alt-right movement and its rhetoric of hate and racism. However, 4chan remains relatively unstudied by the scientific community: little is known about its user base, the content it generates, and how it affects other parts of the Web. In this paper, we start addressing this gap by analyzing /pol/ along several axes, using a dataset of over 8M posts we collected over two and a half months. First, we perform a general characterization, showing that /pol/ users are well distributed around the world and that 4chans unique features encourage fresh discussions. We also analyze content, finding, for instance, that YouTube links and hate speech are predominant on /pol/. Overall, our analysis not only provides the first measurement study of /pol/, but also insight into online harassment and hate speech trends in social media.},
  Kind      = {conference},
  Timestamp = {2017-03-16}
}

@InProceedings{Iedemska2015The_Tricks,
  Title      = {The {Tricks} of the {Trade}: {What} {Makes} {Spam} {Campaigns} {Successful}?},
  Paper      = {yes},
  Author     = {Iedemska, Jane and Stringhini, Gianluca and Kemmerer, Richard and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle  = {Proceedings of the 2014 {IEEE} {Security} and {Privacy} {Workshops} {(SPW)}},
  Year       = {2014},
  Address    = {Washington, DC, USA},
  Pages      = {77--83},
  Publisher  = {IEEE Computer Society},
  Abstract   = {Spam is a profitable business for cyber criminals, with the revenue of a spam campaign that can be in the order of millions of dollars. For this reason, a wealth of research has been performed on understanding how spamming botnets operate, as well as what the economic model behind spam looks like. Running a spamming botnet is a complex task: the spammer needs to manage the infected machines, the spam content being sent, and the email addresses to be targeted, among the rest. In this paper, we try to understand which factors influence the spam delivery process and what characteristics make a spam campaign successful. To this end, we analyzed the data stored on a number of command and control servers of a large spamming botnet, together with the guidelines and suggestions that the botnet creators provide to spammers to improve the performance of their botnet.},
  ISBN       = {978-1-4799-5103-1},
  doi        = {10.1109/SPW.2014.21},
  Kind       = {workshop},
  Timestamp  = {2015-12-11}
}

@InProceedings{Ilia2015FaceOff_Preventing,
  Paper     = {yes},
  Title     = {Face/{Off}: {Preventing} {Privacy} {Leakage} {From} {Photos} in {Social} {Networks}},
  Author    = {Ilia, Panagiotis and Polakis, Iasonas and Athanasopoulos, Elias and Maggi, Federico and Ioannidis, Sotiris},
  Booktitle = {Proceedings of the 2015 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security} {(CCS)}},
  Year      = {2015},
  Address   = {Denver, USA},
  Month     = oct,
  Publisher = {ACM},
  Kind      = {conference},
  Timestamp = {2015-10-12}
}

@InProceedings{Invernizzi2016Evilseed_A,
  Title      = {Evilseed: {A} guided approach to finding malicious web pages},
  Paper      = {yes},
  Author     = {Invernizzi, Luca and Comparetti, Paolo Milani and Benvenuti, Stefano and Kruegel, Christopher and Cova, M. and Vigna, Giovanni},
  Booktitle  = {Proceedings of the 33rd Symposiym on Security and {Privacy}},
  Year       = {2012},
  Address    = {San Francisco, CA, USA},
  Pages      = {428--442},
  Publisher  = {IEEE},
  Url        = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6234428},
  Kind       = {conference},
  Timestamp  = {2016-01-26}
}

@InProceedings{Invernizzi2015Message_in,
  Paper     = {yes},
  Title      = {Message in a {Bottle}: {Sailing} {Past} {Censorship}},
  Author     = {Invernizzi, Luca and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle  = {{Proceedings of the 29th Annual Computer Security Applications Conference (ACSAC)}},
  Year       = {2013},
  Address    = {New York, NY, USA},
  Pages      = {39--48},
  Publisher  = {ACM},
  Abstract   = {Exploiting recent advances in monitoring technology and the drop of its costs, authoritarian and oppressive regimes are tightening the grip around the virtual lives of their citizens. Meanwhile, the dissidents, oppressed by these regimes, are organizing online, cloaking their activity with anti-censorship systems that typically consist of a network of anonymizing proxies. The censors have become well aware of this, and they are systematically finding and blocking all the entry points to these networks. So far, they have been quite successful. We believe that, to achieve resilience to blocking, anti-censorship systems must abandon the idea of having a limited number of entry points. Instead, they should establish first contact in an online location arbitrarily chosen by each of their users. To explore this idea, we have developed Message In A Bottle, a protocol where any blog post becomes a potential "drop point" for hidden messages. We have developed and released a proof-of-concept application of our system, and demonstrated its feasibility. To block this system, censors are left with a needle-in-a-haystack problem: Unable to identify what bears hidden messages, they must block everything, effectively disconnecting their own network from a large part of the Internet. This, hopefully, is a cost too high to bear.},
  ISBN       = {978-1-4503-2015-3},
  doi        = {10.1145/2523649.2523654},
  Kind       = {conference},
  Timestamp  = {2015-12-11}
}

@InProceedings{Invernizzi2014Nazca_Detecting,
  Paper     = {yes},
  Title     = {Nazca: {Detecting} {Malware} {Distribution} in {Large}-{Scale} {Networks}},
  Author    = {Invernizzi, Luca and Miskovic, Stanislav and Torres, Ruben and Saha, Sabyaschi and Lee, Sung-Ju and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the 21st Symposium on {Network} and {Distributed} {System} {Security} {Symposium}},
  Year      = {2014},
  Month     = feb,
  Url       = {http://seclab.cs.ucsb.edu/media/uploads/papers/invernizzi_nazca_ndss14.pdf},
  Kind      = {conference},
  Timestamp = {2014-02-23}
}

@InProceedings{Kapravelos2015Escape_from,
  Title      = {Escape from {Monkey} {Island}: {Evading} {High}-interaction {Honeyclients}},
  Author     = {Kapravelos, Alexandros and Cova, Marco and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle  = {{Proceedings of the 8th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA)}},
  Year       = {2011},
  Address    = {Berlin, Heidelberg},
  Pages      = {124--143},
  Publisher  = {Springer-Verlag},
  Abstract   = {High-interaction honeyclients are the tools of choice to detect malicious web pages that launch drive-by-download attacks. Unfortunately, the approach used by these tools, which, in most cases, is to identify the side-effects of a successful attack rather than the attack itself, leaves open the possibility for malicious pages to perform evasion techniques that allow one to execute an attack without detection or to behave in a benign way when being analyzed. In this paper, we examine the security model that high-interaction honeyclients use and evaluate their weaknesses in practice. We introduce and discuss a number of possible attacks, and we test them against several popular, well-known high-interaction honeyclients. Our attacks evade the detection of these tools, while successfully attacking regular visitors of malicious web pages.},
  ISBN       = {978-3-642-22423-2},
  Url        = {http://dl.acm.org/citation.cfm?id=2026647.2026658},
  Kind       = {conference},
  Timestamp  = {2015-12-11}
}

@InProceedings{Kapravelos2016Revolver_An,
  Title      = {Revolver: {An} {Automated} {Approach} to the {Detection} of {Evasive} {Web}-based {Malware}.},
  Paper      = {yes},
  Author     = {Kapravelos, Alexandros and Shoshitaishvili, Yan and Cova, Marco and Kruegel, Christopher and Vigna, Giovanni},
  Booktitle  = {Proceedings of the 22nd Symposium on {USENIX} {Security}},
  Year       = {2013},
  Pages      = {637--652},
  Kind       = {conference},
  Timestamp  = {2016-01-26}
}

@inBook{Kemmerer2005Sensor_Families,
  Paper     = {yes},
  Title     = {Sensor {Families} for {Intrusion} {Detection} {Infrastructures}},
  Author    = {Kemmerer, Richard A. and Vigna, Giovanni},
  Booktitle = {Managing {Cyber} {Threats}: {Issues}, {Approaches} and {Challenges}},
  Publisher = {Springer-Verlag},
  Year      = {2005},
  Series    = {Massive {Computing}},
  Volume    = {5},
  Kind      = {chapter},
  Timestamp = {2005-01-01}
}

@Article{Kemmerer2002Intrusion_Detection,
  Title     = {Intrusion {Detection}: {A} {Brief} {History} and {Overview}},
  Author    = {Kemmerer, Richard A. and Vigna, Giovanni},
  Journal   = {IEEE Computer},
  Year      = {2002},
  Month     = apr,
  Pages     = {27--30},
  Kind      = {journal},
  Timestamp = {2002-04-01}
}

@InProceedings{Kirat2015SigMal_A,
  Title      = {{SigMal}: {A} {Static} {Signal} {Processing} {Based} {Malware} {Triage}},
  Paper      = {yes},
  Author     = {Kirat, Dhilung and Nataraj, Lakshmanan and Vigna, Giovanni and Manjunath, B. S.},
  Booktitle  = {Proceedings of the 29th {Annual} {Computer} {Security} {Applications} {Conference}},
  Year       = {2013},
  Address    = {New York, NY, USA},
  Pages      = {89--98},
  Publisher  = {ACM},
  Series     = {{ACSAC} '13},
  Abstract   = {In this work, we propose SigMal, a fast and precise malware detection framework based on signal processing techniques. SigMal is designed to operate with systems that process large amounts of binary samples. It has been observed that many samples received by such systems are variants of previously-seen malware, and they retain some similarity at the binary level. Previous systems used this notion of malware similarity to detect new variants of previously-seen malware. SigMal improves the state-of-the-art by leveraging techniques borrowed from signal processing to extract noise-resistant similarity signatures from the samples. SigMal uses an efficient nearest-neighbor search technique, which is scalable to millions of samples. We evaluate SigMal on 1.2 million recent samples, both packed and unpacked, observed over a duration of three months. In addition, we also used a constant dataset of known benign executables. Our results show that SigMal can classify 50\% of the recent incoming samples with above 99\% precision. We also show that SigMal could have detected, on average, 70 malware samples per day before any antivirus vendor detected them.},
  ISBN       = {978-1-4503-2015-3},
  doi        = {10.1145/2523649.2523682},
  Kind       = {conference},
  Timestamp  = {2015-12-11}
}

@InProceedings{Kirat2015MalGene_Automatic,
  Paper     = {yes},
  Title      = {{MalGene}: {Automatic} {Extraction} of {Malware} {Analysis} {Evasion} {Signature}},
  Author     = {Kirat, Dhilung and Vigna, Giovanni},
  Booktitle  = {Proceedings of the 22Nd {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
  Year       = {2015},
  Address    = {New York, NY, USA},
  Pages      = {769--780},
  Publisher  = {ACM},
  Series     = {{CCS} '15},
  Abstract   = {Automated dynamic malware analysis is a common approach for detecting malicious software. However, many malware samples identify the presence of the analysis environment and evade detection by not performing any malicious activity. Recently, an approach to the automated detection of such evasive malware was proposed. In this approach, a malware sample is analyzed in multiple analysis environments, including a bare-metal environment, and its various behaviors are compared. Malware whose behavior deviates substantially is identified as evasive malware. However, a malware analyst still needs to re-analyze the identified evasive sample to understand the technique used for evasion. Different tools are available to help malware analysts in this process. However, these tools in practice require considerable manual input along with auxiliary information. This manual process is resource-intensive and not scalable. In this paper, we present MalGene, an automated technique for extracting analysis evasion signatures. MalGene leverages algorithms borrowed from bioinformatics to automatically locate evasive behavior in system call sequences. Data flow analysis and data mining techniques are used to identify call events and data comparison events used to perform the evasion. These events are used to construct a succinct evasion signature, which can be used by an analyst to quickly understand evasions. Finally, evasive malware samples are clustered based on their underlying evasive techniques. We evaluated our techniques on 2810 evasive samples. We were able to automatically extract their analysis evasion signatures and group them into 78 similar evasion techniques.},
  ISBN       = {978-1-4503-3832-5},
  doi        = {10.1145/2810103.2813642},
  Kind       = {conference},
  Timestamp  = {2015-12-11}
}

@InProceedings{Kirat2015Barecloud_Bare-metal,
  Title      = {Barecloud: {Bare}-metal {Analysis}-based {Evasive} {Malware} {Detection}},
  Author     = {Kirat, Dhilung and Vigna, Giovanni and Kruegel, Christopher},
  Booktitle  = {Proceedings of the 23rd {USENIX} {Conference} on {Security} {Symposium}},
  Year       = {2014},
  Address    = {Berkeley, CA, USA},
  Pages      = {287--301},
  Publisher  = {USENIX Association},
  Series     = {{SEC}'14},
  Abstract   = {The volume and the sophistication of malware are continuously increasing and evolving. Automated dynamic malware analysis is a widely-adopted approach for detecting malicious software. However, many recent malware samples try to evade detection by identifying the presence of the analysis environment itself, and refraining from performing malicious actions. Because of the sophistication of the techniques used by the malware authors, so far the analysis and detection of evasive malware has been largely a manual process. One approach to automatic detection of these evasive malware samples is to execute the same sample in multiple analysis environments, and then compare its behaviors, in the assumption that a deviation in the behavior is evidence of an attempt to evade one or more analysis systems. For this reason, it is important to provide a reference system (often called bare-metal) in which the malware is analyzed without the use of any detectable component. In this paper, we present BareCloud, an automated evasive malware detection system based on bare-metal dynamic malware analysis. Our bare-metal analysis system does not introduce any in-guest monitoring component into the malware execution platform. This makes our approach more transparent and robust against sophisticated evasion techniques. We compare the malware behavior observed in the bare-metal system with other popular malware analysis systems. We introduce a novel approach of hierarchical similarity-based malware behavior comparison to analyze the behavior of a sample in the various analysis systems. Our experiments show that our approach produces better evasion detection results compared to previous methods. BareCloud was able to automatically detect 5,835 evasive malware out of 110,005 recent samples.},
  ISBN       = {978-1-931971-15-7},
  Url        = {http://dl.acm.org/citation.cfm?id=2671225.2671244},
  Kind       = {conference},
  Timestamp  = {2015-12-11}
}

@InProceedings{Kirat2016BareBox_efficient,
  Title      = {{BareBox}: efficient malware analysis on bare-metal},
  Paper      = {yes},
  Author     = {Kirat, Dhilung and Vigna, Giovanni and Kruegel, Christopher},
  Booktitle  = {Proceedings of the 27th {Annual} {Computer} {Security} {Applications} {Conference}},
  Year       = {2011},
  Address    = {Orlando, FL},
  Pages      = {403--412},
  Publisher  = {ACM},
  Kind       = {conference},
  Timestamp  = {2016-01-26}
}

@Article{Kirda2009Client-Side_Cross-Site,
  Paper     = {yes},
  Title     = {Client-{Side} {Cross}-{Site} {Scripting} {Protection}},
  Author    = {Kirda, Engin and Jovanovic, Nenad and Kruegel, Christopher and Vigna, Giovanni},
  Journal   = {Computers \& Security},
  Year      = {2009},
  Number    = {7},
  Pages     = {592--604},
  Volume    = {28},
  Kind      = {journal},
  Timestamp = {2009-01-01}
}

@InProceedings{Kirda2006Behavior-based_Spyware,
  Title     = {Behavior-based {Spyware} {Detection}},
  Author    = {Kirda, Engin and Kruegel, Christopher and Banks, Greg and Vigna, Giovanni and Kemmerer, Richard},
  Booktitle = {Proceedings of the 15th Symposium on the {USENIX} {Security}},
  Year      = {2006},
  Address   = {Vancouver, Canada},
  Month     = aug,
  Kind      = {conference},
  Timestamp = {2006-08-01}
}

@Article{Klinkoff2007Extending_.NET,
  Title     = {Extending .{NET} {Security} to {Unmanaged} {Code}},
  Author    = {Klinkoff, Patrick and Kirda, Engin and Kruegel, Christopher and Vigna, Giovanni},
  Journal   = {International Journal of Information Security},
  Year      = {2007},
  Month     = oct,
  Number    = {6},
  Pages     = {417--428},
  Volume    = {6},
  Kind      = {journal},
  Timestamp = {2007-10-01}
}

@InProceedings{Kolbitsch2009Effective_and,
  Title     = {Effective and efficient malware detection at the end host},
  Author    = {Kolbitsch, Clemens and Comparetti, Paolo Milani and Kruegel, Christopher and Kirda, Engin and Zhou, Xiaoyong and Wang, XiaoFeng},
  Booktitle = {Proceedings of the 18th conference on {USENIX} security symposium},
  Year      = {2009},
  Pages     = {351--366},
  Publisher = {USENIX Association},
  Kind      = {conference},
  Timestamp = {2009-06-14}
}

@InProceedings{Kolbitsch2010Inspector_Gadget,
  Title     = {Inspector {Gadget}: {Automated} {Extraction} of {Proprietary} {Gadgets} from {Malware} {Binaries}},
  Author    = {Kolbitsch, Clemens and Holz, Thorsten and Kruegel, Christopher and Kirda, Engin},
  Booktitle = {Proceedings of the 31st {IEEE} {Symposium} on {Security} and {Privacy}},
  Year      = {2010},
  doi       = {10.1109/SP.2010.10},
  Pages     = {29--44},
  Kind      = {conference},
  Timestamp = {2010-05-16}
}

@InProceedings{Kruegel2007Improving_Signature,
  Title     = {Improving {Signature} {Testing} {Through} {Dynamic} {Data} {Flow} {Analysis}},
  Author    = {Kruegel, Christopher and Balzarotti, Davice and Robertson, William and Vigna, Giovanni},
  Booktitle = {Proceedings of the 23rd {Annual} {Computer} {Security} {Applications} {Conference} ({ACSAC})},
  Year      = {2007},
  Address   = {Miami, FL},
  Month     = dec,
  Pages     = {53--63},
  Kind      = {conference},
  Timestamp = {2007-12-01}
}

@InProceedings{Kruegel2005Automating_Mimicry,
  Title     = {Automating {Mimicry} {Attacks} {Using} {Static} {Binary} {Analysis}},
  Author    = {Kruegel, Christopher and Kirda, Engin and Mutz, Darren and Robertson, William and Vigna, Giovanni},
  Booktitle = {Proceedings of the 14th Symposium on {USENIX} {Security}},
  Year      = {2005},
  Address   = {Baltimore, MD},
  Month     = aug,
  Kind      = {conference},
  Timestamp = {2005-08-10}
}

@InProceedings{Kruegel2005Polymorphic_Worm,
  Title     = {Polymorphic {Worm} {Detection} {Using} {Structural} {Information} of {Executables}},
  Author    = {Kruegel, Christopher and Kirda, Engin and Mutz, Darren and Robertson, William and Vigna, Giovanni},
  Booktitle = {Proceedings of the 8th {International} {Symposium} on {Recent} {Advances} in {Intrusion} {Detection} ({RAID})},
  Year      = {2005},
  Address   = {Seattle, WA},
  Month     = sep,
  Pages     = {207--226},
  Publisher = {Springer-Verlag},
  Series    = {{LNCS}},
  Volume    = {3858},
  Kind      = {conference},
  Timestamp = {2005-10-01}
}

@InProceedings{Kruegel2005Reverse_Engineering,
  Title     = {Reverse {Engineering} of {Network} {Signatures}},
  Author    = {Kruegel, Christopher and Mutz, Darren and Robertson, William and Vigna, Giovanni and Kemmerer, Richard},
  Booktitle = {Proceedings of the {AusCERT} {Asia} {Pacific} {Information} {Technology} {Security} {Conference}},
  Year      = {2005},
  Address   = {Gold Coast, Australia},
  Month     = may,
  Kind      = {conference},
  Timestamp = {2005-05-01}
}

@InProceedings{Kruegel2003On_the,
  Title     = {On the {Detection} of {Anomalous} {System} {Call} {Arguments}},
  Author    = {Kruegel, Christopher and Mutz, Darren and Valeur, Fredrik and Vigna, Giovanni},
  Booktitle = {Proceedings of the 8th {European} {Symposium} on {Research} in {Computer} {Security} ({ESORICS} 39;03)},
  Year      = {2003},
  Address   = {Gjovik, Norway},
  Month     = oct,
  Pages     = {326--343},
  Publisher = {Springer-Verlag},
  Series    = {{LNCS}},
  Kind      = {conference},
  Timestamp = {2003-10-01}
}

@InProceedings{Kruegel2004Static_Disassembly,
  Title     = {Static {Disassembly} of {Obfuscated} {Binaries}},
  Author    = {Kruegel, Christopher and Robertson, William and Valeur, Fredrik and Vigna, Giovanni},
  Booktitle = {Proceedings of 13th Symposium on {USENIX} {Security}},
  Year      = {2004},
  Address   = {San Diego, CA},
  Month     = aug,
  Pages     = {255--270},
  Kind      = {conference},
  Timestamp = {2004-08-01}
}

@InProceedings{Kruegel2004Detecting_Kernel-Level,
  Title     = {Detecting {Kernel}-{Level} {Rootkits} {Through} {Binary} {Analysis}},
  Author    = {Kruegel, Christopher and Robertson, William and Vigna, Giovanni},
  Booktitle = {Proceedings of the 20th {Annual} {Computer} {Security} {Applications} {Conference} ({ACSAC})},
  Year      = {2004},
  Address   = {Tucson, AZ},
  Month     = dec,
  Pages     = {91--100},
  Kind      = {conference},
  Timestamp = {2004-12-01}
}

@Article{Kruegel2004Using_Alert,
  Title     = {Using {Alert} {Verification} to {Identify} {Successful} {Intrusion} {Attempts}},
  Author    = {Kruegel, Christopher and Robertson, William and Vigna, Giovanni},
  Journal   = {Practice in Information Processing and Communication (PIK)},
  Year      = {2004},
  Month     = dec,
  Number    = {4},
  Pages     = {219 -- 227},
  Volume    = {27},
  Kind      = {journal},
  Timestamp = {2004-12-01}
}

@inBook{Kruegel2005Intrusion_Detection,
  Paper     = {yes},
  Title     = {Intrusion {Detection} and {Correlation}: {Challenges} and {Solutions}},
  Author    = {Kruegel, Christopher and Valeur, Fredrik and Vigna, Giovanni},
  Publisher = {Springer},
  Year      = {2005},
  Series    = {Advances in {Information} {Security}},
  Volume    = {14},
  Kind      = {chapter},
  Timestamp = {2005-01-01}
}

@InProceedings{Kruegel2002Stateful_Intrusion,
  Title     = {Stateful {Intrusion} {Detection} for {High}-{Speed} {Networks}},
  Author    = {Kruegel, Christopher and Valeur, Fredrik and Vigna, Giovanni and Kemmerer, Richard A.},
  Booktitle = {Proceedings of the 23rd {IEEE} {Symposium} on {Security} and {Privacy}},
  Year      = {2002},
  Address   = {Oakland, CA},
  Month     = may,
  Pages     = {285--293},
  Publisher = {IEEE Press},
  Kind      = {conference},
  Timestamp = {2002-05-12}
}

@InProceedings{Kruegel2003Anomaly_Detection,
  Title     = {Anomaly {Detection} of {Web}-based {Attacks}},
  Author    = {Kruegel, Christopher and Vigna, Giovanni},
  Booktitle = {Proceedings of the 10th {ACM} {Conference} on {Computer} and {Communication} {Security} ({CCS} 39;03)},
  Year      = {2003},
  Address   = {Washington, DC},
  Month     = oct,
  Pages     = {251--261},
  Publisher = {ACM Press},
  Kind      = {conference},
  Timestamp = {2003-10-27}
}

@Article{Kruegel2015A_Multi-model,
  Title     = {A {Multi}-model {Approach} to the {Detection} of {Web}-based {Attacks}},
  Paper     = {yes},
  Author    = {Kruegel, Christopher and Vigna, Giovanni and Robertson, William},
  Journal   = {Comput. Netw.},
  Year      = {2005},
  Month     = aug,
  Number    = {5},
  Pages     = {717--738},
  Volume    = {48},
  Abstract  = {Web-based vulnerabilities represent a substantial portion of the security exposures of computer networks. In order to detect known web-based attacks, misuse detection systems are equipped with a large number of signatures. Unfortunately, it is difficult to keep up with the daily disclosure of web-related vulnerabilities, and, in addition, vulnerabilities may be introduced by installation-specific web-based applications. Therefore, misuse detection systems should be complemented with anomaly detection systems.This paper presents an intrusion detection system that uses a number of different anomaly detection techniques to detect attacks against web servers and web-based applications. The system analyzes client queries that reference server-side programs and creates models for a wide-range of different features of these queries. Examples of such features are access patterns of server-side programs or values of individual parameters in their invocation. In particular, the use of application-specific characterization of the invocation parameters allows the system to perform focused analysis and produce a reduced number of false positives.The system derives automatically the parameter profiles associated with web applications (e.g., length and structure of parameters) and relationships between queries (e.g., access times and sequences) from the analyzed data. Therefore, it can be deployed in very different application environments without having to perform time-consuming tuning and configuration.},
  ISSN      = {1389-1286},
  doi       = {10.1016/j.comnet.2005.01.009},
  Kind      = {journal},
  Timestamp = {2015-12-11}
}

@InProceedings{Lanzi2010AccessMiner_using,
  Paper     = {yes},
  Title     = {{AccessMiner}: using system-centric models for malware protection},
  Author    = {Lanzi, Andrea and Balzarotti, Davide and Kruegel, Christopher and Christodorescu, Mihai and Kirda, Engin},
  Booktitle = {Proceedings of the 17th {Conference} on {Computer} and {Communications} {Security}},
  Year      = {2010},
  doi       = {10.1145/1866307.1866353},
  Pages     = {399--412},
  Kind      = {conference},
  Timestamp = {2010-09-08}
}

@InProceedings{Lazarov2016Honey_Sheets,
  Title     = {Honey {Sheets}: {What} {Happens} to {Leaked} {Google} {Spreadsheets}?},
  Paper     = {yes},
  Author    = {Lazarov, Martin and Onaolapo, Jeremiah and Stringhini, Gianluca},
  Booktitle = {Proceedings of the 2016 {USENIX} {Workshop} on {Cyber} {Security} {Experimentation} and {Test} ({CSET})},
  Year      = {2016},
  Address   = {Austin, TX},
  Month     = aug,
  Publisher = {USENIX},
  Abstract  = {Cloud-based documents are inherently valuable, due to the volume and nature of sensitive personal and business content stored in them. Despite the importance of such documents to Internet users, there are still large gaps in the understanding of what cybercriminals do when they illicitly get access to them by for example compromising the account credentials they are associated with. In this paper, we present a system able to monitor user activity on Google spreadsheets. We populated 5 Google spreadsheets with fake bank account details and fake funds transfer links. Each spreadsheet was configured to report details of accesses and clicks on links back to us. To study how people interact with these spreadsheets in case they are leaked, we posted unique links pointing to the spreadsheets on a popular paste site. We then monitored activity in the accounts for 72 days, and observed 165 accesses in total. We were able to observe interesting modifications to these spreadsheets performed by illicit accesses. For instance, we observed deletion of some fake bank account information, in addition to insults and warnings that some visitors entered in some of the spreadsheets. Our preliminary results show that our system can be used to shed light on cybercriminal behavior with regards to leaked online documents.},
  Kind      = {workshop},
  Timestamp = {2016-08-01}
}
